---
title: 高斯分布相关算法
date: '2022/12/17 20:53:18'
top_img: 'https://pic.hycbook.com/i//hexo/post_imgs/蕾姆2.webp'
cover: 'https://pic.hycbook.com/i//hexo/post_cover/蕾姆2.webp'
categories:
  - machine_learning
tags:
  - 机器学习
  - 高斯分布
mathjax: true
description: 高斯分布相关算法
---



---



---



# 学派

对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派，后面我们对观测集采用下面记号：
$$
X_{N\times p}=(x_{1},x_{2},\cdots,x_{N})^{T},x_{i}=(x_{i1},x_{i2},\cdots,x_{ip})^{T}
$$
$X$这个矩阵展开如下
$$
X=\left(\begin{array}{cccc}x_{11} & x_{12} & \cdots & x_{1 p} \\ x_{21} & x_{22} & \cdots & x_{2 p} \\ \vdots & & & \\ x_{N 1} & x_{N 22} & \cdots & x_{N p}\end{array}\right)_{N \times p}
$$
表示有$N$个样本，每个样本都是$p$维向量，其中假设每个观测都是由 $p(x|\theta)$生成的

## 频率派

频率派认为$p(x|\theta)$中的$\theta$是一个未知的常量，而数据是一个随机变量，关心的是数据，目标是估计未知的的常量$\theta$

常用的方法是`最大似然估计`
$$
\theta_{MLE}=\mathop{argmax}\limits _{\theta}\log p(X|\theta) \mathop{=} \mathop{argmax}\limits _{\theta}\prod\limits _{i=1}^{N}\log p(x_{i}|\theta) \mathop{=} \limits _{iid}\mathop{argmax}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)
$$
其中每个样本$x_{i}$独立同分布于$P(x \mid \theta)$，因此上面的累乘可以改写成累加的形式

## 贝叶斯派

贝叶斯派认为$p(x|\theta)$中的$\theta$是一个随机变量，且$\theta$服从一定的概率分$\theta\sim p(\theta)$，通常将$p(\theta)$成为`先验`

根据贝叶斯定理，将参数的`先验`和`后验`用`似然函数`联系起来
$$
p(\theta|X) = \frac{p(X|\theta)\cdot p(\theta)}{p(X)} = \frac{p(X|\theta)\cdot p(\theta)}{\int _{\theta}p(X|\theta)\cdot p(\theta)d\theta} \propto p(X|\theta)\cdot p(\theta)
$$
其中先验是$ p(\theta)$，后验是$p(\theta|X)$，似然函数为$p(\theta){p(X)}$

> 最大后验估计

为了估计$\theta$的值，我们使用`最大后验估计MAP`进行求解，其目的是找到一个$\theta$使用估计出来的结果最大
$$
\theta_{MAP}=\mathop{argmax}\limits _{\theta}p(\theta|X)  = \mathop{argmax}\limits _{\theta}\frac{p(X|\theta)\cdot p(\theta)}{p(X)} \propto \mathop{argmax}\limits _{\theta}p(X|\theta)\cdot p(\theta)
$$
其中$\propto$是因为对于分类问题而言$p(X)$都是一样的，可以看成一个常数，严格意义上MAP并不是标准的贝叶斯方法

> 贝叶斯估计

真正的`贝叶斯估计`是实实在在的去求解后验概率
$$
p(\theta|X) = \frac{p(X|\theta)\cdot p(\theta)}{p(X)} = \frac{p(X|\theta)\cdot p(\theta)}{\int _{\theta}p(X|\theta)\cdot p(\theta)d\theta}
$$
其中$\int _{\theta}p(X|\theta)\cdot p(\theta)d\theta$通常求解难度较大，因此可以随机采样算法，如`蒙特卡洛`MCMC算法进行近似求解

求出来的后验概率可以在`贝叶斯预测`时使用，假设这时候来了个新样本$\tilde{x}$，预测问题就是求$p(\tilde{x}|X)$

通过$\theta$这个桥梁，即$X \rightarrow \theta \rightarrow \tilde{x}$，上式可以变换如下
$$
p(\tilde{x}|X) = \int _{\theta} p(\tilde{x}, \theta|X) d \theta = \int _{\theta} p(\tilde{x}| \theta) \cdot p(\theta | X) d \theta
$$
其中$p(\theta | X)$就是贝叶斯估计求出来的后验

## 小结

`频率派`和`贝叶斯派`分别给出了一系列的机器学习算法

频率派的观点导出了一系列的`统计机器学习`算法，而贝叶斯派导出了`概率图`理论

频率派主要对应的问题是优化问题，通常的步骤是

1. 定义模型
2. 定义loss function
3. 优化算法

贝叶斯派主要是求积分的问题




# 高斯分布

> 笔记整理自：Bilibili站上[shuhuai008](https://www.bilibili.com/video/BV1aE411o7qd/?p=3)强势手推讲解的[白板推导CRF系列课程](https://www.bilibili.com/video/av34444816/?p=1)，课程质量很高！
>
> [B站scyw读者整理的笔记](https://www.yuque.com/bystander-wg876/yc5f72/hu0291)

高斯分布在机器学习中占有举足轻重的作用，尤其在统计机器学习中，比如线性高斯模型

线性高斯模型是一个体系，比如`卡曼滤波`，隐变量服从线性高斯分布，即$$Z_t = A Z_{t-1}+B+\epsilon$$，其中$$\epsilon$$是一个高斯噪声


$$
\begin{array}{l}  X=\left(x_{1}, x_{2}, \cdots, x_{N}\right)^{\top}=\left(\begin{array}{c}x_{1}^{\top} \\ x_{1}^{\top} \\ \vdots \\ x_{N}^{\top}\end{array}\right)_{N \times p} \end{array}
$$
其中$$x_{i} \in \mathbb{R}^{p}$$，$$x_{i}$$独立同分布于$N(\mu, \Sigma)$

## 参数估计

高斯分布下的MLE可以表述为
$$
\theta_{MLE}= \mathop{argmax}\limits _{\theta}\log p(X|\theta)\mathop{=}\limits _{iid}\mathop{argmax}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)
$$
这里先写出一维的高斯分布的概率密度函数
$$
p(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)
$$
高维的高斯分布密度函数为
$$
p(x)=\frac{1}{(2 \pi)^{\frac{p}{2}}|\Sigma|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}(x-\mu)^{\top} \Sigma^{-1}(x-\mu)\right)
$$

### 一维情况

假设$p=1$，$\theta=(\mu, \sigma ^2)$，将一维高斯分布的概率密度函数带入到MLE中，可以得到
$$
\begin{aligned} \log P(x \mid \theta) & =\log \prod_{i=1}^{N} p\left(x_{i} \mid \theta\right) \mathop{=}\limits _{iid} \sum_{i=1}^{N} \log p\left(x_{i} \mid \theta\right) \\ & =\sum_{i=1}^{N} \log \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}\right) \\ & =\sum_{i=1}^{N}\left[\log \frac{1}{\sqrt{2 \pi}}+\log \frac{1}{\sigma}-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}\right]\end{aligned}
$$

> 求解$\mu$

我们的目标是求解参数$\theta$，这里先求解$\mu$，可以得到
$$
\begin{array}{l} \mu_{M L E}=\arg \max _{\mu} \log P(x \mid \theta) \\ =argmax \sum_{i=1}^{N}-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}} \\ =argmin _{\mu} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2} 
\end{array}
$$
对$\mu$求偏导可以得到
$$
\begin{array}{l}

\frac{\partial}{\partial \mu} \sum\left(x_{i}-\mu\right)^{2}=\sum_{i=1}^{N} 2 \cdot\left(x_{i}-\mu\right) \cdot(-1)=0 
\\ 

\sum_{i=1}^{N}\left(x_{i}-\mu\right) = \sum_{i=1}^{N} x_{i}-\sum_{i=1}^{N} \mu =
 \sum_{i=1}^{N} x_{i}- N \mu=0 
\\ \mu_{M L E}=\frac{1}{N} \sum_{i=1}^{N} x_{i}

\end{array}
$$
这里的$\mu$是无偏估计，如果对$\mu$求期望，可以得到
$$
\begin{aligned} & E\left[\mu_{M L E}\right] = \frac{1}{N} \sum_{i=1}^{N} E\left[x_{i}\right] = \frac{1}{N} \sum_{i=1}^{N} \mu =  \frac{1}{N} \cdot N \cdot \mu =  \mu\end{aligned}
$$


> 求解$\Sigma$

同理
$$
\begin{array}{l} \sigma_{MLE}^{2} = argmax _{\sigma} P(x | \sigma) 

\\ = argmax \sum _{i=1}^{N} \left(-\log \sigma-\frac{1}{2 \sigma^{2}}\left(x_{i}-\mu\right)^{2}\right) = argmax (\mathcal{L}(\sigma)) \end{array}
$$
对$\sigma$求偏导，可以得到
$$
\begin{array}{l} 

\frac{\partial \mathcal{L}}{\partial \sigma} = \sum_{i=1}^{N}\left[-\frac{1}{\sigma}+\frac{1}{2}\left(x_{i}-\mu\right)^{2} \cdot2 \sigma^{-3}\right]=0 \Rightarrow\sum_{i=1}^{N}\left[-\frac{1}{\sigma}+\left(x_{i}-\mu\right)^{2} \cdot \sigma^{-3}\right]=0 

\\ \Rightarrow \sum_{i=1}^{N}\left[-\sigma^{2}+\left(x_{i}-\mu\right)^{2}\right]=0 \\ -\sum_{i=1}^{N} \sigma^{2}+\sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}=0 \\ \sum_{i=1}^{N} \sigma^{2}=\sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2} \\ \sigma_{M L E}^{2}=\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}\end{array}
$$
上式中的$\mu$严格意义上应该是$$\mu_{MLE}$$，此时$$\sigma_{M L E}^{2}$$是`有偏估计`，我们对$\sigma_{M L E}^{2}$求期望可以得到
$$
E[\sigma_{M L E}^{2}] = \frac {N-1}{N} \sigma ^2
$$
真实的`无偏估计`$\hat{\sigma}$应该是
$$
\hat{\sigma} = \frac{1}{N-1}\sum\limits _{i=1}^{N}(x_{i}-\mu_{MLE})^{2}
$$

























