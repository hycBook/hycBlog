---
title: 机器学习_线性代数与矩阵论
date: '2022/10/11 20:38:22'
top_img: 'https://pic.hycbook.com/i/hexo/post_imgs/蕾姆1.webp'
cover: 'https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp'
categories:
  - math
tags:
  - python
  - 机器学习数学
  - 线性代数
  - 矩阵论
mathjax: true
description: 机器学习的数学基础入门知识
swiper_index: 7
abbrlink: 47032
---

---



# 向量及其运算

## 基本概念

{% note success modern %}线性代数是多元函数微积分的基础{% endnote %}

> 定义

`向量(Vector)`是具有大小和方向的量，是由多个数构成的一维数组，每个数称为向量的分量，向量分量的数量称为向量的`维数`

> 向量的表示

物理中的力、速度以及加速度是典型的向量，$n$维向量$x$有$n$个分量，可以写成行向量的形式$(x_1 \cdots x_n)$

通常将向量写成**小写黑体斜体**字符，如果写成列的形式则称为列向量，这些分量在列方向排列
$$
\begin{bmatrix}
x_1 \\
\vdots \\
x_n
\end{bmatrix}
$$
这些向量的分量是实数，则成为实向量，如果是复数，则成为复向量，$n$维实向量的集合记为$\mathbb{R}^n$

与向量相对的是`标量(Scalar)`，标量只有大小而无方向，物理中的时间、质量以及电流是典型的标量

在数学中通常把向量表示成列向量，而计算机中通常按行存储

二维平面内的一个向量，其在$x$轴方向和$y$轴方向的分量分别为$3$和$1$，写成行向量形式为$\left[ \begin{matrix} 3 & 1 \end{matrix} \right]$

![二维平面内的向量](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/二维平面内的向量.webp)

图中的向量以虚线箭头表示，起点为原点，终点是以向量的分量为坐标的点，三维空间中的力是三维向量，写成向量形式为
$$
\left[ \begin{matrix} F_x & F_y & F_z \end{matrix} \right]
$$
力的加法遵守`平行四边形法则`

> 零向量

所有分量全为$0$的向量称为`零向量`，即为$0$，它的方向是不确定的

向量与空间的点是一一对应的，向量$x$是以原点为起点，以$x$点为终点

在机器学习中，样本数据通常用向量的形式表达，称为`特征向量(Feature Vectos)`，用于描述样本的特征

但是这里的特征向量和矩阵的特征向量是不同的概念，不要混淆



## 基本运算

`转置运算`(Transpose)将列向量变成行向量，将列向量转行向量，向量$x$的转置记为$x^T$
$$
\left[  
  \begin{matrix}
   1 & 0 & 0
  \end{matrix}
\right]^T = 
\left[  
  \begin{matrix}
   1 \\
   0 \\
   1
  \end{matrix} 
\right]
$$

> 加法

两个向量的加法定义为对应分量相加，要求参与运算的两个向量`维数相等`

向量$x$和$y$相加记为$x+y$，比如$\left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] + \left[ \begin{matrix} 4 & 0 & 1 \end{matrix} \right] = \left[ \begin{matrix} 5 & 2 & 4 \end{matrix} \right]$

这与力的加法的平行四边形法则一致，是其在高维空间的推广

![向量的加法](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/向量的加法.webp)

向量满足`交换律`和`结合律`
$$
x+y=y+x \qquad x+y+z=x+(y+z)
$$

> 减法

两个向量的减法为它们对应分量相减，同样要求参与运算的两个向量`维数相等`

与向量加法的平行四边形法则相对应，向量减法符合三角形法则，$x-y$的结果是以$y$为起点，以$x$为终点的向量

> 乘积

向量$x$与标量$k$的乘积$kx$定义为标量与向量的每个分量相乘，比如
$$
5 \times \left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] = \left[ \begin{matrix} 5 \times 2 & 5 \times 3 & 5 \times 1 \end{matrix} \right] = \left[ \begin{matrix} 10 & 15 & 5 \end{matrix} \right]
$$
乘积运算可以改变向量的大小和方向

加法和数乘满足分配律
$$
k(x+y) = kx + ky
$$

> 内积

两个向量$x$和$y$`内积(Inner Product)`定义为它们对应分量乘积之和
$$
x^{T}y = \sum _{i=1}^{n}{x_iy_i}
$$
内积可以记为$x \cdot y$
$$
\left[  
  \begin{matrix}
   1 \\
   2 \\
   3
  \end{matrix}
\right]^T
\left[  
  \begin{matrix}
   1 \\
   0 \\
   1
  \end{matrix}
\right] = 1 \times 1 + 2 \times 0 + 3 \times 1 = 4
$$
两个$n$维向量的内积运算需要执行$n$次乘法运算和$n-1$次加法运算

内积运算满足下面的规律
$$
x^Ty = y^Tx \qquad (kx)^Ty=kx^Ty \\ \qquad
(x+y)^Tz=x^T+y^Tz \qquad z^T(x+y)=z^Tx+z^Ty
$$
利用内积可以简化线性函数(一次函数)的表述

对于机器学习中广泛使用的线性模型的预测函数$\omega _1x_1 + \cdots \omega _nx_n + b$

定义系数(权重)向量$\omega = (\omega _1 \cdots \omega _n)^T$，输入向量$x = (x_1 \cdots x_n)^T$，$b$为偏置项，预测函数写成向量内积的话为
$$
\omega ^Tx + b
$$
向量与自身内积的结果为其所有分量的平方和，即$x^Tx=\sum _{i=1}^{n}{x_i^2}$

{% note primary modern %}两个向量的内积为$0$，则称它们`正交`{% endnote %}

正交是**几何垂直**这一概念在高维空间的推广
$$
\left[  
  \begin{matrix}
   1 \\
   0 \\
   0
  \end{matrix}
\right]^T
\left[  
  \begin{matrix}
   0 \\
   1 \\
   0
  \end{matrix}
\right] = 0
$$

> 阿达玛积

两个向量的`阿达玛(Hadamard)`积定义为它们对应分量相乘，结果为相同维数的向量，记为$x \odot y$

对于两个向量
$$
x = (x_1 \cdots x_n)^T \qquad y = (y_1 \cdots y_n)^T
$$
它们的阿达玛积为
$$
x \odot y = ({x_1}{y_1} \cdots {x_n}{y_n})^T
$$
阿达玛积可以简化问题的表述，在反向传播算法、各种梯度下降法中被使用

## 向量的范数

> 定义

向量的`范数(Norm)`是向量的模(长度)这一概念的推广，向量的$L-p$`范数是一个标量`，定义为
$$
||x||_p = (\sum _{i=1}^{n}{|x_i|^p})^{\frac {1}{p}}
$$
$p$为整数，常用的是$L1$和$L2$范数，$p$的取值分别为$1$和$2$



{% tabs 范数 %}
<!-- tab L1范数 -->

$L1$范数是所有分量的绝对值之和
$$
||x||_1 = \sum _{i=1}^{n}{|x|_i}
$$
对于向量$x = \left[ \begin{matrix} 1 & -1 & 2 \end{matrix} \right]$的$L1$范数为$||x||_1 = |1|+|-1|+|2| = 4$

<!-- endtab -->

<!-- tab L2范数 -->

$L2$范数也称为向量的模。即向量的长度，定义为
$$
||x||_p = \sqrt {\sum _{i=1}^{n}{|x_i|^2}}
$$
长度为$1$的向量称为单位向量，向量$x = \left[ \begin{matrix} 1 & -1 & 2 \end{matrix} \right]$的$L1$范数为$||x||_2 = \sqrt {1^2+(-1)^2+2^2} = \sqrt {6}$

$L1$范数和$L2$范数被用于构造机器学习的正则化项

向量范数默认指$L2$范数

<!-- endtab -->

<!-- tab 无穷范数 -->

当$p=\infty$时，称为$L - \infty$范数，其定义为
$$
||x||_{\infty} = max|x_i|
$$
即向量分量绝对值的最大值，向量$x = \left[ \begin{matrix} 1 & -1 & 2 \end{matrix} \right]$的$L1$范数为$||x||_1 = 2$

$L - \infty$范数是$L-p$范数的极限
$$
||x||_{\infty} = \lim _{p \rightarrow + \infty}{(\sum _{i=1}^{n}{|x_i|^p})^{\frac {1}{p}}}
$$
<!-- endtab -->

{% endtabs %}



> 性质

向量数乘之后的范数为$||kx|| = |k| \cdot ||x||$，显然有$x^Tx = ||x||_2^2$

对于非$0$向量，通过数乘向量模的倒数，可以将向量单位化(标准化)，使其长度为$1$

对于上面的$L2$范数，归一化之后为$\left[ \begin{matrix} \frac {1}{\sqrt 6} & \frac {-1}{\sqrt 6} & \frac {2}{\sqrt 6} \end{matrix} \right]$

> 向量内积和$L2$范数满足著名的`柯西-施瓦茨(Cauchy-Schwarz)`不等式

$$
x^Ty \leq ||x|| \cdot ||y||
$$

可以通过构造一元二次方程证明

由于$(x+ty)^T (x+ty) = y^Tyt^2 + 2x^Tyt + x^Tx \geq 0$

对于$t$的一元二次方程$y^Tyt^2+2x^Tyt+x^Tx = 0$，只有$x+ty=0$时才有实数解，根据二次方程的判别法则有
$$
\Delta = (2x^Ty - 4y^Tyx^Tx \leq 0)
$$
即$(x^Ty)^2 \leq ||x||^2 ||y||^2$，当且仅当$x+ty=0$即两个向量成比例时不等式取等号



> 向量内积、向量模与向量夹角之间的关系

可以表示为$x^Ty = ||x|| \cdot ||y|| \cdot cos \theta$

其中$\theta$为两个向量之间的夹角，其取值范围为$[0, \pi]$，变形后得到向量夹角计算公式
$$
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||}
$$
当向量之间的夹角超过$\frac {\pi}{2}$时，它们的内积为负

对于两个长度确定的向量，当夹角为$0$时它们的内积最大，此时$cos \theta=1$；夹角为$\pi$时它们的内积最小，此时$cos \theta=-1$

这一结论常在`梯度下降法`和`最速下降法`的推导中被使用

对于向量$x = \left[ \begin{matrix} 1 & 1 & 0 \end{matrix} \right]$、$y=\left[ \begin{matrix} 0 & 1 & 1 \end{matrix} \right]$，它们夹角的余弦为
$$
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||} = \frac {1 \times 0 + 1 \times 1 + 0 \times 1}{\sqrt {1^2+1^2+0^2} \times \sqrt {0^2+1^2+1^2} } = \frac {1}{2}
$$
因此它们的夹角为$\frac {\pi}{3}$

对于向量$x = \left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right]$、$y=\left[ \begin{matrix} 0 & 1 & 0 \end{matrix} \right]$，它们夹角的余弦为
$$
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||} = \frac {1 \times 0 + 0 \times 1 + 0 \times 0}{\sqrt {1^2+0^2+0^2} \times \sqrt {0^2+1^2+0^2} } = 0
$$
因此它们的夹角为$\frac {\pi}{2}$，两个向量正交，正好是$x$轴和$y$轴

> 范数满足三角不等式，是平面几何中三角不等式的抽象

$$
||x+y|| \leq ||x|| + ||y||
$$

将三角不等式两边同时平方，有
$$
||x+y||^2 = (x+y)^T(x+y) = x^Tx + 2x^Ty + y^Ty
$$
以及
$$
(||x||+||y||)^2 = ||x||^2 + 2||x||||u|| + ||y||^2 = x^Tx + 2 ||x|| ||y|| + y^Ty
$$

> 欧氏距离

两个向量相减之后的$L2$范数是它们对应的点之间的距离，称为`欧氏距离`，即$||x-y||$

对于三维空间中的两个点$x_1 = \left[ \begin{matrix} 1 & 2 & 1 \end{matrix} \right]$与$x_2 = \left[ \begin{matrix} 1 & 2 & 3 \end{matrix} \right]$，它们之间的距离为
$$
d = ||x_1 - x_2|| = \sqrt {(1-1)^2+(2-2)^2+(1-3)^2} = 2
$$
除了欧氏距离还可以定义其他的距离

{% note primary modern %}一个将两个向量映射为实数的函数$d(x_1,x_2)$只要满足下面的性质，均可以作为距离函数{% endnote %}

* **非负性**: 距离必须是非负的，对于$ \forall x_1,x_2 \in \mathbb {R}^n$，均有$d(x_1,x_2) \geq 0$
* **对称性**: 距离是对称的，对于$ \forall x_1,x_2 \in \mathbb {R}^n$，均有$d(x_1,x_2) = d(x_2, x_1)$
* **三角不等式**: 对于$ \forall x_1,x_2,x_3 \in \mathbb {R}^n$，均有$d(x_1,x_2) + d(x_2,x_3) \geq d(x_1, x_2)$

这些性质是欧式几何中距离特性的抽象

## 解析几何

> 定义

介绍下线性代数在解析几何中的应用，结论可以从二维平面和三维空间

平面解析几何中直线方程为$ax+by+x=0$，空间解析几何中平面方程为$ax+by+cz+d = 0$

将其推广到$n$维空间，得到`超平面(Hyperplane)`方程$\omega ^Tx+b = 0$

> 法向量

超平面中的$\omega$称为法向量，它与超平面内任意两个不同点之间连成的直线垂直

![平面的法向量](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/平面的法向量.webp)

图中黑色虚线为平面的法向量，它与平面垂直，对于平面内任意两点$x_1$和$x_2$，它们的连线(平面上虚线)均与法向量垂直

事实上，如果这两个点在平面内，则它们满足平面方程，有$\omega ^Tx_1 + b = 0$和$\omega ^Tx_2 + b = 0$

两式相减可以得到$\omega ^T(x_1-x_2) = 0$，因此法向量$\omega$与平面内任意两点之间的连线$x_1x_2$正交

将线性方程式的两侧同时乘以一个非$0$的系数，表示的还是同一个超平面

> 点到超平面的距离

{% tabs 点到超平面的距离 %}
<!-- tab 平面解析 -->

在平面解析几何中，点$(x,y)$到直接的距离为
$$
d = \frac {|ax+by+c|}{\sqrt {a^2+b^2}}
$$
<!-- endtab -->
<!-- tab 空间解析 -->

在空间解析几何中，点到平面的距离为
$$
d = \frac {|ax+by+cz+d|}{\sqrt {a^2+b^2+c^2}}
$$
<!-- endtab -->
<!-- tab 超平面 -->

将其推广到$n$维空间，根据向量内积和范数可以计算出点到超平面的距离，对于上面定义的超平面，点$x$到它的距离为
$$
d = \frac {|\omega ^Tx+b|}{||\omega||^2}
$$
这与二维平面、三维空间中点到直线和平面的距离公式在形式上是统一的，在支持向量机的推导过程中会用到

<!-- endtab -->

{% endtabs %}

计算点$\left[ \begin{matrix} 1 & 1 & 1 & 1 \end{matrix} \right]$到超平面$x_1-2x_2+x_3-3x_4+1=0$的距离
$$
d = \frac {|1-2 \times 1 + 1 - 3 \times 1 +1|}{\sqrt {1^2+(-2)^2+1^2+(-3)^2}} = \frac {2}{\sqrt {15}}
$$


## 线性相关性

> 线性相关

根据数乘和加法运算定义`线性组合`的概念，有向量组$x_1, \cdots ,x_l$，如果存在一组实数$k_1, \cdots ,k_l$使得
$$
x = k_1x_1 + \cdots k_lx_l 
$$
则称向量$x$可由向量组$x_1, \cdots ,x_l$线性表达

右侧称为向量组$x_1, \cdots ,x_l$的`线性组合`，$k_1, \cdots ,k_l$为`组合系数`

对于向量组

$x_1 = \left[ \begin{matrix} 1 & 2 & 3 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 & 0 & 2 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 & 0 & 1 \end{matrix} \right] $

向量$x= x_1+2_x2+x_3 = \left[ \begin{matrix} 3 & 2 & 8 \end{matrix} \right] $，可由该向量组线性表达，组合系数为$\left[ \begin{matrix} 1 & 2 & 1 \end{matrix} \right]$

对于向量组$x_1, \cdots ,x_l$，如果存在一组不全为$0$的数$kx_1, \cdots ,k_l$，使得
$$
k_1x_1+k_2x_2+ \cdots +k_lx_l = 0
$$
则称这组向量`线性相关`，如果不存在一组不全为$0$的数使得上式成立，则称为这组向量`线性无关`，也称为`线性独立`

> 线性无关

线性相关意味着这组向量存在冗余，至少有一个向量可以由其他向量线性表达，如果$x_1 \neq 0$，则有
$$
x_i = -\frac {\alpha _1}{\alpha _i}{x_1} - \cdots \frac {\alpha _{i-1}}{\alpha _i}{x_{i-1}} - \frac {\alpha _{i+1}}{\alpha _i}{x_{i+1}} - \frac {\alpha _{l}}{\alpha _i}{x_{l}}
$$
比如下面的行向量线性无关

$x_1 = \left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 0 & 1 & 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 & 0 & 1 \end{matrix} \right] $

给定组合系数$k_1$、$k_2$、$k_3$，有

$k_1 \left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] + k_2 \left[ \begin{matrix} 0 & 1 & 0 \end{matrix} \right] + k_3 \left[ \begin{matrix} 0 & 0 & 1 \end{matrix} \right] = \left[ \begin{matrix} k_1 & k_2 & k_3 \end{matrix} \right]$

欲使该向量为$0$，则有$k_1=k_2=k_3=0$，因此这组向量线性无关

下面的行向量线性相关，因为存在系数$\left[ \begin{matrix} 1 & 1 & -1 \end{matrix} \right]$是的向量为$0$

$x_1 = \left[ \begin{matrix} 1 & 1 & 0 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 2 & 2 & 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 3 & 3 & 0 \end{matrix} \right] $

> 极大线性无关组

一个向量组数量最大的线性无关向量子集称为`极大线性无关组`

给定向量组$$x_1, \cdots, x_l$$，如果$$x_{i_1},x_{i_2}, \cdots, x_{i_m}$$线性无关，但任意加入一个向量$$x_{i_{m+1}}$$之后线性相关

则$$x_{i_1},x_{i_2}, \cdots, x_{i_m}$$是极大线性无关组，`极大线性无关组不唯一`

$n$维向量的极大线性无关组最多有$n$个向量，这意味着任意一个向量均可以由$n$个线性无关的$n$维向量线性表达

## 向量空间

> 定义

有$n$维向量的集合$X$，如果在其上定义了加法和数乘运算，且对两种计算封闭，即运算结果仍属于此集合，则称$X$为`向量空间(Vector Sapce)`，也称为线性空间，对于任意的向量$x,y \in X$都有$x+y \in X \qquad kx \in X$，则集合$X$为向量空间

根据线性组合的定义，向量空间中任意向量的线性组合仍属于此空间

设$S$是向量空间$X$的子集，如果$S$对加法和数乘运算都封闭，则称$S$为$X$的`子空间`

例如，由三维实向量构成的集合$\mathbb {R}^3$是一个线性空间，显然对于任意$x,y \in \mathbb {R}^3$以及$k \in \mathbb {R}^3$，都有
$$
x+y \in \mathbb {R}^3 \qquad kx \in \mathbb {R}^3
$$
集合$S = \{ x \in \mathbb {R}^3, x_i > 0 \}$，即分量全为正的三维向量的集合不是线性空间，因为它对数乘不封闭

$S$中的向量$x$数乘一个负数，结果向量的分量为负，不再属于该集合

> 基(维数)

向量空间的极大线性无关组称为空间的`基`，基所包含的向量数称为空间的维数

如果$u_1, \cdots ,u_n$是空间的一组基，空间中的任意向量$x$均可由这组基线性表达$x = k_1u_1 + cdots + k_nu_n$

则$k_1, \cdots k_n$称为向量$x$在这组基下的坐标

> 正交基

如果基向量$u_1, \cdots ,u_n$相互正交
$$
u_i^Tu_j = 0, i \neq j
$$
则称为`正交基`，如果基向量相互正交且长度均为$1$
$$
u_i^Tu_j = 0, i \neq j \qquad  u_i^Tu_i = 0
$$
则称为`标准正交基`

向量组$\left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] \qquad \left[ \begin{matrix} 0 & 1 & 0 \end{matrix} \right] \qquad \left[ \begin{matrix} 0 & 0 & 1 \end{matrix} \right]$为$\mathbb {R}^3$的一组标准正交基，其方向对应三维空间的$3$个坐标轴方向

需要强调的是，空间的基和标准正交基不唯一

> 格拉姆-施密特(Gram-Schmidt)正交化

给定一组线性无关的向量，可以根据它们构造出标准正交基，用的是`格拉姆-施密特(Gram-Schmidt)正交化`

具体方法: 给定一组非$0$且线性无关的向量$x_1, \cdots ,x_l$，格拉姆-施密特正交化先构造出一组正交基$u_1, \cdots ,u_l$

然后将这组正交基进行标准化得到标准正交基$e_1, \cdots ,e_l$

首先选择向量$x_1$作为一个正交基方向，令$u_1=x_1$

然后加入$$x_2$$，构造$$u_1$$和$$x_2$$的线性组合，使得它与$$u_1$$正交，即$$u_2 = x_2 - \alpha_{21}u_1$$

由于$$u_2$$与$$u_1$$正交，因此有$$(x_2- \alpha _{21}u_1)^T u_1 = 0$$

解得$\alpha _{21} = \frac {x_2^Tu_1}{u_1^Tu_1}$

解释下这种做法的几何意义，由于$x_2^Tu_1 = ||x_2||||u_1|| cos \theta$

![通过向量投影构造垂直向量](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/通过向量投影构造垂直向量.webp)

因此$\frac {x_2^Tu_1}{||u_1||} = ||x_2|| cos \theta$就是$x_2$在$u_1$方向上投影向量的长度，是图中直角三角形$ABC$的直角边$AB$的长度，这里$x_2$是三角形的斜边$AC$

由于$\frac {u_1}{||u_1||}$是$u_1$方向的单位向量，$\frac {x_2^Tu_1}{||u_1||} \frac {u_1}{||u_1||} = \frac {x_2^Tu_1}{u_1^Tu_1} u_1$就是$x_2$在$u_1$方向上的投影向量，是图中的向量$AB$

根据向量减法的三角形法则，$x_2- \frac {x_2^Tu_1}{u_1^Tu_1} u_1$就是图中的向量$BC$，与$u_1$垂直

加下来加入$x_3$，构造出$u_3$，是$u_1$、$u_2$和$x_3$的线性组合，使得它与$u_1$及$u_2$均正交
$$
u_3 = x_3 - \alpha _{31} u_1 - \alpha _{31} u_2
$$
由于$u_3$与$u_1$正交，因此有
$$
(x_3- \alpha _{31} u_1 - \alpha _{32} u_2)^T_1 = 0
$$
而$$u_1$$与$$u_2$$正交，$$(\alpha _{32} u_2)^T u_1 = 0$$，因此可以解得$$\alpha _{31} = \frac {x_3^T u_1}{u_1^T u_1}$$

由于$u_3$与$u_2$正交，因此有
$$
(x_3 - \alpha _{31}u_1 - \alpha _{32}u_2 )^Tu_2 = 0
$$
而$$u_1$$与$$u_2$$正交，$$(\alpha _{31} u_1)^T u_2 = 0$$，因此可以解得$$\alpha _{32} = \frac {x_3^T u_2}{u_2^T u_2}$$

以此类推，在加入$x_k$时构造下面的线性组合
$$
u_k = x_k - \sum _{i=1}^{k-1}{\alpha _{ki}u_i}
$$
由于它与$$u_1, \cdots, u_{k-1}$$均正交，因此
$$
(x_k - \sum _{i=1}^{k-1}{\alpha _{ki} u_i})^Tu_j = 0, j=0, \cdots ,k-1
$$

而$u_j$与$u_i,i=1, \cdots, k-1 ,i \neq j$均正交，从而解得
$$
\alpha _{ki} = \frac {x_k^T u_i}{u_i^T u_i}
$$
反复执行上述步骤，可以得到一组正交基$u_1, \cdots , u_l$

将它们分别标准化，得到标准正交基$ \frac {u_1}{||u_1||} , \cdots , \frac {u_l}{||u_l||}$

> 格拉姆-施密特正交化的几何意义

首先考虑二维的情况

![二维平面的格拉姆-施密特正交化](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/二维平面的格拉姆-施密特正交化.webp)

图中向量$\frac {x_2^Tu_1}{u_1^Tu_1}u_1$与$u_1$同向，是向量$x_2$在$x_1$方向的投影，显然$x_2$减掉该投影之后的向量，即向量$u_2$，与$u_1$垂直

下面考虑三维的情况

首先构造出$u_2$，与二维平面的方法相同，保证$u_2$与$u_1$垂直，然后处理$x_3$，首先减掉其在$u_1$方向的投影，保证相减之后与$u_1$垂直，然后减掉在$u_2$方向的投影，保证与$u_2$垂直

![三维空间的格拉姆-施密特正交化](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/三维空间的格拉姆-施密特正交化.webp)

下面举例说明，有如下的向量组
$$
x_1 = \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 \\ 1 \\ 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 \\ 1 \\ 1 \end{matrix} \right]
$$
首先生成$u_1=x_2= \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right]$

然后生成$u_2$，组合系数为
$$
\alpha _{21} = \frac {x_2^T u_1}{x_1^T u_1} = \frac {1 \times 1 + 0 \times 1 + 1 \times 0}{1^2+0^2+1^2} = \frac {1}{2}
$$
因此
$$
u_2 = x_2 - \alpha _{21}u_1 = \left[ \begin{matrix} 1 \\ 1 \\ 0 \end{matrix} \right] - \frac {1}{2} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] = \frac {1}{2}\left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right]
$$
最后生成$u_3$，组合系数为
$$
\alpha _{31} = \frac {x_3^Tu_1}{u_1^Tu_1} = \frac {1 \times 0 + 0 \times 1 + 1 \times 1}{1^2+0^2+1^2} = \frac {1}{2}
$$
以及
$$
\alpha _{32} = \frac {x_3^Tu_2}{u_2^Tu_2} = \frac {\frac {1}{2} ( 1 \times 0 + 2 \times 1 + (-1) \times 1)}{ \frac {1}{4} (1^2+2^2+(-1)^2)} = \frac {1}{3}
$$
因此
$$
u_3= x_3- \alpha_{31} u_1 - \alpha _{32}u_2 = \left[ \begin{matrix} 0 \\ 1 \\ 1 \end{matrix} \right] - \frac {1}{2} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] - \frac {1}{3} \times \frac {1}{2} \left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right] = \frac {2}{3} \left[ \begin{matrix} -1 \\ 1 \\ 1 \end{matrix} \right]
$$
最后对$u_1$、$u_2$和$u_3$进行单位化
$$
e_1 = \frac {u_1}{||u_1||}=\frac {1}{\sqrt {2}} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] \qquad 
e_1 = \frac {u_2}{||u_2||}=\frac {1}{\sqrt {6}} \left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right] \qquad 
e_1 = \frac {u_3}{||u_3||}=\frac {1}{\sqrt {3}} \left[ \begin{matrix} -1 \\ 1 \\ 1 \end{matrix} \right]
$$
即为一组标准正交基


## 应用之线性回归

## 应用之线性分类器与支持向量机



# 矩阵及其运算

## 基本概念

> 定义

`矩阵`$A$是二维数组，一个$m \times n$的矩阵有$m$行和$n$列，每个位置$(i,j)$处的元素$a_{i,j}$是一个数，记为
$$
\left[ 
\begin{matrix} 
a_{11} & \cdots & a_{an} \\ 
\vdots & \ddots & \vdots \\ 
a_{m1} & \cdots & a_{mn} 
\end{matrix} 
\right]
$$
矩阵通常用大写的黑体、斜体字母表示

矩阵的元素可以是实数，称为`实矩阵`，元素为复数，称为`复矩阵`，全体$m \times n$实矩阵的集合记为$\mathbb R ^{m \times n}$

> 方阵

如果矩阵行数和列数相等，则称为`方阵`，$n \times n$的方阵称为$n$阶方阵

> 对称矩阵

如果一个方阵的元素满足$$a_{ij} = a_{ji}$$，则称为`对称矩阵`，比如
$$
\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
2 & 2 & 0 \\ 
3 & 0 & 4
\end{matrix} 
\right]
$$

> 对角矩阵

矩阵所有行号和列号相等的元素$a_{ii}$的全体称为`主对角线`，如果一个矩阵出主对角线之外所有的元素均为$0$，则称为`对角矩阵`
$$
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 2 & 0 \\ 
0 & 0 & 4
\end{matrix} 
\right]
$$
该对角矩阵可以简记为$diag(1,2,3)$，通常将对角矩阵记为$A$

> 单位矩阵

如果矩阵的主对角线的元素为$1$，其他元素为$0$，则称为`单位矩阵`，记为$I$
$$
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1
\end{matrix} 
\right]
$$
单位矩阵的作用类似于实数中的$1$，在矩阵乘法中会说明，$n$阶单位矩阵记为$I_n$

> 零矩阵

如果矩阵的所有元素都为$0$，则称为`零矩阵`，记为**$0$**，其作用类似于实数中的$0$

> 上三角矩阵

如果矩阵的主对角线下方的元素全为$0$，则称为`上三角矩阵`
$$
\left[ 
\begin{matrix} 
1 & 1 & 0 \\ 
0 & 2 & 1 \\ 
0 & 0 & 3
\end{matrix} 
\right]
$$

> 下三角矩阵

如果矩阵的主对角线上方的元素全为$0$，则称为`下三角矩阵`
$$
\left[ 
\begin{matrix} 
1 & 1 & 0 \\ 
4 & 2 & 0 \\ 
6 & 5 & 3
\end{matrix} 
\right]
$$

> 格拉姆(Gram)矩阵

一个向量组$$x_1, \cdots , x_n$$的`格拉姆(Gram)矩阵`是一个$n \times  n$的矩阵，其每一个矩阵元素$$G_{ij}$$为向量$$x_i$$与$$x_j$$的内积，即
$$
G = \left[ 
\begin{matrix} 
x_1^Tx_1 & x_1^Tx_2 & \cdots & x_1^Tx_n \\ 
x_2^Tx_1 & x_2^Tx_2 & \cdots & x_2^Tx_n \\ 
\vdots & \vdots & \ddots & \vdots \\ 
x_n^Tx_1 & x_n^Tx_3 & \cdots & x_n^Tx_n
\end{matrix} 
\right]
$$
由于$x_i^Tx_j = x_j^Tx_i$，因此格拉姆矩阵是一个对称矩阵

对于向量$$x_1 = \left[ \begin{matrix} 1 & 2 & 3 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 & 0 & 1 \end{matrix} \right]$$，其格拉姆矩阵为

$$
 G = \left[ \begin{matrix} x_1^Tx_1 & x_1^Tx_2 \\ x_2^Tx_1 & x_2^Tx_2 \end{matrix} \right] = \left[ \begin{matrix} 14 & 4 \\ 4 & 2 \end{matrix} \right]
$$
在机器学习中该矩阵常被使用，比如主成分分析、核主成分分析、线性判别分析、线性回归、logisitic回归以及支持向量机的推导和证明

## 基本运算

> 转置

矩阵的`转置(Transpose)`定义为行和列下标相互交换，一个$m \times n$的矩阵转置之后为$n \times m$的矩阵，矩阵$A$的转置记为$A^T$
$$
\left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right]^T = \left[ \begin{matrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{matrix} \right]
$$

> 加法

矩阵的加法为对应位置的元素相加，需要保证两个矩阵有相同的尺寸，矩阵$A$和$B$相加记为$A+B$
$$
\left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] + 
\left[ \begin{matrix} 7 & 8 & 9 \\ 10 & 11 & 12 \end{matrix} \right] = 
\left[ \begin{matrix} 8 & 10 & 12 \\ 14 & 16 & 18 \end{matrix} \right]
$$
加法和转置满足$(A+B)^T = A^T+B^T$

加法满足交换律和结合律$A+B=B+A \qquad A+B+C = A+(B+C)$

> 数乘

矩阵和标量的乘法即`数乘`，定义为标量和矩阵每个元素相乘，矩阵$A$和$k$数乘记为$kA$
$$
5 \times \left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] = \left[ \begin{matrix} 5 & 10 & 15 \\ 20 & 25 & 30 \end{matrix} \right]
$$
数乘和加法满足分配律$k(A+B) = kA + kB$

> 乘法

矩阵`乘法`定义为第一个矩阵的每个行向量和第二个矩阵的每个列向量做**内积**，形成结果矩阵的每个元素，矩阵相乘记为$AB$

要求第一个矩阵的列数要等于第二个矩阵的行数

结果矩阵第$i$行第$j$列位置处的元素为$A$的第$i$行与$B$的第$j$列的内积$$\sum _{k=1}^{p}{a_{ip}b_{pj}}$$
$$
\left[ \begin{matrix} 1 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] \times
\left[ \begin{matrix} 0 & 1 \\ 0 & 0 \\ 1 & 0 \end{matrix} \right] = 
\left[ \begin{matrix} 1 \times 0 + 1 \times 0 + 0 \times 1 & 1 \times 1 + 1 \times 0 + 0 \times 0 \\ 0 \times 0 + 0 \times 0 + 1 \times 1  & 0 \times 1 + 0 \times 0 + 1 \times 0 \end{matrix} \right] =
\left[ \begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix} \right]
$$
结果矩阵的每个元素需要$p$次乘法运算、$p-1$次加法运算得到，结果矩阵有$m \times n$个元素

因此，矩阵乘法需要$m \times n \times p$次乘法和$m \times n \times (p-1)$次加法

使用矩阵乘法可以简化线性方程组的表述，对于如下的线性方程组
$$
\begin{cases} a_{11}x_1 + a_{12}x_2 +\cdots + a_{1n}x_n = b_1 \\
\vdots \\
a_{n11}x_1 + a_{n2}x_2 +\cdots + a_{nn}x_n = b_n
\end{cases} 
$$
定义系数矩阵为
$$
A = \left[ 
\begin{matrix} 
a_{11} & \cdots & x_{1n} \\ 
\vdots & \ddots & \vdots \\ 
x_{n1} & \cdots & x_{nn}
\end{matrix} 
\right]
$$
定义解向量和常数向量为
$$
x = \left[ 
\begin{matrix} 
x_{1} \\ 
\vdots \\ 
x_{n}
\end{matrix} 
\right]

\qquad

b = \left[ 
\begin{matrix} 
b_{1} \\ 
\vdots \\ 
b_{n}
\end{matrix} 
\right]
$$
既可以将方程组写成矩阵的形式$Ax=b$

这种表示可以与一元一次方程$ax=b$达成形式上的统一，系数矩阵和常数向量合并之后称为`增广矩阵`，比如以上的增广矩阵为
$$
A = \left[ 
\begin{matrix} 
a_{11} & \cdots & x_{1n} & b_1 \\ 
\vdots & \ddots & \vdots & \vdots \\ 
x_{n1} & \cdots & x_{nn} & b_n
\end{matrix} 
\right]
$$

> 阿达玛积

矩阵的阿达玛积定义为对应位置元素乘积形成的矩阵，记为$A \odot B$

> 矩阵分块表示

对于下面的矩阵
$$
A =
\left[ 
\begin{matrix} 
1 & 1 & 3 & 4 & 0 & 0 & 0 \\ 
5 & 6 & 7 & 8 & 0 & 0 & 0 \\ 
9 & 10 & 11 & 12 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 1 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 0 & 1 \\ 
0 & 0 & 0 & 0 & 1 & 1 & 1
\end{matrix} 
\right]
$$
可以将其分块为
$$
A =
\left[ 
\begin{matrix} 
A_{11} & A_{12} \\ 
A_{21} & A_{22}
\end{matrix} 
\right]
$$
其中
$$
A_{11} =
\left[ 
\begin{matrix} 
1 & 1 & 3 & 4\\ 
5 & 6 & 7 & 8\\ 
9 & 10 & 11 & 12
\end{matrix} 
\right]

\qquad

A_{12} =
\left[ 
\begin{matrix} 
0 & 0 & 0 \\ 
0 & 0 & 0 \\ 
0 & 0 & 0 
\end{matrix} 
\right]
$$

$$
A_{11} =
\left[ 
\begin{matrix} 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0
\end{matrix} 
\right]

\qquad

A_{12} =
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1 \\ 
1 & 1 & 1
\end{matrix} 
\right]
$$

如果矩阵的`子矩阵`为$0$矩阵，或者单位矩阵等特殊类型的矩阵，这边表示会非常有效

如果矩阵$A,B$分块后各块的尺寸以及水平、垂直方向的块数量相容，那可以将块当做标量来计算乘积$AB$
$$
\left[ 
\begin{matrix} 
A_{11} & \cdots & A_{1s} \\ 
\vdots & \ddots & \vdots \\ 
A_{r1} & \cdots & A_{ns}
\end{matrix} 
\right]

\qquad

\left[ 
\begin{matrix} 
B_{11} & \cdots & B_{1t} \\ 
\vdots & \ddots & \vdots \\ 
B_{s1} & \cdots & B_{st}
\end{matrix} 
\right]
$$
如果各个位置处对应的两个字块尺寸相容，那么可以进行矩阵乘积运算
$$
AB = 
\left[ 
\begin{matrix} 
\sum_{i=1}^{s}{A_{1i}B_{i1}} & \cdots & \sum_{i=1}^{s}{A_{1i}B_{it}} \\ 
\vdots & \ddots & \vdots \\ 
\sum_{i=1}^{s}{A_{ri}B_{i1}} & \cdots & \sum_{i=1}^{s}{A_{ri}B_{it}}
\end{matrix} 
\right]
$$
🌰举个分块乘法的例子
$$
A =
\left[ 
\begin{matrix} 
1 & 0 & 0 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 0 \\ 
-1 & 2 & 1 & 0 & 0 \\ 
1 & 1 & 0 & 1 & 0 \\ 
-2 & 0 & 0 & 0 & -1
\end{matrix} 
\right]

\qquad

B =
\left[ 
\begin{matrix} 
3 & 2 & 0 & 1 & 0 \\ 
1 & 3 & 0 & 0 & 1 \\ 
-1 & 0 & 0 & 0 & 0 \\ 
0 & -1 & 0 & 0 & 0 \\ 
0 & 0 & -1 & 0 & 0
\end{matrix} 
\right]
$$
将$A$分为4块
$$
A = 
\left[ 
\begin{matrix} 
I_{2} & 0_{2 \times 3} \\ 
A_{1} & I_{3}
\end{matrix} 
\right]

\qquad

A1 = 
\left[ 
\begin{matrix} 
-1 & 2 \\ 
1 & 1 \\ 
-2 & 0
\end{matrix} 
\right]
$$
将$B$分块为
$$
B = 
\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
-I_{3} & 0_{3 \times 2}
\end{matrix} 
\right]

\qquad

B1 = 
\left[ 
\begin{matrix} 
3 & 2 & 0 \\ 
1 & 3 & 0
\end{matrix} 
\right]
$$
因此它们的乘积为
$$
AB =

\left[ 
\begin{matrix} 
I_{2} & 0_{2 \times 3} \\ 
A_{1} & I_{3}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
-I_{3} & 0_{3 \times 2}
\end{matrix} 
\right]
= 

\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
A_{1}B_{1}-I_3 & A_{1}
\end{matrix} 
\right]
$$


其中
$$
A_{1}B_{1}-I_3 = 

\left[ 
\begin{matrix} 
-1 & 2 \\ 
1 & 1 \\ 
-2 & 0
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
3 & 2 & 0 \\ 
1 & 3 & 0
\end{matrix} 
\right]

-

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 1
\end{matrix} 
\right]
$$
因此
$$
AB =

\left[ 
\begin{matrix} 
3 & 2 & 0 & 1 & 0 \\ 
1 & 3 & 0 & 0 & 1 \\ 
-2 & 4 & 0 & -1 & -2 \\ 
4 & 4 & 0 & 1 & 0 \\ 
-6 & -4 & -1 & -2 & 0
\end{matrix} 
\right]
$$
在多态正态分布中，将会对协方差矩阵进行分块

> 特性

1️⃣单位矩阵与任意矩阵的左乘和右乘都等于该矩阵本身，即
$$
IA = A = AI
$$
2️⃣矩阵$A$左乘对角矩阵$\Lambda = diag(k_1, \cdots, k_n)$相当于将$A$的第$i$行的所有元素都乘以$k_i$
$$
\left[ 
\begin{matrix} 
k_{1} & 0 & \cdots & 0 \\ 
0 & k_{2} & \cdots & 0 \\ 
\cdots & \cdots & \cdots & \cdots \\ 
0 & 0 & \cdots & k_{n}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\ 
a_{21} & a_{22} & \cdots & a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
k_1a_{11} & k_1a_{12} & \cdots & k_1a_{1n} \\ 
k_2a_{21} & k_2a_{22} & \cdots & k_2a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
k_na_{n1} & k_na_{n2} & \cdots & k_na_{nn}
\end{matrix} 
\right]
$$
3️⃣矩阵$A$右乘对角矩阵$\Lambda = diag(k_1, \cdots, k_n)$相当于将$A$的第$i$列的所有元素都乘以$k_i$
$$
\left[ 
\begin{matrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\ 
a_{21} & a_{22} & \cdots & a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
k_{1} & 0 & \cdots & 0 \\ 
0 & k_{2} & \cdots & 0 \\ 
\cdots & \cdots & \cdots & \cdots \\ 
0 & 0 & \cdots & k_{n}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
k_1a_{11} & k_2a_{12} & \cdots & k_na_{1n} \\ 
k_1a_{21} & k_2a_{22} & \cdots & k_na_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
k_1a_{n1} & k_2a_{n2} & \cdots & k_na_{nn}
\end{matrix} 
\right]
$$
4️⃣向量组$$x_1, x_2, \cdots, x_n$$的格拉姆矩阵可以写成一个矩阵与其转置的乘积
$$
G = \left[ 
\begin{matrix} 
x_{1}^T \\ 
\vdots \\ 
x_{n}^T
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
x_{1} & \cdots & x_{n}
\end{matrix} 
\right]

= X^TX
$$
其中$$X=\left[ \begin{matrix} x_{1} & \cdots & x_{n} \end{matrix} \right]$$是所有向量按列形成的矩阵

5️⃣矩阵的乘法满足结合律
$$
(AB)C = A(BC)
$$
这些由标量乘法的结合律可推得

6️⃣矩阵乘法和加法满足左分配律和右分配律
$$
A(B+C) = AB+AC \qquad (A+B)C=AC+BC
$$
注意矩阵的乘法不满足交换律，即一般情况下$AB \neq BA$

7️⃣矩阵乘法和转置满足`穿脱原则`
$$
(AB)^T = B^TA^T
$$

## 逆矩阵

> 定义

`逆矩阵`对应标量的倒数运算，对于$n$阶矩阵$A$，如果存在另一个$n$阶矩阵$B$，使得它们的乘积为单位矩阵
$$
AB=I \qquad BAI
$$
对于$AB=I$，$B$称为$A$的右逆矩阵，对于$BA=I$，$B$称为$A$的左逆矩阵

> 如果矩阵的左逆矩阵和右逆矩阵存在，则它们相等，统称为矩阵的逆，记为$A^{-1}$

假设$B_1$是$A$的左逆，$B_2$是$A$的右逆，则有
$$
B_1AB_2 = (B_1A)B_2=IB_2=B_2 \qquad B_1AB_2=B_1(AB_2)=B_1I=B_1
$$
因此$B_1=B_2$

> 非奇异矩阵和奇异矩阵

如果矩阵的逆矩阵存在，则称其`可逆(Invertable)`。可逆矩阵也称为`非奇异矩阵`，不可逆矩阵也称为`奇异矩阵`

> 如果矩阵可逆，则其逆矩阵唯一

假设$B$和$C$都是$A$的逆矩阵，则有$AB=BA=I$和$AC=CA-I$

从而有$CAB=(CA)B=IB=B$和$CAB=C(AB)=CI=C$，因此B=C

对于线性方程组，如果能得到系数矩阵的逆矩阵，方程两边同乘以该逆矩阵，可以得到方程的解
$$
A^{-1}Ax = A^{-1}b \Rightarrow x=A^{-1}b
$$
这与一元一次方程的求解形式上是统一的$ax=b \Rightarrow x=a^{-1b}$

> 如果对角矩阵$A$的主对角线非$0$，则其逆矩阵存在，且逆矩阵为对角矩阵，主对角线元素为矩阵$A$的主对角线元素的逆

$$
\left[ 
\begin{matrix} 
a_{11} & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & a_{nn}
\end{matrix} 
\right] ^{-1}

= 
\left[ 
\begin{matrix} 
a_{11}^{-1} & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & a_{nn}^{-1}
\end{matrix} 
\right]
$$

可以推出，上三角矩阵的逆矩阵仍然是上三角矩阵
$$
(AB)^{-1} = B^{-1}A^{-1} \qquad (A^{-1})^{-1} = A
$$

$$
(A^T)^{-1} = (A^{-1})^T  \qquad (\lambda A)^{-1} = \lambda ^{-1} A^{-1}
$$

第1个等式与矩阵乘法的转置类似
$$
(AB)(B^{-1}A^{-1}) = ABB^{-1}A^{-1} = A(BB^{-1})A^{-1} = AIA^{-1} = AA^{-1} = I
$$
因此第1个等式成立，这里利用了矩阵乘法的结合律

由于$AA^{-1}=I$根据逆矩阵的定义，第2个等式成立

由于$(A^{-1})^TA^T = (AA^{-1})^T = I^T = I$根据逆矩阵的定义，第3个等式成立

该等式可以证明对称矩阵的逆矩阵也是对称矩阵，用类似的方法可以证明第4个等式成立

> 矩阵的秩

矩阵的`秩`定义为矩阵线性无关的行向量或列向量的最大数量，记为$r(A)$
$$
\left[ 
\begin{matrix} 
1 & 2 & 0 & 0 \\ 
1 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0
\end{matrix} 
\right]
$$
该矩阵秩为$2$，该矩阵的极大线性无关组为矩阵的前两个行向量或列向量

如果$n$阶方阵的秩为$n$，则称其`满秩`，矩阵可逆的充分必零条件是满秩

对于$m \times n$的矩阵$A$，其秩满足$r(A) \leq min(m,n)$，即矩阵的秩不超过其行数和列数的较小值

> 矩阵的秩相关结论

$$
r(A) = r(A^T) \qquad r(A+B) \leq r(A)+r(B) \qquad r(AB) \leq min(r(A),r(B))
$$

> 初等行变换

所谓矩阵的初等行变换是指以下3种变换

1. 用一个非零的数$k$乘矩阵的某一行
   $$
   \left[ 
   \begin{matrix} 
   1 & 2 & 3 \\ 
   4 & 5 & 6 \\ 
   7 & 8 & 9
   \end{matrix} 
   \right]
   
   \overset {r_1 \times 2}{\longrightarrow}
   
   \left[ 
   \begin{matrix} 
   2 & 4 & 6 \\ 
   4 & 5 & 6 \\ 
   7 & 8 & 9
   \end{matrix} 
   \right]
   $$

2. 把矩阵的某一行的$k$倍加到另一行，这里的$k$是任意实数
   $$
   \left[ 
   \begin{matrix} 
   1 & 2 & 3 \\ 
   4 & 5 & 6 \\ 
   7 & 8 & 9
   \end{matrix} 
   \right]
   
   \overset {r_2 + r_1 \times 2}{\longrightarrow}
   
   \left[ 
   \begin{matrix} 
   1 & 2 & 3 \\ 
   6 & 9 & 12 \\ 
   7 & 8 & 9
   \end{matrix} 
   \right]
   $$
   
3. 互换矩阵的两行
   $$
   \left[ 
   \begin{matrix} 
   1 & 2 & 3 \\ 
   4 & 5 & 6 \\ 
   7 & 8 & 9
   \end{matrix} 
   \right]
   
   \overset {r_2 \leftrightarrow r_3 }{\longrightarrow}
   
   \left[ 
   \begin{matrix} 
   1 & 2 & 3 \\ 
   7 & 8 & 9 \\
   4 & 5 & 6
   \end{matrix} 
   \right]
   $$

🌴`初等变换`是单位矩阵$I$经过一次初等变换之后得到的矩阵

1. 对于第一种初等行变化，对应的初等矩阵和逆矩阵分别如下，这意味着将单位矩阵的第$i$行乘以$k$，然后再乘以$\frac{1}{k}$，将变为单位矩阵
   $$
   \left[ 
   \begin{matrix} 
   1 &   &   &   &   &   &   \\ 
    & \ddots  &   &   &   &   &   \\ 
    &   & 1 &   &   &   &   \\ 
    &   &   & k &   &   &   \\ 
    &   &   &   & 1 &   &   \\ 
    &   &   &   &   & \ddots &   \\ 
    &   &   &   &   &   & 1 
   \end{matrix} 
   \right]
   
   \qquad
   
   \left[ 
   \begin{matrix} 
   1 &   &   &   &   &   &   \\ 
    & \ddots  &   &   &   &   &   \\ 
    &   & 1 &   &   &   &   \\ 
    &   &   & \frac{1}{k} &   &   &   \\ 
    &   &   &   & 1 &   &   \\ 
    &   &   &   &   & \ddots &   \\ 
    &   &   &   &   &   & 1 
   \end{matrix} 
   \right]
   $$

2. 对于第二种初等行变化，对应的初等矩阵和逆矩阵分别如下，意味着将单位矩阵的第$i$行乘以$k$之后加到第$j$行，然后再将第$i$行乘以$-k$之后加到第$j$行，将变为单位矩阵
   $$
   \left[ 
   \begin{matrix} 
   1 &   &   &   &   &   &   \\ 
    & \ddots  &   &   &   &   &   \\ 
    &   & 1 &   &   &   &   \\ 
    &   & \vdots & k &   &   &   \\ 
    &   & k & \cdots & 1 &   &   \\ 
    &   &   &   &   & \ddots &   \\ 
    &   &   &   &   &   & 1 
   \end{matrix} 
   \right]
   
   \qquad
   
   \left[ 
   \begin{matrix} 
   1 &   &   &   &   &   &   \\ 
    & \ddots  &   &   &   &   &   \\ 
    &   & 1 &   &   &   &   \\ 
    &   & \vdots & k &   &   &   \\ 
    &   & -k & \cdots & 1 &   &   \\ 
    &   &   &   &   & \ddots &   \\ 
    &   &   &   &   &   & 1 
   \end{matrix} 
   \right]
   $$

3. 对于第三种初等行变化，对应的初等矩阵和逆矩阵相等，这意味着，将单位矩阵的第$i$行和$j$行互换，然后再互换一次，将变为单位矩阵
   $$
   \left[ 
   \begin{matrix} 
   1 &   &   &   &   &   &   \\ 
    & \ddots  &   &   &   &   &   \\ 
    &   & 0 & \cdots & 1 &   &   \\ 
    &   & \vdots & \ddots & \vdots &   &   \\ 
    &   & 1 & \cdots & 0 &   &   \\ 
    &   &   &   &   & \ddots &   \\ 
    &   &   &   &   &   & 1 
   \end{matrix} 
   \right]
   $$

4. 

🍒对矩阵做初等变换，等价于左乘对应的初等矩阵

1. 对于第一种行变换
   $$
   \left[ 
   \begin{matrix} 
   1 & 0 & 0 \\ 
   0 & k & 0 \\
   0 & 0 & 1
   \end{matrix} 
   \right]
   
   \left[ 
   \begin{matrix} 
   a_{11} & a_{12} & a_{13} \\ 
   a_{21} & a_{22} & a_{23} \\
   a_{31} & a_{32} & a_{33}
   \end{matrix} 
   \right]
   
   =
   
   \left[ 
   \begin{matrix} 
   a_{11} & a_{12} & a_{13} \\ 
   ka_{21} & ka_{22} & ka_{23} \\
   a_{31} & a_{32} & a_{33}
   \end{matrix} 
   \right]
   $$

2. 对于第二种行变换
   $$
   \left[ 
   \begin{matrix} 
   1 & 0 & 0 \\ 
   0 & 1 & 0 \\
   0 & k & 1
   \end{matrix} 
   \right]
   
   \left[ 
   \begin{matrix} 
   a_{11} & a_{12} & a_{13} \\ 
   a_{21} & a_{22} & a_{23} \\
   a_{31} & a_{32} & a_{33}
   \end{matrix} 
   \right]
   
   =
   
   \left[ 
   \begin{matrix} 
   a_{11} & a_{12} & a_{13} \\ 
   a{21} & a_{22} & a_{23} \\
   a_{31}+ka_{21} & a_{32}+ka_{22} & a_{33}+ka_{23}
   \end{matrix} 
   \right]
   $$

3. 对于第三种行变换
   $$
   \left[ 
   \begin{matrix} 
   0 & 1 & 0 \\ 
   1 & 0 & 0 \\
   0 & 0 & 1
   \end{matrix} 
   \right]
   
   \left[ 
   \begin{matrix} 
   a_{11} & a_{12} & a_{13} \\ 
   a_{21} & a_{22} & a_{23} \\
   a_{31} & a_{32} & a_{33}
   \end{matrix} 
   \right]
   
   =
   
   \left[ 
   \begin{matrix} 
   a_{21} & a_{22} & a_{23} \\
   a_{11} & a_{12} & a_{13} \\ 
   a_{31} & a_{32} & a_{33}
   \end{matrix} 
   \right]
   $$

4. 

> 初等行变换计算逆矩阵

如果矩阵$A$可逆，则可以利用初等行变换将其变换为单位矩阵，对应于一次左乘初等矩阵$P1,P2,\cdots,P_s$
$$
P_s \cdots P_2P_! A = I
$$
两侧同时右乘$A^{-1}$可以得到$$P_s \cdots P_2P_! I = A^{-1}$$

这意味着同样的初等行变换序列，在将矩阵$A$化为单位矩阵的同时，可将矩阵$I$化为$A^{-1}$，这就是逆矩阵

🌰用初等行变换求解$A$的逆矩阵
$$
A =

\left[ 
\begin{matrix} 
2 & 3 & 1 \\ 
0 & 1 & 3 \\
1 & 2 & 5
\end{matrix} 
\right]
$$
求解过程如下
$$
\left[ \begin{matrix} A & I\end{matrix} \right]
=

\left[ 
\begin{matrix} 
2 & 3 & 1 & 1 & 0 & 0 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
1 & 2 & 5 & 0 & 0 & 1
\end{matrix} 
\right]

\overset {r_1与r_3互换 }{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
2 & 3 & 1 & 1 & 0 & 0
\end{matrix} 
\right]

\overset {r_3-2 \times r_1 }{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & -1 & -9 & 1 & 0 & -2
\end{matrix} 
\right]
$$

$$
\overset {r_3+r_2}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & 0 & -6 & 1 & 1 & -2
\end{matrix} 
\right]

\overset {r_3 \times (-\frac{1}{6})}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]


\overset {r_2 - r_3 \times 3}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]
$$

$$
\overset {r_1 - r_3 \times 5}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 0 & \frac{5}{6} & \frac{5}{6} & -\frac{2}{3} \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]

\overset {r_1 - r_2 \times 2}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 1 & 0 & -\frac{1}{6} & -\frac{13}{6} & \frac{4}{3} \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]
$$

> python的linalg库中的inv函数实现了逆矩阵的计算

```python
import numpy as np
A = np.array([[1,0,0], [0,1,0], [0,0,5]])
B = np.linalg.inv(A)
```

$$
A^{-1} =

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 5
\end{matrix} 
\right]^{-1}

=

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 0.2
\end{matrix} 
\right]
$$

> 正交矩阵

如果一个方阵满足
$$
AA^T=A^TA=I
$$
则称为正交矩阵，正交矩阵的行向量均为单位向量且`相互正交`，构成`标准正交基`，对于矩阵按行分块，有


$$
A A^{\mathrm{T}}=\left(\begin{array}{c}
a_{1} \\
a_{2} \\
\vdots \\
a_{n}
\end{array}\right)\left(\begin{array}{llll}
a_{1}^{\mathrm{T}} & a_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{n}^{\mathrm{T}}
\end{array}\right)=\left(\begin{array}{cccc}
\boldsymbol{a}_{1} a_{1}^{\mathrm{T}} & \boldsymbol{a}_{1} \boldsymbol{a}_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{1} a_{n}^{\mathrm{T}} \\
\boldsymbol{a}_{2} a_{1}^{\mathrm{T}} & a_{2} a_{2}^{\mathrm{T}} & \cdots & a_{2} a_{n}^{\mathrm{T}} \\
\vdots & \vdots & & \vdots \\
a_{n} a_{1}^{\mathrm{T}} & \boldsymbol{a}_{n} \boldsymbol{a}_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{n} a_{n}^{\mathrm{T}}
\end{array}\right)=\left(\begin{array}{cccc}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 1
\end{array}\right)
$$
因此有
$$
\begin{array}{l}
a_{i} a_{i}^{\mathrm{T}}=1 \\
a_{i} a_{j}^{\mathrm{T}}=0, i \neq j
\end{array}
$$

* 如果一个矩阵是正交矩阵，根据逆矩阵的定义，有

$$
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}}
$$

下面是一个正交矩阵的例子
$$
\left(\begin{array}{cc}
\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
\end{array}\right)
$$
可以验证其行向量和列向量均为单位向量，且相互正交

* 正交矩阵的乘积仍然是正交矩阵，如果

$$
\begin{array}{l}
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}} \\
\boldsymbol{B}^{-1}=\boldsymbol{B}^{\mathrm{T}}
\end{array}
$$

则
$$
(\boldsymbol{A B})^{-1}=\boldsymbol{B}^{-1} \boldsymbol{A}^{-1}=\boldsymbol{B}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}=(\boldsymbol{A B})^{\mathrm{T}}
$$

* 正交矩阵的逆矩阵仍然是正交矩阵。如果有

$$
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}}
$$

则
$$
\left(\boldsymbol{A}^{-1}\right)^{-1}=\left(\boldsymbol{A}^{\mathrm{T}}\right)^{-1}=\left(\boldsymbol{A}^{-1}\right)^{\mathrm{T}}
$$

* 正交矩阵的转置仍然是正交矩阵，因为

$$
A^{-1}=A^{\mathrm{T}}
$$

而$A^{-1}$是正交矩阵，因此$A^{\mathrm{T}}$也是正交矩阵

## 矩阵的范数

> 诱导范数

矩阵$\boldsymbol{W}$的范数定义为
$$
\|\boldsymbol{W}\|_{p}=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|_{p}}{\|\boldsymbol{x}\|_{p}}
$$
该范数通过向量的L-p范数定义，因此也称为`诱导范数`(Induced Norm)

式中右侧分母为向量$x$的L-p范数，分子是经过矩阵对应的线性映射作用之后的向量的L-p范数

因此诱导范数的几何意义是矩阵所代表的线性变换对向量进行变换后，向量长度的最大拉伸倍数

> 谱范数

如果$p=2$，此时诱导范数你为`谱范数`(Spectral Norm)
$$
\|\boldsymbol{W}\|=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|}
$$

> F范数

矩阵的`Frobenius范数`(F范数)定义为
$$
\|\boldsymbol{W}\|_{F}=\sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} w_{i j}^{2}}
$$
这等价于向量的L2范数，将矩阵按行或列展开之后形成向量，然后计算L2范数

对于下面的矩阵
$$
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right)
$$
其$\mathrm{F}$范数为
$$
\|\boldsymbol{A}\|_{F}=\sqrt{1^{2}+2^{2}+3^{2}+4^{2}+5^{2}+6^{2}}=\sqrt{91}
$$
根据`柯西不等式`，对于任意的$\boldsymbol{x}$，下面不等式成立
$$
\|\boldsymbol{W} \boldsymbol{x}\| \leqslant\|\boldsymbol{W}\|_{F} \cdot\|\boldsymbol{x}\|
$$
如果$x \neq 0$，上式两边同时除以$\|x\|$可以得到
$$
\frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|} \leqslant\|\boldsymbol{W}\|_{F}
$$
因此$(\mathrm{F}$范数)是谱范数的一个上界

矩阵的范数对于分析线性映射函数的特性有重要的作用，典型的应用是深度神经网络稳定性与泛化性能的分析

## 线性变换

> 定义

矩阵与向量的乘法可以解释为`线性变换`(Linear Transformation)，它将一个向量变成另外一个向量

对于线性空间$X$，如果在其上定义了一种变换(即映射)$A$，对任意$\boldsymbol{x} 、 y \in X$以及数域中的数$k$均满足
$$
A(x+y)=A(x)+A(y)
$$
以及
$$
A(k x)=k A(x)
$$
即对加法和数乘具有线性关系，则称这种映射为线性变换

> 线性变换对向量的加法与数乘运算具有线性

矩阵乘法是一种线性变换，它满足线性变换的定义要求，对任意的向量$x, y \in \mathbb{R}^{n}$以及实数$k$有
$$
\boldsymbol{A}(\boldsymbol{x}+\boldsymbol{y})=\boldsymbol{A} \boldsymbol{x}+\boldsymbol{A} y \qquad \boldsymbol{A}(k \boldsymbol{x})=k \boldsymbol{A} \boldsymbol{x}
$$
几何中的旋转变换是一种线性变换，下面以二维平面的旋转为例进行说明

对于二维平面内的向量$$\boldsymbol{x}=\left(x_{1} x_{2}\right)^{\mathrm{T}}$$，其在极坐标系下的坐标为$$(r \theta)^{\mathrm{T}}$$，从极坐标系到直角坐标系的转换公式为
$$
x_{1}=r \cos \theta \qquad x_{2}=r \sin \theta
$$
将极坐标为$(r \quad \alpha)^{\mathrm{T}}$的向量$$\boldsymbol{x}=\left(\begin{array}{lll}x_{1} & x_{2}\end{array}\right)^{\mathrm{T}}$$逆时针旋转$\alpha$度之后的结果向量$\boldsymbol{x}^{\prime}$的极坐标为$$(r \alpha+\theta)^{\mathrm{T}}$$，其直角坐标为
$$
\begin{aligned}
\boldsymbol{x}^{\prime} & =(r \cos (\alpha+\theta) r \sin (\alpha+\theta))^{\mathrm{T}} \\
& =(r \cos (\alpha) \cos (\theta)-r \sin (\alpha) \sin (\theta) r \sin (\alpha) \cos (\theta)+r \cos (\alpha) \sin (\theta))^{\mathrm{T}} \\
& =\left(x_{1} \cos (\theta)-x_{2} \sin (\theta) x_{2} \cos (\theta)+x_{1} \sin (\theta)\right)^{\mathrm{T}} \\
& =\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right)\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)
\end{aligned}
$$
因此旋转变换的变换矩阵为
$$
\boldsymbol{A}=\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right)
$$

> 正交变换

如果一个线性变换能保持向量之间的角度以及向量的长度不变，即变换之后两个向量的夹角不变，且向量的长度不变，则称为`正交变换`，正交变换对应的矩阵是`正交矩阵`

下面给出证明: 如果$\boldsymbol{A}$是正交矩阵，使用它对向量$\boldsymbol{x}$进行变换之后的向量长度为
$$
\|\boldsymbol{A} \boldsymbol{x}\|=\sqrt{(\boldsymbol{A x})^{\mathrm{T}}(\boldsymbol{A x})}=\sqrt{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}=\sqrt{\boldsymbol{x}^{\mathrm{T}}\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\right) \boldsymbol{x}}=\sqrt{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}=\|\boldsymbol{x}\|
$$
变换之后向量长度不变，对向量$\boldsymbol{x}$和$\boldsymbol{y}$变换之后的内积为
$$
(\boldsymbol{A} \boldsymbol{x})^{\mathrm{T}}(\boldsymbol{A} \boldsymbol{y})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{y}=\boldsymbol{x}^{\mathrm{T}}\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\right) \boldsymbol{y}=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{y}
$$
根据向量夹角公式
$$
\cos \theta=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{y}}{\|\boldsymbol{x}\|\|\boldsymbol{y}\|}
$$
内积和向量长度均不变，因此保持向量夹角不变

旋转变换是正交变换，以二维平面的旋转矩阵为例，有
$$
\begin{aligned}
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} & =\left(\begin{array}{cc}
\cos \theta & \sin \theta \\
-\sin \theta & \cos \theta
\end{array}\right)\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right) \\
& =\left(\begin{array}{cc}
\cos ^{2} \theta+\sin ^{2} \theta & -\cos \theta \sin \theta+\sin \theta \cos \theta \\
-\sin \theta \cos \theta+\cos \theta \sin \theta & \sin ^{2} \theta+\cos ^{2} \theta
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)
\end{aligned}
$$
旋转变换矩阵是正交矩阵，因此旋转变换是正交变换

几何中的缩放变换也是一种线性变换，对于二维平面的向量$$\boldsymbol{x}=\left(\begin{array}{lll}x_{1} & x_{2}\end{array}\right)^{\mathrm{T}}$$，如果有下面的缩放变换矩阵
$$
\boldsymbol{A}=\left(\begin{array}{ll}
2 & 0 \\
0 & 3
\end{array}\right)
$$
则变换之后的向量为
$$
\boldsymbol{x}^{\prime}=\boldsymbol{A} \boldsymbol{x}=\left(\begin{array}{ll}
2 & 0 \\
0 & 3
\end{array}\right)\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)=\left(\begin{array}{l}
2 x_{1} \\
3 x_{2}
\end{array}\right)
$$
这相当于在$$x_{1}$$方向拉伸2倍，在$$x_{2}$$方向拉伸3倍

缩放变换对应的矩阵为对角矩阵，主对角线元素为在该方向上的拉伸倍数，如果为负，则表示反向

缩放变换和旋转变换被广泛应用于数字图像处理、计算机图形学，以及机器视觉等领域，实现对几何体和图像的旋转和缩放等操作

# 行列式

`行列式`(Determinant, det)是对矩阵的一种运算，它作用于方阵，将其映射成一个标量

## 行列式的定义与性质

$n$阶方阵$\boldsymbol{A}$的行列式记为$|\boldsymbol{A}|$或$\operatorname{det}(\boldsymbol{A})$，称为$n$阶行列式。计算公式为
$$
|\boldsymbol{A}|=\left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n_{1}} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|=\sum_{j_{1} j_{2} \cdots j_{n} \in S_{n}}(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} \prod_{i=1}^{n} a_{i, j j_{1}}
$$
其中$$j_{1} j_{2} \cdots j_{n}$$为正整数$1,2, \cdots, n$的一个排列，$S_{n}$是这$n$个正整数所有排列构成的集合， 显然有$$n !$$ 种排列

$$\tau\left(j_{1} j_{2} \cdots j_{n}\right)$$为排列$j_{1} j_{2} \cdots j_{n}$的逆序数，对于一个排列$j_{1} j_{2} \cdots j_{n}$，如果$m<n$，但$$j_{m}>j_{n}$$，则称为一个逆序，排列中所有逆序的数量称为排列的逆序数

下面举例说明，对于3个正整数$1,2,3$，其所有排列的集合$S_{n}$为
$$
\begin{array}{lll}
1,2,3 & 1,3,2 & 2,1,3 \\
2,3,1 & 3,1,2 & 3,2,1
\end{array}
$$
排列$3,2,1$的所有逆序为
$$
(3,2),(2,1),(3,1)
$$
因此其逆序数为3

排列$2,1,3$的所有逆序为
$$
(2,1)
$$
因此其逆序数为1

根据定义，$n$阶行列式的求和项有$n!$ 项，每个求和项中的$\prod_{i=1}^{n} a_{i, j_{i}}$表示按行号递增的顺序从$\boldsymbol{A}$的每一行各抽取一个元素相乘，且这些元素的列号不能重复，它们的列号$j_{1} j_{2} \cdots j_{n}$是$1,2, \cdots, n$的一个排列

$$(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)}$$决定了求和项的符号，它意味着如果这些元素的列号排列的逆序数为偶数，则其值为1；如果为奇数，则为-1

$n!$ 种排列中逆序数为奇数的排列和逆序数为偶数的排列各占一半,，此求和项中正号和负号各占一半

下面按照定义计算3阶行列式的值
$$
\begin{aligned}
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right|= & (-1)^{\tau(1,2,3)} a_{11} a_{22} a_{33}+(-1)^{\tau(1,3,2)} a_{11} a_{23} a_{32}+(-1)^{\tau(2,1,3)} a_{12} a_{21} a_{33} \\
& -+(-1)^{\tau(2,3,1)} a_{12} a_{23} a_{31}+(-1)^{\tau(3,1,2)} a_{13} a_{21} a_{32}+(-1)^{\tau(3,2,1)} a_{13} a_{22} a_{31} \\
= & (-1)^{0} \times 1 \times 0 \times 0+(-1)^{1} \times 1 \times 1 \times 1+(-1)^{1} \times 2 \times 1 \times 0+(-1)^{2} \times 2 \times 1 \times 1 \\
& +(-1)^{2} \times 3 \times 1 \times 0+(-1)^{3} \times 3 \times 0 \times 1 \\
= & 1
\end{aligned}
$$
下面推导2阶和3阶行列式的计算公式，2阶矩阵的行列式的计算公式为
$$
\left|\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right|=(-1)^{\tau(1,2)} a_{11} a_{22}+(-1)^{\tau(2,1)} a_{12} a_{21}=a_{11} a_{22}-a_{12} a_{21}
$$
下面的2阶行列式值为
$$
\left|\begin{array}{ll}
1 & 2 \\
3 & 4
\end{array}\right|=1 \times 4-2 \times 3=-2
$$
3阶矩阵的行列式的计算公式为
$$
\begin{aligned}
\left|\begin{array}{lll}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{array}\right|= & (-1)^{\tau(1,2,3)} a_{11} a_{22} a_{33}+(-1)^{\tau(2,3,1)} a_{12} a_{23} a_{31}+(-1)^{\tau(3,1,2)} a_{13} a_{21} a_{32} \\
& +(-1)^{\tau(3,2,1)} a_{13} a_{22} a_{31}+(-1)^{\tau(1,3,2)} a_{11} a_{23} a_{32}+(-1)^{\tau(2,1,3)} a_{12} a_{21} a_{33} \\
= & a_{11} a_{22} a_{33}+a_{12} a_{23} a_{31}+a_{13} a_{21} a_{32}-a_{13} a_{22} a_{31}-a_{11} a_{23} a_{32}-a_{12} a_{21} a_{33}
\end{aligned}
$$
下面的3阶行列式值为
$$
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
1 & 2 & 2
\end{array}\right|=1 \times 5 \times 2+2 \times 6 \times 1+3 \times 4 \times 2-3 \times 5 \times 1-1 \times 6 \times 2-2 \times 4 \times 2=3
$$
行列式可以表示平行四边形与平行六面体的有向面积和体积，也是线性变换的伸缩因子

如果将方阵看作线性变换，则其行列式的绝对值表示该变换导致的体积元变化系数

`雅克比行列式`被广泛应用于多元函数微分与积分的计算，代表了多元换元后的比例量

按照定义，一个行列式可以按照行或列进行递归展开，称为`拉普拉斯展开`(Laplace Expan-sion)
$$
|\boldsymbol{A}|=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\cdots+a_{i n} A_{i n}=a_{1 j} A_{1 j}+a_{2 j} A_{2 j}+\cdots+a_{n j} A_{n j}
$$
其中
$$
A_{i j}=(-1)^{i+j}\left|\begin{array}{cccccc}
a_{11} & \cdots & a_{1, j-1} & a_{1, j+1} & \cdots & a_{1 n} \\
\vdots & & \vdots & \vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, j-1} & a_{i-1, j+1} & \cdots & a_{i-1, n} \\
a_{i+1,1} & \cdots & a_{i+1, j-1} & a_{i+1, j+1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots & \vdots & & \vdots \\
a_{n 1} & \cdots & a_{n, j-1} & a_{n, j+1} & \cdots & a_{n n}
\end{array}\right|
$$
是去掉矩阵$\boldsymbol{A}$的第$i$行和第$j$ 后的$n-1$阶矩阵的行列式，并且带有符号$(-1)^{i+j}, i+j$为行号和列号之和，称$$A_{i j}$$为$$a_{i j}$$的`代数余子式`，不带符号的子行列式则称为余子式

下面的行列式可以按第一行展开为
$$
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right|=1 \times(-1)^{1+1} \times\left|\begin{array}{cc}
0 & 1 \\
1 & 0
\end{array}\right|+2 \times(-1)^{1+2} \times\left|\begin{array}{cc}
1 & 1 \\
1 & 0
\end{array}\right|+3 \times(-1)^{1+3} \times\left|\begin{array}{cc}
1 & 0 \\
1 & 1
\end{array}\right|
$$

> 特殊行列式的值

某一行(列)全为0的行列式值为0，根据拉普拉斯展开可以得到此结论，根据行列式的定义也可以直接得到此结果，$n!$ 个求和项中每一项都必然包含某一 行列的一个元素，根据此结论，下面的行列式值为0
$$
\left|\begin{array}{lll}0 & 0 & 0 \\ 1 & 2 & 3 \\ 4 & 5 & 6\end{array}\right|=0
$$
根据定义，如果一个矩阵为对角矩阵，则其行列式为矩阵主对角线元素的乘积，这是因为$n !$ 个求和项中，除了全部由主对角线元素构成的项之外，其他的项的乘积中都含有0
$$
\left|\begin{array}{ccc}
a_{11} & 0 & 0 \\
0 & \ddots & 0 \\
0 & 0 & a_{n n}
\end{array}\right|=\prod_{i=1}^{n} a_{i i}
$$
下面的对角矩阵的行列式值为
$$
\left|\begin{array}{lll}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 3
\end{array}\right|=1 \times 2 \times 3=6
$$
单位矩阵的行列式为1
$$
|\boldsymbol{I}|=\left|\begin{array}{ccc}
1 & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & 1
\end{array}\right|=1 \times 1 \times \cdots \times 1=1
$$
上三角矩阵和下三角矩阵的行列式为其主对角线元素的乘积，这是因为$n$ ! 个求和项中，除了全部由主对角线元素构成的项之外，其他的项的乘积中都含有0
$$
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & \ddots & \vdots \\
0 & \cdots & a_{n n}
\end{array}\right|=\prod_{i=1}^{n} a_{i i}
$$
根据这一结论有
$$
\left|\begin{array}{lll}
1 & 4 & 6 \\
0 & 2 & 5 \\
0 & 0 & 3
\end{array}\right|=1 \times 2 \times 3=6
$$

> 行列式的重要性质

行列式具有多线性，可以按照某一行或列的线性组合拆分成两个行列式之和
$$
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
\alpha a_{i 1}+\beta b_{i 1} & \cdots & \alpha a_{i n}+\beta b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=\alpha\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
a_{i 1} & \cdots & a_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|+\beta\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
b_{i 1} & \cdots & b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|
$$
因为
$$
\left|\begin{array}{ccc}a_{11} & \cdots & a_{1 n} \\ \vdots & & \vdots \\ a_{i-1,1} & \cdots & a_{i-1, n} \\ \alpha a_{i 1}+\beta b_{i 1} & \cdots & \alpha a_{i n}+\beta b_{i n} \\ a_{i+1,1} & \cdots & a_{i+1, n} \\ \vdots & & \vdots \\ a_{n 1} & \cdots & a_{n n}\end{array}\right|=\sum_{j_{1} j_{2} \cdots j_{n}}(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} a_{1 j_{1}} \cdots\left(\alpha a_{i j}+\beta b_{i j}\right) \cdots a_{n j_{n}}
\\
= \alpha \sum _{j_1j_2 \cdots j_n}{(-1)^{\tau (j_1j_2 \cdots j_n)} } \alpha_{1j_1} \cdots \alpha_{ij_i} \cdots \alpha_{nj_n} + \beta \sum _{j_1j_2 \cdots j_n}{(-1)^{\tau (j_1j_2 \cdots j_n)} } \alpha_{1j_1} \cdots \alpha_{ij_i} \cdots \alpha_{nj_n}
\\
\begin{array}{l}
=\alpha\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
a_{i 1} & \cdots & a_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|+\beta\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
b_{i 1} & \cdots & b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right| \\
\end{array}
$$
按照这一结论有
$$
\left|\begin{array}{ccc}
1+2 & 2+3 & 3+4 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|=\left|\begin{array}{ccc}
1 & 2 & 3 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|+\left|\begin{array}{ccc}
2 & 3 & 4 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|
$$
如果行列式的两行或列相等，那么行列式的值为0，即
$$
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=0
$$
下面给出证明，假设行列式的第$i$行和第$k$行相等，$n!$ 个求和项可以分成两组，即
$$
(-1)^{\tau\left(j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}\right)} a_{1 j_{1}} \cdots a_{i j_{i}} \cdots a_{k j_{k}} \cdots a_{n j_{n}}
$$
与
$$
(-1)^{\tau\left(j_{1} \cdots j_{k} \cdots j_{1} \cdots j_{n}\right)} a_{1 j_{1}} \cdots a_{i j_{k}} \cdots a_{k j_{k}} \cdots a_{n j_{n}}
$$
由于$$a_{i j_{1}}=a_{k j_{1}}, a_{k j_{k}}=a_{i j_{k}}$$且排列$$j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}$$与$$j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}$$的逆序数的奇偶性相反(二者通过一次置换可以互相得到)，因此这两项的符号相反，故行列式的值为0

根据这一结论，下面的行列式为0
$$
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{array}\right|=0
$$
根据这一结论可以构造出可逆矩阵的逆矩阵，对于矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)
$$
假设$$A_{i j}$$是$$a_{i j}$$的代数余子式，利用它们构造如下的伴随矩阵
$$
\boldsymbol{A}^{*}=\left(\begin{array}{cccc}
A_{11} & A_{21} & \cdots & A_{n 1} \\
A_{12} & A_{22} & \cdots & A_{n 2} \\
\vdots & \vdots & & \vdots \\
A_{1 n} & A_{2 n} & \cdots & A_{n n}
\end{array}\right)
$$
根据拉普拉斯展开，第$i$行与其代数余子式的内积为行列式本身
$$
|\boldsymbol{A}|=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\cdots+a_{i n} A_{i n}
$$
第$i$行与第$j, j \neq i$行的代数余子式的内积为0，这是因为它是第$j$行与第$i$行相等的行列式的拉普拉斯展开，其值为0
$$
0=a_{i 1} A_{j 1}+a_{i 2} A_{j 2}+\cdots+a_{i n} A_{j n}, j \neq i
$$
因此有
$$
\boldsymbol{A} \boldsymbol{A}^{*}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)\left(\begin{array}{cccc}
A_{11} & A_{21} & \cdots & A_{n 1} \\
A_{12} & A_{22} & \cdots & A_{n 2} \\
\vdots & \vdots & & \vdots \\
A_{1 n} & A_{2 n} & \cdots & A_{n n}
\end{array}\right)=\left(\begin{array}{cccc}
|\boldsymbol{A}| & 0 & \cdots & 0 \\
0 & |\boldsymbol{A}| & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & |\boldsymbol{A}|
\end{array}\right)=|\boldsymbol{A}| \boldsymbol{I}
$$
如果$|\boldsymbol{A}| \neq 0$，则有
$$
A \frac{1}{|A|} A^{*}=I
$$
因此
$$
\boldsymbol{A}^{-1}=\frac{1}{|\boldsymbol{A}|} \boldsymbol{A}^{*}
$$
这也证明了矩阵$\boldsymbol{A}$可逆的充分必要条件是$|\boldsymbol{A}| \neq 0$

如果把行列式的某一行元素都乘以$k$，则行列式变为之前的$k$倍，即
$$
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
k a_{i 1} & \cdots & k a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=k\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|
$$
如果将行列式的两行交换，行列式反号

如果一个行列式的两行成比例关系，其值为0

行列式的一行加上另一行的$k$倍，行列式值不变

按照这一结论，下面两个行列式的值相等
$$
\left|\begin{array}{lll}
1 & 1 & 1 \\
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right|=\left|\begin{array}{ccc}
1+1 & 1+2 & 1+3 \\
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right|
$$
可以通过这种变换将矩阵化为三角矩阵，然后计算其行列式的值

根据拉普拉斯展开可以证明下面的结论成立
$$
\left|\begin{array}{cccccccc}
a_{11} & a_{12} & \cdots & a_{1 n} & 0 & \cdots & \cdots & 0 \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
c_{11} & c_{12} & \cdots & c_{1 n} & b_{11} & b_{12} & \cdots & b_{1 m} \\
c_{21} & c_{22} & \cdots & c_{2 n} & b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
c_{m 1} & c_{m 2} & \cdots & c_{m n} & b_{m 1} & b_{m 2} & \cdots & b_{m m}
\end{array}\right|=\left|\begin{array}{ccccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|\left|\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 m} \\
b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & & \vdots \\
b_{m 1} & b_{m 2} & \cdots & b_{m m}
\end{array}\right|
$$
如果矩阵$A$和$B$是尺寸相同的$n$阶矩阵，则有
$$
|A B|=|A||B|
$$
即矩阵乘积的行列式等于矩阵行列式的乘积，下面给出证明，由于
$$
|\boldsymbol{A}||\boldsymbol{B}|=\left|\begin{array}{cccccccc}
a_{11} & a_{12} & \cdots & a_{1 n} & 0 & \cdots & \cdots & 0 \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right|
$$
将$n+1$行乘以$$a_{11}$$加到第1行，第$n+2$行乘以$a_{12}$加到第1行，... ， 将第$$2 n$$行乘以$$a_{1 n}$$加到第1行，可以得到
$$
|\boldsymbol{A}||\boldsymbol{B}|=\left|\begin{array}{cccccccc}
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{1 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{1 k} b_{k n} \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right|
$$
对第$2 \sim n$行执行类似的操作，将上式右侧行列式的左上角全部消为0，最后可以得到
$$
\begin{aligned}
|\boldsymbol{A}||\boldsymbol{B}| & =\left|\begin{array}{cccccccc}
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{1 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{1 k} b_{k n} \\
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{2 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{2 k} b_{k n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{n k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{n k} b_{k n} \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right| \\
& =\left|\begin{array}{ccc}
\mathbf{0}-1 \\
-\boldsymbol{I} & B
\end{array}\right|=(-1)^{n}\left|\begin{array}{ccc}
A B & 0 \\
B & -I
\end{array}\right|=(-1)^{n}|\boldsymbol{A B}||-\boldsymbol{I}|=(-1)^{n}|\boldsymbol{A B}|(-1)^{n}=|\boldsymbol{A B}|
\end{aligned}
$$
上式第3步将行列式左侧的$n$列与右侧的$n$列对换，因此出现$(-1)^{n}$，第4步利用了拉普拉斯展开，第5步利用了对角矩阵的行列式计算公式，通常使用它计算矩阵乘积的行列式

根据上式可以直接得到下面的结论: 如果矩阵可逆，则其行列式不为0，且其逆矩阵的行列式等于行列式的逆，即
$$
\left|A^{-1}\right|=|A|^{-1}
$$
这是因为$A A^{-1}=I$，因此
$$
|\boldsymbol{A}|\left|\boldsymbol{A}^{-1}\right|=|\boldsymbol{I}|=1
$$
矩阵与标量乘法的行列式为
$$
|\alpha \boldsymbol{A}|=\alpha^{n}|\boldsymbol{A}|
$$
其中$n$为矩阵的阶数，这可以根据行列式的定义直接证明，所有求和项$$(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} \prod_{i=1}^{n} a_{i, j}$$中$$a_{i, j}$$均变为$$\alpha a_{i, j i}$$，因此最后出现$\alpha^{n}$，根据这一结论有
$$
\left|\begin{array}{ccc}
2 & 4 & 6 \\
8 & 10 & 12 \\
14 & 16 & 18
\end{array}\right|=2^{3} \times\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right|
$$
矩阵转置之后行列式不变
$$
|\boldsymbol{A}|=\left|\boldsymbol{A}^{\mathrm{T}}\right|
$$
这可以根据行列式的定义以及行列对换进行证明

正交矩阵的行列式为$\pm 1$，如果$A$是正交矩阵，则有
$$
\left|\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}\right|=|\boldsymbol{A}|\left|\boldsymbol{A}^{\mathrm{T}}\right|=|\boldsymbol{A}||\boldsymbol{A}|=|\boldsymbol{I}|=1
$$
因此$|\boldsymbol{A}|=\pm 1$

## 计算方法

行列式的计算分为手动计算与编程计算两种方式

> 手动计算

对于手动计算，重点介绍将矩阵化为`上三角矩阵`的方法

上三角矩阵或下三角矩阵的行列式是易于许算的，等于其主对角线元素的乘积

根据下面的初等行变换

1. 将行列式的两行交换
2. 将行列式的某一行乘以$k$倍之后加到另外一行

可以将行列式化为上三角形式，根据前面介绍的行列式的性质，第一种变换使得行列式的值反号，第二种变换保证行列式的值不变

下面举例说明，对于下面的行列式
$$
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right|
$$
将其化为上三角矩阵，然后计算行列式的值
$$
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right| \stackrel{r_{2}-4 \times r_{1}, r_{3}-7 \times r_{1}}{\longrightarrow}\left|\begin{array}{ccc}
1 & 2 & 3 \\
0 & -3 & -6 \\
0 & -6 & -12
\end{array}\right| \stackrel{r_{3}-2 \times r_{2}}{\longrightarrow}\left|\begin{array}{ccc}
1 & 2 & 3 \\
0 & -3 & -6 \\
0 & 0 & 0
\end{array}\right|=0
$$

> 编程计算

Python中linalg的det函数实现了计算方阵行列式的功能，下面是计算矩阵行列式的示例代码

```python
import numpy  
A = np.array([[1,0,0],[0,1,0],[0,0,5]])
d = np.linalg.det(A)
print(d)
```

程序运行结果为5，对角矩阵的行列式为主对角线元素的乘积




# 线性方程组

## 高斯消元法

`高斯消元法`(Gaussian Elimination Method)即`加减消元法`，是求解线性方程组的经典方法

通过将一个方程减掉另一个方程的倍数消掉末知数，得到`阶梯型方程组`，然后依次解出每一个末知数

下面用一个简单的例子进行说明，对于如下的线性方程组
$$
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
6 x_{1}+2 x_{2}+x_{3}=-1 \\
-2 x_{1}+2 x_{2}+x_{3}=7
\end{array}\right.
$$
先消去方程2和方程3的第一个末知数，将方程2减去方程1的3倍，将方程3加上方程1，消掉方程2和方程3中的$x_{1}$，得
$$
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
3 x_{2}+2 x_{3}=8
\end{array}\right.
$$
然后将方程3加上方程2的3倍，消掉方程3中的$x_{2}$，得
$$
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
-4 x_{3}=-4
\end{array}\right.
$$
可以解得
$$
x_{1}=-1 \qquad x_{2}=2 \qquad x_{3}=1
$$
下面用矩阵的形式描述这一求解过程，如下所示
$$
\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
6 & 2 & 1 & -1 \\
-2 & 2 & 1 & 7
\end{array}\right) \stackrel{r_{2}-3 \times r_{1}, r_{3}+r_{1}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 3 & 2 & 8
\end{array}\right) \stackrel{r_{3}+3 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 0 & -4 & -4
\end{array}\right)
$$
下面将这种消元法进行推广，对于任意的线性方程组，采用如下的初等变换对其进行变形，方程组的解不变

1. 交换两个方程的位置
2. 用非0的常数乘以某方程的两端
3. 将一个方程的常数倍加到另一个方程上去

采用这种初等变换，每次消掉一个末知数，最后得到一个阶梯形方程组，即可求出方程的解

## 齐次方程组

`齐次线性方程组`(Homogeneous Linear Equations)是常数项全部为0的线性方程组，可以写成如下形式
$$
\boldsymbol{A x}=\mathbf{0}
$$
其中$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ 

将系数矩阵$\boldsymbol{A}$按列分块为$\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)$，齐次方程可以写成
$$
x_{1} \boldsymbol{a}_{1}+\cdots+x_{n} \boldsymbol{a}_{n}=\mathbf{0}
$$
以解向量$\boldsymbol{x}=\left(x_{1} \cdots x_{n}\right)^{\mathrm{T}}$为组合系数，向量组$\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}$的线性组合为$\mathbf{0}$向量

显然$\boldsymbol{x}=\mathbf{0}$是方程组的解，因此齐次方程一定有解，更重要的是，除$\boldsymbol{x}=\mathbf{0}$ 外的解，称为`非0解`，下面讨论这种解的存在性

根据线性相关性的定义，如果向量组$\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}$线性无关，则不存在一组不全为0的系数$\boldsymbol{x}$使得其线性组合为0

如果向量组$a_{1}, \cdots, a_{n}$线性相关，则存在一组不全为0的系数$x$使得其线性组合为0，这就是方程组的非0解

前者对应于矩阵$A$的秩为$n$，后者秩小于$n$，由此得到齐次方程组解的存在性判定条件，分下面两种情况

1. 如果$r(\boldsymbol{A})=n$，方程组只有0解
2. 如果$r(\boldsymbol{A}) \lt n$，方程组有非0解

方程组有非$\boldsymbol{0}$解的充分必要条件是$r(\boldsymbol{A})<n$

如果$\boldsymbol{A}$是方阵，$r(\boldsymbol{A})<n$等同于$\boldsymbol{A}$不可逆， 如果$m<n$，即(方程的数量)小于未知数的数量，则有
$$
r(\boldsymbol{A}) \leqslant \min (m, n) \leqslant m<n
$$
此时方程组必定有非$\boldsymbol{0}$解，对于如下的线性方程组
$$
\left\{\begin{array}{l}
x_{1}-x_{2}+x_{3}=0 \\
-x_{1}+x_{2}+x_{3}=0 \\
x_{1}+x_{2}-x_{3}=0
\end{array}\right.
$$
其系数矩阵的秩为
$$
r\left(\left(\begin{array}{ccc}
1 & -1 & 1 \\
-1 & 1 & 1 \\
1 & 1 & -1
\end{array}\right)\right)=3
$$
因此方程组只有$\mathbf{0}$解，对于如下的方程组
$$
\left\{\begin{array}{l}
x_{1}+x_{2}+x_{3}=0 \\
2 x_{1}+2 x_{2}+2 x_{3}=0
\end{array}\right.
$$
其系数矩阵的秩为
$$
r\left(\left(\begin{array}{lll}
1 & 1 & 1 \\
2 & 2 & 2
\end{array}\right)\right)=1
$$
也是方程组的解，证明如下
$$
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}=\sum_{i=1}^{l} k_{i} \mathbf{0}=\mathbf{0}
$$
假设$x_{1}, \cdots, x_{l}$都是方程组的解，如果这组解线性无关且方程组的任意一个解都可以由这组解线性表示，则称$x_{1}, \cdots, x_{l}$是方程组的一个`基础解系`

如果$r(\boldsymbol{A})<n$，则存在基础解系，且基础解系中包含$n-r(\boldsymbol{A})$个解

> 齐次线性方程组的求解方法

通常采用的是初等行变换法，对应`高斯消元法`，经过初等行变换将系数矩阵化为阶梯形矩阵之后

如果出现自由未知数，可以将它们设为特殊值，形成基础解系，然后得到方程组的`通解`(General Solution)

如果$x_{r+1}, \cdots, x_{n}$是自由末知数，通常将它们的值依次设为
$$
\left(\begin{array}{llll}1 & 0 & \cdots & 0\end{array}\right) \qquad
\left(\begin{array}{llll}0 & 1 & \cdots & 0\end{array}\right) \qquad \cdots \qquad
\left(\begin{array}{llll}0 & 0 & \cdots & 1\end{array}\right)
$$
这是$\mathbb{R}^{n-r}$空间一组最简单的`标准正交基`，然后根据它们的值解出其他的末知数，对于如下的方程组
$$
\left\{\begin{array}{l}
x_{1}+2 x_{2}+2 x_{3}+x_{4}=0 \\
2 x_{1}+x_{2}-2 x_{3}-2 x_{4}=0 \\
x_{1}-x_{2}-4 x_{3}-3 x_{4}=0
\end{array}\right.
$$
对其系数矩阵进行初等行变换
$$
\begin{array}{l} 
A=\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
2 & 1 & -2 & -2 \\
1 & -1 & -4 & -3
\end{array}\right) \stackrel{r_{2}-2 r_{1}, r_{3}-r_{1}}{\longrightarrow} \\
\stackrel{r_{3}-r_{2}, r_{2} \times(-1 / 3)}{\longrightarrow}\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
0 & 1 & 2 & 4 / 3 \\
0 & -3 & -6 & -4 \\
0 & -3 & -6 & -4
\end{array}\right) \stackrel{r_{1}-2 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
1 & 0 & -2 & -5 / 3 \\
0 & 1 & 2 & 4 / 3 \\
0 & 0 & 0 & 0
\end{array}\right)
\end{array}
$$
由于$r(\boldsymbol{A})=2<4$，因此方程组有非$\mathbf{0}$解，最后丙个末知数为自由变量

令$x_{3}=1, x_{4}=0$，得到基础解系的第一个解
$$
x_{1}=\left(\begin{array}{llll}
2 & -2 & 1 & 0
\end{array}\right)^{T}
$$
令$x_{3}=0, x_{4}=1$，得到基础解系的第二个解
$$
x_{2}=\left(\begin{array}{llll}
5 / 3 & -4 / 3 & 0 & 1
\end{array}\right)^{\mathrm{T}}
$$
方程组的通解为
$$
\boldsymbol{x}=k_{1} x_{1}+k_{2} x_{2}
$$
其中$k_{1}, k_{2}$为任意常数

## 非齐次方程组

`非齐次线性方程组`(Non-homogeneous Linear Equations)的常数项不全为0，可写成如下形式

\boldsymbol{A} \boldsymbol{x}=\boldsymbol{b}

这与一元一次方程$a x=0$在形式上是统一的，方程组的增广矩阵是系数矩阵和常数向量合并构成的矩阵
$$
\boldsymbol{B}=\left(\begin{array}{ll}
\boldsymbol{A} & \boldsymbol{b}
\end{array}\right)
$$
对于如下的线性方程组
$$
\left\{\begin{array}{l}
2 x_{1}-3 x_{2}+x_{3}=1 \\
4 x_{1}-2 x_{2}+x_{3}=2 \\
3 x_{1}+3 x_{2}+x_{3}=0
\end{array}\right.
$$
其系数矩阵为
$$
\left(\begin{array}{ccc}
2 & -3 & 1 \\
4 & -2 & 1 \\
3 & 3 & 1
\end{array}\right)
$$
增广矩阵为
$$
\left(\begin{array}{cccc}
2 & -3 & 1 & 1 \\
4 & -2 & 1 & 2 \\
3 & 3 & 1 & 0
\end{array}\right)
$$
假设$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ ，系数矩阵$\boldsymbol{A}$扩列分块为$\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)$，非齐次方程可以写成
$$
x_{1} a_{1}+\cdots+x_{n} a_{n}=b
$$
以$x$为组合系数，向量组$a_{1}, \cdots, a_{n}$的线性组合为向量$b$，如果$b$可以由$A$的列向量线性表示，则方程组有解，否则方程组无解

用初等行变换將增广矩阵化为阶梯矩阵
$$
\left(\begin{array}{ccccccc}
1 & \cdots & c_{1 r} & c_{1, r+1} & \cdots & c_{1 n} & d_{1} \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 1 & c_{r, r+1} & \cdots & c_{r n} & d_{r} \\
0 & \cdots & 0 & 0 & \cdots & 0 & d_{r+1} \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0 \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0
\end{array}\right)
$$
如果$d_{r+1} \neq 0$，则意味着出现矛盾方程，方程无解，如果$d_{r+1}=0$，则方程组有解，对于第二种情况，增广矩阵的秩与系数矩阵的秩小于增广矩阵的秩，且
$$
r(\boldsymbol{B})=r(\boldsymbol{A})+1
$$
由此得到非齐次方程组解的存在性判定条件

1. 如果$r(\boldsymbol{A})=r(\boldsymbol{B})$，那么方程组的解存在
2. 如果$r(\boldsymbol{A})<r(\boldsymbol{B})$，那么方程组的解不存在

对于第一种情况，如果$r(\boldsymbol{A})=n$，那么方程组有唯一解，如果$r(\boldsymbol{A})<n$，那么方程组有无穷多组解

> 解的性质与结构

如果$x_{1}, \cdots, x_{l}$是非齐次方程组所对应的齐次方程的一组解，$x^{*}$是非齐次方程的一个解，则$\sum_{i=1}^{1} k_{i} x_{i}+x^{*}$是非齐次方程的解，显然
$$
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}+\boldsymbol{x}^{*}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}+\boldsymbol{A} \boldsymbol{x}^{*}=\sum_{i=1}^{l} k_{i} \mathbf{0}+\boldsymbol{b}=\boldsymbol{b}
$$
如果$x_{1}, \cdots, x_{l}$是齐次方程组的基础解系，$x^{*}$是非齐次方程组的一个解，则非齐次方程组的解可以表示为
$$
\sum_{i=1}^{l} k_{i} x_{i}+x^{*}
$$
同样可以用初等行变换求解非齐次方程组，其解为对应的齐次方程组的通解加上它的一个`特解`(Particular Solution)

齐次方程组通解的求解方法在前面已经介绍，非齐次方程组的特解可以任意选取，通常令自由末知数的值全为0

用初等行变换解下面的非齐次线性方程组
$$
\left\{\begin{array}{l}
x_{1}+5 x_{2}-x_{3}-x_{4}=-1 \\
x_{1}-2 x_{2}+x_{3}+3 x_{4}=3 \\
3 x_{1}+8 x_{2}-x_{3}+x_{4}=1 \\
x_{1}-9 x_{2}+3 x_{3}+7 x_{4}=7
\end{array}\right.
$$
对其增广矩阵进行初等行变换
$$
\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 1 & -2 & 1 & 3 & 3 \\ 3 & 8 & -1 & 1 & 1 \\ 1 & -9 & 3 & 7 & 7\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & -7 & 2 & 4 & 4 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & 1 & -2 / 7 & -4 / 7 & -4 / 7 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right)
$$
$x_{3}, x_{4}$是自由未知数，令$x_{3}=x_{4}=0$，得到一个特解
$$
\boldsymbol{x}^{*}=\left(\begin{array}{c}
13 / 7 \\
-4 / 7 \\
0 \\
0
\end{array}\right)
$$
方次方程组的基础解系为
$$
\boldsymbol{x}_{1}=\left(\begin{array}{c}
-3 / 7 \\
2 / 7 \\
1 \\
0
\end{array}\right), \boldsymbol{x}_{2}=\left(\begin{array}{c}
-13 / 7 \\
4 / 7 \\
0 \\
1
\end{array}\right)
$$
因此方程的解为
$$
\boldsymbol{x}=\boldsymbol{x}^{*}+k_{1} \boldsymbol{x}_{1}+k_{2} \boldsymbol{x}_{2}
$$
其中$k_{1}, k_{2}$为任意常数

Python中linalg的solve函数提供了求解非齐次线性方程组的功能，函数的传人参数为系数矩阵$A$，以及常数向量$\boldsymbol{b}$，返回值是方程组$\boldsymbol{A x}=\boldsymbol{b}$的解向量$x$，对于方程组
$$
\begin{array}{l}
3 x_{1}+x_{2}=9 \\
x_{1}+2 x_{2}=8
\end{array}
$$
下面是求解该方程组的代码

```python
import numpy as np
A = np.array([3,1], [1,2])
b = np.array([9,8])
x = np.linalg.solve(A, b)
print(x)
```

程序运行结果为$[2,3]$



# 特征值和特征向量

`特征值`(Eigenvalue，也称为本征值)与`特征向量`(Eigenvector，也称为`本征向量`)决定了矩阵的很多性质

从几何的角度来看，持征向量是经过矩阵的线性变换仍然处于同一条直线上的向量

##  特征值与特征向量

> 特征值与特征向量

对于$n$阶矩阵$A$，其特征向量是经过这个矩阵的线性变换之后仍然处于同一条直线上的向量，新向量的方向可能会相反，长度可能会改变，即存在一个数$\lambda$以及非$0$向量$x$，满足
$$
\boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{x}
$$
则称$\lambda$为矩阵$A$的`特征值`，$x$为该特征值对应的`特征向量`

特征值是特征向量在矩阵的线性变换下的缩放代，如果持征值大于0，那么经过线性变换之后特征向量的方向不变；如果特征值小于0，那么经过线性变换之后特征向量的方向相反，如果特征值为0，则经过线性变换之后特征向量收缩回原点

> 特征矩阵和特征方程

上式变形后可以得到
$$
(A-\lambda I) x=0
$$
$A-\lambda I$ 称为`特征矩阵`，按照线性方程组的理论，上面的齐次方程有非0解的条件是系数矩阵的行列式必须为0，即
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=0
$$
式子称为`特征方程`(Eigenvalue Equation)

对于矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)
$$
其特征方程为
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|=0
$$

> 特征多项式

上面的行列式展开之后是$\lambda$的$n$次多项式，称为矩阵的`特征多项式`(Characteristic Polynomial)，为如下形式
$$
c_{n} \lambda^{n}+c_{n-1} \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+c_{0}
$$
求解这个特征多项式对应的特征方程可以得到所有特征值，方程的根可能是复数，此时的特征值为复数，特征向量为复向量

根据对角行列式的计算公式，对角矩阵的特征为其主对角线元素，对于如下对角矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & 0 & \cdots & 0 \\
0 & a_{22} & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)
$$
其特征方程为
$$
\left|\begin{array}{cccc}a_{11}-\lambda & 0 & \cdots & 0 \\ 0 & a_{22}-\lambda & \cdots & 0 \\ \vdots & \vdots & & \vdots \\ 0 & 0 & \cdots & a_{n n}-\lambda\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0
$$
类似地，上三角矩阵的特征值为其主对角线元素，对于如下的上三角矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
0 & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)
$$
其特征方程为
$$
\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
0 & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}-\lambda
\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0
$$
对于下三角矩阵有相同的结论，一种计算特征值的方法是通过相似变换将矩阵变为上三角矩阵

> 代数重数、谱

根据多项式分解定理，特征方程可以写成
$$
\left(\lambda-\lambda_{1}\right)^{n_{1}}\left(\lambda-\lambda_{2}\right)^{n_{2}} \cdots\left(\lambda-\lambda_{N_{\lambda}}\right)^{n_{N_{\lambda}}}=0
$$
其中$n_{i}$称为特征值$\lambda_{i}$的`代数重数`(Algebraic Multiplicity)，根据代数方程的理论，有
$$
\sum_{i=1}^{N_{\lambda}} n_{i}=n
$$
所有$N_{\lambda}$个不同的特征值构成的集合称为矩阵的`谱`(Spectrum)

矩阵的`谱半径`(Spectral Radius)定义为所有特征值绝对值的最大值，记为
$$
\rho(\boldsymbol{A})=\max \left\{\left|\lambda_{1}\right|, \cdots,\left|\lambda_{N_{\lambda}}\right|\right\}
$$
如果矩阵$\boldsymbol{A}$不可逆，则
$$
|\boldsymbol{A}|=|\boldsymbol{A}-0 \boldsymbol{I}|=0
$$
因此0是它的特征值，反之，如果可逆，则0不是它的特征值

> 几何重数

得到每个特征值$\lambda_{i}$之后，解下面的线性方程组
$$
(A - \lambda _i I)x = 0
$$
即可得到其对应的特征向量，此方程组有$1 \leq m_i \leq n_i$，个线性无关的解，称$m_i$为$\lambda _i$的`几何重数`(Geometric Multiplicity)

这些线性无关的解构成的空间称为矩阵$\boldsymbol{A}$关于特征值$\lambda_{i}$的特征子空间，记为$V_{\lambda _i}$

根据齐次线性方程组解的理论，特征子空间的维数为
$$
m_{i}=n-r\left(\boldsymbol{A}-\lambda_{i} \boldsymbol{I}\right)
$$
属于不同特征值的特征向量线性无关，矩阵所有线性无关的特征向量的数量为
$$
N_{x}=\sum_{i=1}^{N_{ \lambda}} m_{i}
$$
显然有$N_{x} \leqslant n$

> 特征值与特征向量的计算

下面用一个例子来说明特征值与特征向量的计算，对于如下矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cc}
1 & 2 \\
0 & -1
\end{array}\right)
$$
其特征多项式为
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cc}
1-\lambda & 2 \\
0 & -1-\lambda
\end{array}\right|=-(1-\lambda)(1+\lambda)
$$
特征方程$-(1-\lambda)(1+\lambda)=0$的根为$\lambda=1$与$\lambda=-1$，因此该矩阵的特征值为1与-1

将特征值1代人，可得
$$
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{cc}
0 & 2 \\
0 & -2
\end{array}\right) \boldsymbol{x}=\mathbf{0}
$$
该齐次方程的解为
$$
\boldsymbol{x}=\left(\begin{array}{l}
1 \\
0
\end{array}\right)
$$
此即特征值1对应的特征向量

将另外一个特征值-1代人，可得
$$
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{ll}
2 & 2 \\
0 & 0
\end{array}\right) \boldsymbol{x}=\mathbf{0}
$$
该齐次方程的解为
$$
\boldsymbol{x}=\left(\begin{array}{c}
1 \\
-1
\end{array}\right)
$$
即特征值-1对应的特征向量

上三角矩阵的特征值为其主对角线元素，对于如下矩阵
$$
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 1 & 1 \\
0 & 2 & 2 \\
0 & 0 & 3
\end{array}\right)
$$
根据前面的结论，其特征多项式为
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
1-\lambda & 1 & 1 \\
0 & 2-\lambda & 2 \\
0 & 0 & 3-\lambda
\end{array}\right|=(1-\lambda)(2-\lambda)(3-\lambda)
$$
其特征值为 $1 、 2 、 3$

对于不超过4阶的矩阵，可通过解特征方程得到特征值

但更高次方程的求根存在困难，阿贝尔-鲁菲尼(Abel-Ruffini)定理指出，4次以上的代数方程没有公式解，对于一般的高次方程，方程系数的有限次四则运算、开方运算的结果均不可能是方程的根，因此**高阶矩阵的特征值只能求近似解**

直接求解特征方程并不是一种好的选择，更有效的方法是迭代法

Python中linalg的eig函数实现了计算矩阵的特征值与特征向量的功能，函数的输入为方阵，输出为所有的特征值以及这些特征值对应的特征向量

```python
import numpy as np
A = np.array([[1,0,0],[0,1,0],[0,0,5]])
eigvalues, eigvectors = np.1inalg.eig(A)
print(eigvalues)
print(eigvectors)
```

程序运行结果为

```python
#  特征值
[1. 1. 5.]
# 特征向量
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
```

> 矩阵的迹

下面介绍特征值与矩阵主对角线元素以及行列式的关系，矩阵的`迹`(Trace)定义为其主对角线元素之和
$$
\operatorname{tr}(\boldsymbol{A})=\sum_{i=1}^{n} a_{i i}
$$
对于如下矩阵
$$
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right)
$$
其迹为
$$
\operatorname{tr}(\boldsymbol{A})=a_{11}+a_{22}+a_{33}=1+5+9=15
$$
关于矩阵的迹，有下面的公式成立
$$
\operatorname{tr}(\boldsymbol{A}+\boldsymbol{B})=\operatorname{tr}(\boldsymbol{A})+\operatorname{tr}(\boldsymbol{B})
\qquad \operatorname{tr}(k \boldsymbol{A})= k \cdot \operatorname{tr}(\boldsymbol{A}) 
\qquad \operatorname{tr}(\boldsymbol{A} \boldsymbol{B})=\operatorname{tr}(\boldsymbol{B} \boldsymbol{A})
$$
根据`韦达定理`，下面的$n$次方程
$$
x^{n}+c_{n-1} x^{n-1}+\cdots+c_{1} x+c_{0}=0
$$
所有根之和为
$$
x_{1}+x_{2}+\cdots+x_{n}=-c_{n-1}
$$
所有根的乘积为
$$
x_{1} x_{2} \cdots x_{n}=(-1)^{n} c_{0}
$$
下面计算$n$阶矩阵的特征多项式，首先将行列式写成下面的形式
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21}-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1}-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|
$$
然后按照第1列拆开、变为两个行列式之和
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11} & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|
$$
接下来将这两个行列式均按照第2列拆开，变为4个行列式之和
$$
\begin{aligned}
|\boldsymbol{A}-\lambda I|= & \left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n}-0 \\
a_{21} & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & a_{1 n}-0 \\
a_{21} & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & a_{n n}-\lambda
\end{array}\right| \\
& +\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & a_{1 n}-0 \\
-0 & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & -0 & \cdots & a_{1 n}-0 \\
-0 & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & -0 & \cdots & a_{n n}-\lambda
\end{array}\right|
\end{aligned}
$$
依此类推，将上一步的结果中所有行列式按照下一列拆开，最后可以得到$2^{n}$个行列式，特征值多项式是它们之和

这些行列式的展开结果中，含有$\lambda^{n}$的只有
$$
\left|\begin{array}{ccc}
-\lambda & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & -\lambda
\end{array}\right|
$$
因此特征多项式的首次项就是$(-1)^{n} \lambda^{n}$ ，含有$\lambda^{n-1}$的是下面$n$个行列式
$$
\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & -0 \\
a_{21} & -\lambda & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & -\lambda
\end{array}\right|,\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & -0 \\
-0 & a_{22} & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & -\lambda
\end{array}\right| \cdots
$$
它们之和为
$$
(-1)^{n-1}\left(a_{11}+\cdots+a_{n n}\right) \lambda^{n-1}
$$
因此特征多项式的$\lambda^{n-1}$项系数是$(-1)^{n-1} \sum_{i=1}^{n} a_{i i}$，不含$\lambda$的只有下面一个行列式
$$
\left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|
$$
因此特征多项式中常数项的系数为$|\boldsymbol{A}|$，由此可以得到特征多项式为
$$
(-1)^{n} \lambda^{n}+(-1)^{n-1} \operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+|\boldsymbol{A}|
$$
将特征多项式乘以$(-1)^{n}$可以变为
$$
\lambda^{n}-\operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+(-1)^{n}|\boldsymbol{A}|
$$
因此矩阵所有特征值的和为矩阵的迹
$$
\sum_{i=1}^{n} \lambda_{i}=\operatorname{tr}(\boldsymbol{A})
$$
所有特征值的积为矩阵的行列式
$$
\prod_{i=1}^{n} \lambda_{i}=(-1)^{n}(-1)^{n}|\boldsymbol{A}|=|\boldsymbol{A}|
$$

> 特征值的若干重要性质

1️⃣如果矩阵$A$可逆且$\lambda$为它的特征值，则$\lambda^{-1}$是$A^{-1}$的特征值，根据特征值与特征向量的定义有
$$
\boldsymbol{A x}=\lambda \boldsymbol{x}
$$
上式两边同时左乘$A^{-1}$，可以得到
$$
A^{-1} A x=x=\lambda A^{-1} x
$$
即
$$
\boldsymbol{A}^{-1} x=\lambda^{-1} x
$$
因此$\lambda^{-1}$是$A^{-1}$的特征值，$x$为对应的特征向量

2️⃣如果$\lambda$是矩阵$A$的特征值，则$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，根据特征值与特征向量的定义有
$$
A x=\lambda x
$$
反复利用此式，有

$$
A^{n} x=A^{n-1} A x=A^{n-1} \lambda x=\lambda A^{n-2} A x=\lambda A^{n-2} \lambda x=\cdots=\lambda^{n} x
$$
因此$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，类似地可以证明如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$k \lambda$是$k \boldsymbol{A}$的特征值，对于如下的多项式
$$
f(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x
$$
3️⃣如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$f(\lambda)$是$f(\boldsymbol{A})$的特征值

4️⃣矩阵$A$与$A^{\mathrm{T}}$有相同的特征值，显然
$$
(\boldsymbol{A}-\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-(\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-\lambda I
$$
因此
$$
|A-\lambda I|=\left|A^{\mathrm{T}}-\lambda I\right|
$$


> 特征向量的若干重要性

1️⃣如果向量$x_{1}, \cdots, x_{1}$都是矩阵$A$关于同一个特征值$\lambda$的特征向量，则它们的非$\mathbf{0}$线性组合
$$
\sum_{i=1}^{l} k_{i} x_{i}
$$
也是矩阵$\boldsymbol{A}$关于$\lambda$的特征向量，根据特征值与特征向量的定义有
$$
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} x_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} x_{i}=\sum_{i=1}^{l} k_{i} \lambda x_{i}=\lambda \sum_{i=1}^{l} k_{i} x_{i}
$$
因此$\sum_{i=1}^{1} k_{i} x_{i}$是关于$\lambda$的特征向量

2️⃣矩阵属于不同特征值的特征向量线性无关

假设矩阵$A$的$l$个不同特征值为$\lambda_{1}, \cdots, \lambda_{l}$，它们对应的特征向量为$x_{1}, \cdots, x_{l}$ ，下面用归纳法进行证明

当$l=1$时结论成立，因为$x_{1} \neq \mathbf{0}$，如果$k_{1} x_{1}=\mathbf{0}$，则必定有$k_{1}=0$

假设当$l=m$时结论成立，当$l=m+1$时，有
$$
k_{1} x_{1}+\cdots+k_{m} x_{m}+k_{m+1} x_{m+1}=\mathbf{0}
$$
式子两边左乘$\boldsymbol{A}$，有
$$
\boldsymbol{A}\left(k_{1} x_{1}+\cdots+k_{m} \boldsymbol{x}_{m}+k_{m+1} \boldsymbol{x}_{m+1}\right)=\mathbf{0}
$$
由于
$$
A x_{i}=\lambda_{i} x_{i}
$$
因此
$$
k_{1} \lambda_{1} x_{1}+\cdots+k_{m} \lambda_{m} \boldsymbol{x}_{m}+k_{m+1} \lambda_{m+1} \boldsymbol{x}_{m+1}=\mathbf{0}
$$
将第一个式子乘以$\lambda_{m+1}$，然后减去上式，可得
$$
k_{1}\left(\lambda_{m+1}-\lambda_{1}\right) \boldsymbol{x}_{1}+\cdots+k_{m}\left(\lambda_{m+1}-\lambda_{m}\right) \boldsymbol{x}_{m}=\mathbf{0}
$$
由于$x_{1}, \cdots, x_{m}$线性无关，因此
$$
{i}\left(\lambda_{m+1}-\lambda_{i}\right)=0, i=1, \cdots, m
$$
而$\lambda_{m+1} \neq \lambda_{i}, i=1, \cdots, m$，因此$k_{i}=0, i=1, \cdots, m$，将$k_{i}=0, i=1, \cdots, m$代入第一个式子可得
$$
k_{m+1} x_{m+1}=\mathbf{0}
$$
由于是特征向量，因此$\boldsymbol{x}_{m+1} \neq \mathbf{0}$，故$k_{m+1}=0$，因此$\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{m+1}$线性无关

3️⃣实对称矩阵的特征值均为实数

首先定义矩阵的`共轭`运算，复数矩阵$\boldsymbol{A}$的共轭$\overline{\boldsymbol{A}}$为将其所有元素共轭后形成的矩阵，例如对于下面的矩阵
$$
\boldsymbol{A}=\left(\begin{array}{cc}
1-i & 1 \\
1 & 1+i
\end{array}\right)
$$
其共轭矩阵为
$$
\bar{A}=\left(\begin{array}{cc}
1+i & 1 \\
1 & 1-i
\end{array}\right)
$$
可以证明共轭运算满足下面的性质
$$
\overline{A+B}=\bar{A}+\bar{B} \qquad \overline{k A}=\bar{k} \bar{B} \qquad \overline{A B}=\bar{A} \bar{B} \qquad \overline{(A B)^{T}}=\bar{B}^{T} \bar{A}^{T}
$$
显然对于实矩阵有
$$
\bar{A}=A
$$
假设$\lambda$是实对称矩阵$\boldsymbol{A}$的特征值，$x$是对应的特征向量

由于是实对称矩阵，因此$\bar{A}^{\mathrm{T}}=A$，由于$A x=\lambda x$，因此
$$
\overline{A x}^{\mathrm{T}}=\overline{\lambda x}^{\mathrm{T}}
$$
上式两边同时右乘$\boldsymbol{x}$可以得到
$$
\overline{\boldsymbol{A} \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}} \boldsymbol{x}=\overline{\lambda \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{\lambda}^{\mathrm{T}}} \boldsymbol{x}
$$
从而有
$$
\overline{\boldsymbol{x}}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\overline{\boldsymbol{x}}^{\mathrm{T}} \lambda \boldsymbol{x}=\lambda \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}=\bar{\lambda} \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}
$$


由于$x \neq 0$，因此$\overline{x^T} x>0$，可以得到 $\lambda=\bar{\lambda}$，这意呠着$\lambda$是实数

4️⃣实对称矩阵属于不同特征值的特征向量相互正交

假设$A$为实对称矩阵，$\lambda_{1}, \lambda_{2}$是它的两个不同的特征值，$x_{1}, x_{2}$分别为属于$\lambda_{1}, \lambda_{2}$的特征向量，则有
$$
\begin{array}{l}
\boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{1} \qquad
\boldsymbol{A} \boldsymbol{x}_{2}=\lambda_{2} \boldsymbol{x}_{2}
\end{array}
$$
上式的第一式两边左乘$x_{2}^{\mathrm{T}}$可以得到
$$
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}
$$
而
$$
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\left(\boldsymbol{A} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\lambda_{2} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}
$$
因此有
$$
\lambda_{1} x_{2}^{\mathrm{T}} x_{1}=\lambda_{2} x_{2}^{\mathrm{T}} x_{1}
$$
由于$\lambda_{1} \neq \lambda_{2}$，因此$x_{2}^{\mathrm{T}} x_{1}=0$

**机器学习中使用的矩阵一般为实对称矩阵，因此特征值均为实数，且不同特征值的特征向量正交**

特征值和特征向量被大量用于机器学习算法，典型的包括`主成分分析`(PCA)，`线性判别分析`(LDA)，`流形学习`等降维算法

## 相似变换

通过相似变换可以将一个矩阵变为对角矩阵

> 定义

如果有两个矩阵$A$、$B$以及一个可逆矩阵$P$满足
$$
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{B}
$$
则称矩阵$A$，$B$相似，记为$A \sim B$，上式称为`相似变换`，$P$为`相似变换矩阵`

> 性质

相似具有自反性，矩阵与其自身相似，即$A \sim A$，显然
$$
I^{-1} A I=A
$$
相似具有对称性，如果$A \sim B$，则$B \sim A$，由于
$$
P^{-1} A P=B
$$
上式两边左乘$P$，右乘$P^{-1}$，可以得到
$$
\boldsymbol{A}=\boldsymbol{P B} \boldsymbol{P}^{-1}=\left(\boldsymbol{P}^{-1}\right)^{-1} \boldsymbol{B} \boldsymbol{P}^{-1}
$$
相似具有传递性，如果$A \sim B$且$B \sim C$，则$A \sim C$，由于$A \sim B$且$B \sim C$，因此有
$$
\boldsymbol{P}_{1}^{-1} \boldsymbol{A} \boldsymbol{P}_{1}=\boldsymbol{B}  \qquad

\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{C}
$$
从而有
$$
\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{P}_{2}^{-1}\left(\boldsymbol{P}_{1}^{-1} \boldsymbol{A P} \boldsymbol{P}_{1}\right) \boldsymbol{P}_{2}=\left(\boldsymbol{P}_{1} \boldsymbol{P}_{2}\right)^{-1} A\left(P_{1} P_{2}\right)=C
$$
相似矩阵有相同的特征值，这意昩着相似变换保持矩阵的特征值不变

假设$A \sim B$，则存在可逆矩阵$\boldsymbol{P}$使得
$$
P^{-1} A P=B
$$
因此
$$
\begin{aligned}
|B-\lambda I| & =|P^{-1} A P-\lambda I|=|P^{-1} A P-\lambda P^{-1} I P|=|P^{-1}(A-\lambda I) P| \\
& =|P^{-1}||A-\lambda I||P|=|A-\lambda I|
\end{aligned}
$$
这一性质可用于求解特征值，通过相似变换将矩阵$A$变为对角矩阵或三角矩阵

特征值不变，对角矩阵或三角矩阵的主对角线元素即为$A$的特征值

如果矩阵满足一定的条件，通过相似变换可将其转为对角矩阵

假设$\lambda _1, \cdots , \lambda _n$是$n$阶矩阵$A$的$n$个特佂值，$x_{1}, \cdots, x_{n}$是它们对应的特征向量根据特征值与特征向量的定义有
$$
\left(\begin{array}{lll}
A x_{1} & \cdots & A x_{n}
\end{array}\right)=\left(\lambda_{1} x_{1} \cdots \lambda_{n} x_{n}\right)
$$
如果令矩阵$P=\left(x_{1} \cdots x_{n}\right)$，对角矩阵
$$
\Lambda=\left(\begin{array}{ccc}
\lambda_{1} & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & \lambda_{n}
\end{array}\right)
$$
根据右乘对角矩阵的性质有
$$
\left(\begin{array}{llll}
\boldsymbol{A} \boldsymbol{x}_{1} & \cdots & \boldsymbol{A} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{A P}=\left(\begin{array}{llll}
\lambda_{1} \boldsymbol{x}_{1} & \cdots & \lambda_{n} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{P} \boldsymbol{\Lambda}
$$
即
$$
A P=P A
$$
如果矩阵$P$可逆，那么上式两边同时左乘$P^{-1}$可以得到
$$
\boldsymbol{P}^{-1} A P=P^{-1} P \boldsymbol{\Lambda}=\boldsymbol{\Lambda}
$$
通过这种相似变换可以将矩阵化为对角矩阵，称为矩阵的`相似对角化`
$$
\boldsymbol{P}^{-1} A P=\Lambda
$$
式子意味着可以以矩阵$A$的特征向量为列构造一个矩阵$P$，通过它将矩阵对角化，得到以$A$的特征值为主对角线的对角矩阵$\boldsymbol{\Lambda}$

这种做法成立的条件是矩阵$\boldsymbol{P}$可逆，即矩阵$A$有$n$个线性无关的特征向量

## 正交变换

对于实对称矩阵，我们可以构造一个正交的相似变换将其对角化

> 用归纳法证明实对称矩阵一定可以对角化

这意味着$n$阶实对称矩阵有$n$个线性无关的特征向量，实对称矩阵$A$属于不同特征值的特征向量是相互正交的

如果用`格拉姆-施密特`正交化将同一个特征值的所有特征向量正交化，然后将所有特征向量单位化，可以得到一组标准正交基$\boldsymbol{p}_{1}, \cdots, \boldsymbol{p}_{n}$

以它们为列构造相似变换矩阵$\boldsymbol{P}$，则矩阵$\boldsymbol{P}$是正交矩阵，可通过正交变换(Orthogonal Transformation)将矩阵化为对角阵
$$
P^{\mathrm{T}} A P=\Lambda
$$
由于$P^{T}=P^{-1}$，因此这是一种更特殊的相似变换，实现时只需要对同一个特征值的不同特征向量正交化，然后将所有正交化之后的特征向量进行标准化即可

> 例子

将矩阵通过正交变换化为对角矩阵。对于下面的矩阵
$$
\boldsymbol{A}=\left(\begin{array}{lll}
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right)
$$
其特征多项式为
$$
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
-\lambda & 1 & 1 \\
1 & -\lambda & 1 \\
1 & 1 & -\lambda
\end{array}\right|=-(\lambda-2)(\lambda+1)^{2}
$$
因此其特征值为$2,-1 ，-1$，当$\lambda=2$时，有
$$
(\boldsymbol{A}-2 \boldsymbol{I}) \boldsymbol{x}=\mathbf{0}
$$
解得
$$
\boldsymbol{x}_{1}=\left(\begin{array}{lll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}}
$$
当$\lambda=-1$时，有
$$
(\boldsymbol{I}+\boldsymbol{A}) \boldsymbol{x}=\mathbf{0}
$$
解得
$$
\begin{array}{llll}
x_{2}=\left(\begin{array}{lll}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad x_{3}=\left(\begin{array}{lll}
-1 & 0 & 1
\end{array}\right)^{\mathrm{T}}
\end{array}
$$
正交单位化之后为
$$
\begin{array}{l} 
p_{1}=\frac{1}{\sqrt{3}}\left(\begin{array}{llll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}} \qquad p_{2}=\frac{1}{\sqrt{2}}\left(\begin{array}{ccc}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad p_{3}=\frac{1}{\sqrt{6}}(-1 & -1 & 2)^T
\end{array}
$$
令
$$
\begin{array}{l} 
\boldsymbol{P}=\left(\begin{array}{lll}
p_{1} & \boldsymbol{p}_{2} & \boldsymbol{p}_{3}
\end{array}\right)=\left(\begin{array}{ccc}
\frac{1}{\sqrt{3}} & -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & 0 & \frac{2}{\sqrt{6}}
\end{array}\right)
\end{array}
$$
则有
$$
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\left(\begin{array}{ccc}
2 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & -1
\end{array}\right)
$$
**正交变换具有一个优良的性质，它可以保持矩阵的对称性**

假设$A$是对称矩阵，$P$是正交矩阵，使用下面的正交变换
$$
\boldsymbol{B}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}
$$
$B$仍然是对称矩阵，下面给出证明，显然有
$$
\boldsymbol{B}^{\mathrm{T}}=\left(\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}\left(\boldsymbol{P}^{\mathrm{T}}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\boldsymbol{B}
$$

> 豪斯霍尔德(Householder)变换

特殊的正交变换`豪斯霍尔德`(Householder)变换，它在QR算法以及其他矩阵算法中有重要的应用

首先定义Householder矩阵，为如下形式
$$
P=I-2 w \boldsymbol{w}^{\mathrm{T}}
$$
其中$\boldsymbol{w}$是$n$维非0列向量，且有$\|\boldsymbol{w}\|=1$，显然矩阵$\boldsymbol{P}$是对称矩阵，并且是正交矩阵

由于$P$是对称矩阵，因此有
$$
P^{\mathrm{T}} \boldsymbol{P}=\boldsymbol{P P}=\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)=\boldsymbol{I}-4 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}+4 \boldsymbol{w}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{w}\right) \boldsymbol{w}^{\mathrm{T}}=\boldsymbol{I}
$$
故该矩阵是正交矩阵，通常将$P$写成如下形式
$$
\boldsymbol{P}=\boldsymbol{I}-\frac{\boldsymbol{u} \boldsymbol{u}^{\mathrm{T}}}{H}
$$
其中$u$为任意非$\mathbf{0}$向量且
$$
H=\frac{1}{2}\|\boldsymbol{u}\|^{2}
$$
这里用$H$对$u$进行了标准化

对于$n$维列向量$\boldsymbol{x}$，构造下面的向量
$$
\boldsymbol{u}=\boldsymbol{x} \mp\|x\| \boldsymbol{e}_{1}
$$
其中单位向量$\boldsymbol{e}_{1}=\left(\begin{array}{llll}1 & 0 & \cdots & 0\end{array}\right)^{\mathrm{T}}$

根据$\boldsymbol{u}$用上面的式子构造Householder矩阵$\boldsymbol{P}$，下面将向量$x$左乘$P$的结果
$$
\begin{aligned}
\boldsymbol{P} \boldsymbol{x} & =\left(\boldsymbol{I}-\frac{\boldsymbol{u} u^{\mathrm{T}}}{H}\right) \boldsymbol{x}=\boldsymbol{x}-\frac{\boldsymbol{u}}{H}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)} \\
& =\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{2\|\boldsymbol{x}\|^{2} \mp 2\|x\| x_{1}}=\boldsymbol{x}-\boldsymbol{u}=\pm\|\boldsymbol{x}\| \boldsymbol{e}_{1}
\end{aligned}
$$
其中$x_{1}$是$x$的第1个分量

这表明将列向量$\boldsymbol{x}$左乘$\boldsymbol{P}$之后将零化$\boldsymbol{x}$除第1个元素之外的所有元素，同时保持向量的长度不变，将行向量右乘该矩阵之后有类似的效果

根据这一特性，我们可以构造以Householder矩阵为基础的正交变换，将矩阵转化为类似对角矩阵的形式，零化主对角线之外的元素

对于对称矩阵$\boldsymbol{A}$，使用它的第1列计算向量$u$，按照上面的式子构造Householder矩阵$P$

然后对$A$进行正交变换，这里的正交变换通过将矩阵$A$先左乘$P$，然后右乘$P$实现
$$
\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A P}=\boldsymbol{P A P}
$$
左乘$P$实现$A$的第1列的零化，右乘$P$实现$A$的第1行的零化

下面来看矩阵$P$的构造

如果用$A$的整个第1列作为向量，按照上面的式子构造$P$，虽然可在左乘$P$之后将$A$的第1列除第1个元素之外的所有元素全部零化，但会改变$A$的第1行所有元素的值

接下来在右乘$P$的时候无法保证将$P A$的第1行零化，因此$P$需要保证将$A$的第1列的元素零化的同时确保$A$的第1行的元素不变，以便在右乘$P$的时候将这个行零化

我们可以按照下面的形式构造$P$
$$
\boldsymbol{P}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{1 \times 1} & \mathbf{0}_{1 \times(n-1)} \\
\mathbf{0}_{(n-1) \times 1} & \boldsymbol{P}_{(n-1) \times(n-1)}
\end{array}\right)
$$
其中
$$
\left(\begin{array}{cccc}
p_{22} & p_{23} & \cdots & p_{2 n} \\
p_{32} & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & \vdots \\
p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)
$$
是用$\boldsymbol{A}$的第1列的后面$n-1$个元素按照上面式子构造的

我们将上上式的矩阵作为第1次豪斯霍尔德变换的矩阵，记为$P_{1}$，将$A$左乘$P_{1}$之后可以保证$A$的第1行元素不变，同时将$A$的第1列的后面$n-1$个元素全部变为0

接下来右乘$P_{1}$，由于$A$是对称矩阵，因此第1列和第1行相同，右乘$P_{1}$可以将第1行后面$n-2$个元素全部变为0，并且不改变第1列所有元素的值，因此不会破坏前面的列零化结果
$$
\begin{aligned}
\boldsymbol{A}_{1}=\boldsymbol{P}_{1} \boldsymbol{A} \boldsymbol{P}_{1} & =\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 n} \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right) \\
& =\left(\begin{array}{ccccc}
a_{11} & k & 0 & \cdots & 0 \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)
\end{aligned}
$$
然后进行第2次豪斯霍尔德变换

由于正交变换可以保持矩阵的对称性，因此$\boldsymbol{A}_{1}$仍然是对称矩阵，用$A_{1}$的第2列的后面$n-2$个元素构造$P_{2}$
$$
p_{2}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & & \vdots \\
0 & 0 & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{2 \times 2} & \mathbf{0}_{2 \times(n-2)} \\
\mathbf{0}_{(n-2) \times 2} & \boldsymbol{P}_{(n-2) \times(n-2)}
\end{array}\right)
$$
其中
$$
\left(\begin{array}{ccc}
p_{33} & \cdots & p_{3 n} \\
\vdots & & \vdots \\
p_{n 3} & \cdots & p_{n n}
\end{array}\right)
$$
根据$A_{1}$的第2列的后面$n-2$个元素按照上面的式子构造

经过第2次豪斯霍尔德变换可以将$A_{1}$的第2列的后面$n-3$个元素，第2行的后面$n-3$个元素全部变为0
$$
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{ccccc}
a_{11} & k & 0 & \ldots & 0 \\
k & s & t & \ldots & 0 \\
0 & t & * & \ldots & * \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & * & \ldots & *
\end{array}\right)
$$
依此类推，经过$n-2$次豪斯霍尔德变换，可以将对称矩阵化为如下的对称三对角矩阵(Tridiagonal Matrix)
$$
\left(\begin{array}{ccccc}
b_{11} & b_{12} & \cdots & \cdots & 0 \\
b_{21} & b_{22} & b_{23} & \cdots & 0 \\
0 & b_{32} & b_{33} & \cdots & 0 \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & b_{n, n-1} & b_{n n}
\end{array}\right)
$$
这种矩阵除主对角线、主对角线以上及以下的对角线之外，其他元素均为0

对于一般的$n$阶矩阵$\boldsymbol{A}$，用同样的方法构造豪斯霍尔德矩阵

左乘$P$之后将$A$的第1列后面$n-2$个元素零化，同时保持$\boldsymbol{A}$的第1行元素不变

由于$\boldsymbol{A}$不是对角矩阵，其行和列不相等，因此右乘$\boldsymbol{P}$ 时候无法将其第1行元素零化

同样不能用完整的列构造豪斯霍尔德变换矩 阵，否则右乘该矩阵的时候会破坏前面零化的结果

用和对称矩阵相同的方法构造变换矩阵，第一次豪斯霍尔德变换之后的结果为
$$
A_{1}=P_{1} A P_{1}=\left(\begin{array}{ccccc}
a_{11} & * & * & \cdots & * \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)
$$
第二次豪斯霍尔德变换可以将第2列的后面$n-3$个元素零化，变换之后的结果为
$$
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{cccccc}
a_{11} & * & * & * & \cdots & * \\
k & * & * & * & \cdots & * \\
0 & s & * & * & \cdots & * \\
0 & 0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & * & * & \cdots & *
\end{array}\right)
$$
依次类推，通过$n-2$次豪斯霍尔德变换可以将$A$化为如下形式的`上海森堡矩阵`(upper-Hessenberg form)
$$
\left(\begin{array}{cccccc}
b_{11} & b_{12} & b_{13} & b_{14} & \cdots & b_{1 n} \\
b_{21} & b_{22} & b_{23} & b_{24} & \cdots & b_{2 n} \\
0 & b_{32} & b_{33} & b_{34} & \cdots & b_{3 n} \\
0 & 0 & b_{43} & b_{44} & \cdots & b_{4 n} \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & 0 & 0 & \cdots & b_{n n}
\end{array}\right)
$$
这种矩阵除主对角线及以上，主对角线下面的对角线的元素外，其他的元素均为0

## QR 算法

下面介绍求解高阶矩阵特征值的`QR筫法`，它被誉为20世纪十大算法之一

它依赖于$\mathrm{QR}$分解，对于一个矩阵$A$，$\mathrm{QR}$分解将其化为一个正交矩阵$Q$与一个上三角矩阵$R$的乘积
$$
\boldsymbol{A}=\boldsymbol{Q R}
$$
$\mathrm{QR}$算法是一种迭代法，从矩阵$\boldsymbol{A}_{0}=\boldsymbol{A}$开始，每次构造一个相似变换，将$\boldsymbol{A}_{k-1}$变换为$\boldsymbol{A}_{k}$，最后$A_{k}$收敛到一个上角矩阵，主对角线元素即为其特征值

由于矩阵$A$与$A_{k}$相似，因此它们有相同的特征值，得到了$A_{k}$的特征值即得到了$A$的特征值

问题的核心是如何构造这种相似变换，这借助于$\mathrm{QR}$分解实现，每次迭代时，首先对$\boldsymbol{A}_{k}$进行$\mathrm{QR}$分解
$$
\boldsymbol{A}_{k}=\boldsymbol{Q}_{k} \boldsymbol{R}_{k}
$$
然后用分解结果构造一个新的矩阵$\boldsymbol{A}_{k+1}$，这里将$\mathrm{QR}$分解的结果矩阵交换顺序后相乘
$$
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}
$$
上面两个式子给出了根据当前矩阵构造下一个矩阵的方式，称为$\mathrm{QR}$迭代

$A_{k}$与$A_{k+1}$是相似的，式$A_k$两边同时左乘$Q_{k}^{-1}$可以得到
$$
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k}
$$
将其代人式$A_{k+1}$可得
$$
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k} \boldsymbol{Q}_{k}
$$
由于相似具有传递性，因此$A$与$A_{k}, k=1, \cdots, n$相似

如果$\boldsymbol{A}$满足一定的条件，那么$\mathrm{QR}$迭代所产生的矩阵序列$\left\{\boldsymbol{A}_{k}\right\}$将收敛到一个上三角矩阵，主对角线元素即为$\boldsymbol{A}$的特征值

$Q R$迭代是正交变换，如果$A$是对称矩阵，这种变换将保持对称性，且收敛到上三角矩阵，因此最终会收敛到对角矩阵

对于实对称矩阵$A$，$Q R$迭代代产生的所有正交矩阵$Q_{k}$的乘积的所有列，即为$\boldsymbol{A}$的特征向量，由于
$$
\boldsymbol{A}_{k+1}=Q_{k}^{-1} A_{k} Q_{k}
$$
因此
$$
\begin{aligned}
\Lambda & =A_{k}=Q_{k-1}^{-1} A_{k-1} Q_{k-1}=Q_{k-1}^{-1} Q_{k-2}^{-1} A_{k-2} Q_{k-2} Q_{k-1}=\cdots \\
& =Q_{k-1}^{-1} Q_{k-2}^{-1} \cdots Q_{0}^{-1} A_{0} Q_{0} \cdots Q_{k-2} Q_{k-1}=\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A_{0}\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right) \\
& =\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)
\end{aligned}
$$
如果令
$$
P=Q_{0} \ldots Q_{k-2} Q_{k-1}
$$
则
$$
\Lambda=P^{-1} A P
$$
因此$P$的列为$A$的特征向量
下面来看$\mathrm{QR}$算法的一个例子，对于如下矩阵
$$
A=\left(\begin{array}{ccc}
-149 & -50 & -154 \\
537 & 180 & 546 \\
-27 & -9 & -25
\end{array}\right)
$$
$Q R$算法第1次迭代的结果为
$$
\boldsymbol{A}_{1}=\boldsymbol{R}_{0} \boldsymbol{Q}_{0}=\left(\begin{array}{ccc}
28.8263 & -259.8671 & 773.9292 \\
1.0353 & -8.6686 & 33.1759 \\
-0.5973 & 5.5786 & -14.1578
\end{array}\right)
$$
再经过5次迭代后的结果为
$$
\boldsymbol{A}_{6}=\boldsymbol{R}_{5} \boldsymbol{Q}_{5}=\left(\begin{array}{ccc}
3.0321 & -8.0851 & 804.6651 \\
0.0017 & 0.9931 & 145.5046 \\
-0.0001 & 0.0005 & 1.9749
\end{array}\right)
$$
此时矩阵$A_{6}$已经接近于上三角矩阵，主对角线元素接近于$A$的特征值，事实上，矩阵$A$的特征值为$1,2,3$ 

为了加速收敛，通常采用带位移的$QR$算法(Shifted QR Algorithm)，在第$k$次迭代时，对于设定的移位常数$s_{k}$，迭代公式为
$$
\boldsymbol{A}_{k}-s_{k} I=\boldsymbol{Q}_{k} \boldsymbol{R}_{k} \qquad \boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}+s_{k} \boldsymbol{I}
$$
即先将矩阵$\boldsymbol{A}_{k}$减掉$s_{k} \boldsymbol{I}$后再进行$\mathrm{QR}$分解，在构造$\boldsymbol{A}_{k+1}$时再将$s_{k} \boldsymbol{I}$加回来

按照这种迭代公式，$\boldsymbol{A}_{k}$与$\boldsymbol{A}_{k+1}$也是相似的，根据上式的1式有
$$
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1}\left(\boldsymbol{A}_{k}-s_{k} \boldsymbol{I}\right)
$$
将其代人上式的2式，可得
$$
A_{k+1}=R_{k} Q_{k}+s_{k} I=Q_{k}^{-1}\left(A_{k}-s_{k} I\right) Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}-Q_{k}^{-1} s_{k} I Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}
$$
因此$\boldsymbol{A}_{k}$与$\boldsymbol{A}_{k+1}$相似

> 移位系数$s_{k}$的计算

一种方案是选择$\boldsymbol{A}_{k}$右下角$2 \times 2$子矩阵的两个特征值中接近于$\boldsymbol{A}_{k}$元素$a_{n, n-1}$的那个特征值，以便于使得经过此次$\mathrm{QR}$迭代后$\boldsymbol{A}_{k+1}$的$a_{n, n-1}$变为0

计算此子矩阵的特征值可以通过求解特征方程实现
$$
\left|\begin{array}{cc}
a_{n-1, n-1}-\lambda & a_{n-1, n} \\
a_{n, n-1} & a_{n, n}-\lambda
\end{array}\right|=0
$$
$\boldsymbol{A}_{k+1}$的$a_{n n}$即为$\boldsymbol{A}$的一个特征值，对剩下的$(n-1) \times(n-1)$矩阵继续进行$\mathrm{QR}$算法迭代， 得到所有的特征值

对于一般的矩阵，QR算法的收敛速度可能很慢，如果将矩阵变换成接近于三角阵，则能加快收敛速度

如果是对称矩阵，可先用豪斯霍尔德变换将其化为对称三对角矩阵，然后用$Q R$算法进行达代，收敛到对角矩阵

求解特征值的整个流程为: 对称矩阵$\rightarrow$对称三对角矩阵$\rightarrow$对角矩阵

对于普通矩阵，可用豪斯霍尔德变换将其化为上海森堡矩阵，然后用QR算法进行迭代，收敛到上三角矩阵

整个流程为: 普通矩阵$\rightarrow$上海森堡矩阵$\rightarrow$三角矩阵

## 广义特征值

`广义特征值`(Generalized Eigenvalue)是特征值的推广，定义于两个矩阵之上

对于方阵$A$和$B$，如果存在一个数$\lambda$及非0向量$\boldsymbol{x}$，满足
$$
\boldsymbol{A x}=\lambda \boldsymbol{B x}
$$
则称$\lambda$为广义特征值，$x$为广义特征向量，类似的有特征方程
$$
|A-\lambda B|=0
$$
如果矩阵$B$可逆，对第一个式子左乘$B^{-1}$，则式1的问题等价于下面的特征值问题
$$
B^{-1} \boldsymbol{A x}=\lambda \boldsymbol{x}
$$
广义特征值在机器学习中被广泛使用，包括流形学习、谱聚类算法，以及线性判别分析等

## 瑞利商

方阵$A$和非0向量$x$的`瑞利商`(Rayleigh Quotient)定义为如下比值
$$
R(\boldsymbol{A}, \boldsymbol{x})=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}
$$
根据式子的定义，对于任意的非0实数$k$，有
$$
R(\boldsymbol{A}, k \boldsymbol{x})=R(\boldsymbol{A}, \boldsymbol{x})
$$
即对向量缩放之后其瑞利商不变，瑞利商存在冗余，证明如下
$$
R(\boldsymbol{A}, k \boldsymbol{x})=\frac{(k \boldsymbol{x})^{\mathrm{T}} \boldsymbol{A}(k \boldsymbol{x})}{(k \boldsymbol{x})^{\mathrm{T}}(k \boldsymbol{x})}=\frac{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}
$$
假设$\lambda_{\text {min }}$是矩阵$\boldsymbol{A}$的最小特征值，$\lambda_{\max }$是最大特征值，则有
$$
\lambda_{\min } \leqslant R(\boldsymbol{A}, \boldsymbol{x}) \leqslant \lambda_{\max }
$$
即瑞利商的最小值为矩阵的最小特征值，最大值为矩阵的最大特征值

并且当$x$分别为最小和最大的特征值对应的特征向量的时候取得这两个值，可以用`拉格朗日乘数法`证明

由于将向量乘以非0系数之后瑞利商不变，因此式1极值问题的解不唯一

为此增加一个约束条件以保证解的唯一性，同时简化问题的表述，限定$x$为单位向量，有下面的等式约束
$$
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}=1
$$
增加此约束之后，瑞利商变为
$$
R(\boldsymbol{A}, \boldsymbol{x})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}
$$


## 谱范数与特征值的关系



## 条件数



## 应用——谱归一化与谱正则化

# 二次型

## 基本概念

## 正定二次型与正定矩阵

## 标准型

# 矩阵分解

## 楚列斯基分解

## QR 分解

## 特征值分解

## 奇异值分解