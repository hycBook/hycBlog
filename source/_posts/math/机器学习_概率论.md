---
title: 机器学习_概率论
date: '2022/11/27 18:03:19'
top_img: 'https://pic.hycbook.com/i/hexo/post_imgs/蕾姆4.webp'
cover: 'https://pic.hycbook.com/i/hexo/post_cover/蕾姆4.webp'
categories:
  - math
tags:
  - python
  - 机器学习数学
  - 概率论
mathjax: true
description: 机器学习的数学基础入门知识
swiper_index: 8
---


---

> 写在前面，本系列主要是对下面这本书做的学习笔记

![](https://pic1.zhimg.com/80/v2-1a36e4e5fb49fe46e99ea3dfddaa9e54_720w.webp)


> [常用数学符号的 LaTeX 表示方法](http://www.mohu.org/info/symbols/symbols.htm)
>
> [Markdown 常用数学符号和公式](https://blog.csdn.net/qq_38253837/article/details/109923758)



# 随机事件与概率

概率论同样在机器学习和深度学习中有至关重要的作用。如果将机器学习算法的输入数据和输出数据看作随机变量，则可用概率论的方法对数据进行计算，以此对不确定性进行建模

使用概率模型，可以输出概率值而非确定性的值，这对某些应用是至关重要的

对于某些应用问题，需要对变量之间的概率依赖关系进行建模，也需要概率论的技术，`概率图`模型是典型代表

随机数生成算法，即采样算法，需要以概率论作为理论指导

某些随机算法，如蒙特卡洛算法、遗传算法，同样需要以概率论作为理论或实现依据。

![概率论的知识体系](https://pic.hycbook.com/i//hexo/bk_resources/math/概率论/概率论的知识体系.webp)



## 随机事件与概率

随机事件和概率是概率论中基本的概念，也是理解随机变量的基础

### 随机事件概率

随机事件是可能发生也可能不发生的事件，这种事件每次出现的结果具有不确定性

例如，天气可能是晴天、雨天、阴天；考试分数可能为0与100之间的整数；掷骰子，1到6这几种点数都可能出现

> 以集合论作为工具，给出随机事件的定义

对于一个随机试验，其所有可能结果组成的集合称为`样本空间`记为$\Omega$

随机试验可能的结果称为`样本点`，记为$\omega$，它是样本空间$\Omega$中的元素

* 对于天气，样本空间为$$\Omega=\{\text { 晴天, 阴天, 雨天 }\}$$，每种天气均为一个样本点
* 对于考试成绩，样本空间为$$\Omega=\{0,1, \cdots, 100\}$$，每个分数均为一个样本点
* 对于掷骰子，样本空间为$$\Omega=\{1,2,3,4,5,6\}$$

> 离散事件和连续事件

样本空间可以是有限集，也可以是无限集

对于无限的样本空间，可以是可数集(离散的)，也可以是不可数集(连续的)

`有限样本空间`与`无限可数样本空间`中定义的随机事件称为`离散型`

* **无限可数样本空间**: 抛一枚硬币，如果令$n$为第一次出现正面时所试验的次数，则其取值为$[1,+\infty)$内的整数

  这种情况的样本空间是无限可数集，如果记事件$A_{n}$为直到扔到第$n$次才第一次出现正面朝上，则这样的事件有无穷多个

* **无限不可数样本空间**: 在区间$[0,1]$内随机扔一个点，这个点的取值为此区间内所有实数，是无限不可数集

  此时, 我们无法将样本空间中所有的样本点列出

样本空间$\Omega$ 元素构成的集合称为随机事件，通常用大写斜体字母表示，如记为$A$

显然$\Omega$也是随机本件，它一定会发生，称为必然事件；空集$\varnothing$则不可能发生，称为不可能事件

> 衡量随机事件的可能性

随机事件发生的可能性用概率进行度量，随机事件$A$发生的概率记为$p(A)$，表示此事件发生的可能性，其值满足
$$
0 \leqslant p(A) \leqslant 1
$$
概率值越大则事件越可能发生。一般情况下，假设样本空间中每个样本点发生的概率是相等的(称为`等概率假设`)

因此事件$A$发生的概率是该集合的基数与整个样本空间基数的比值:
$$
p(A)=\frac{|A|}{|\Omega|}
$$
根据定义，所有单个样本点构成的随机事件的概率之和为$\sum_{i=1}^{n} p\left(A_{i}\right)=1$

其中$A_{1}, \cdots, A_{n}$为样本空间中所有单个样本点构成的随机事件

对于有限样本空间中的随机事件，可直接根据集合的基数计算的概率值

* **抛硬币问题**: 记正面朝上为事件$A$，反面朝上为事件$B$，则有$p(A)=p(B)=\frac{1}{2}$

  表示正面朝上和反面朝上的概率是相等的

* **掷骰子问题**: 记事件$A$为出现的点数为 1 , 则有$p(A)=\frac{1}{6}$
  1至6点出现的概率相等，均为$\frac{1}{6}$ 

显然，不可能事件发生的概率为0；必然事件发生的概率为1

> 两个随机事件

对应集合的交运算与并运算，可以定义两个随机事件`同时发生`的概率，以及两个随机事件`至少有一个`发生的概率

🍁两个随机事件$A$和$B$`同时发生`即为它们的交集，记为$A \cap B$，其概率为
$$
p(A \cap B)=\frac{|A \cap B|}{|\Omega|}
$$
以掷骰子为例，记$A$为出现的点数为奇数，$B$为出现的点数不超过3，则有

$$
A \cap B=\{1,3\} \Rightarrow p(A \cap B)=\frac{2}{6}
$$
两个事件同时发生的概率也可以简记为$p(A, B)$ 
$$
|A \cap B| \leqslant|A| 和 |A \cap B| \leqslant|B| \Rightarrow p(A, B) \leqslant \min (p(A), p(B))
$$
可以将两个事件同时发生的概率推广到多个事件
$$
p\left(A_{1}, \cdots, A_{n}\right)=\frac{\left|A_{1} \cap \cdots \cap A_{n}\right|}{|\Omega|}
$$
如果两个随机事件满足$A \cap B=\varnothing$

则称为`互不相容事件`，即两个事件不可能同时发生，因此互不相容事件同时发生的概率为0

🍒两个随机事件$A$和$B$`至少有一个发生`即为它们的并集，记为$A \cup B$
$$
|A \cup B|=|A|+|B|-|A \cap B| \Rightarrow p(A \cup B)=p(A)+p(B)-p(A \cap B)
$$
称为加法公式，两个集合的并集元素数等于它们元素数之和减掉它们重复的部分

因为重复的部分被算了两次，所以有
$$
p(A \cap B) \geqslant 0 \Rightarrow  p(A \cup B) \leqslant p(A)+p(B)
$$
考虑拼骰子问题，定义事件$A$为点数大于或等于2，定义事件$B$为点数小于或等于4
$$
A=\{2,3,4,5,6\} 和 B=\{1,2,3,4\} \Rightarrow A \cup B=\{1,2,3,4,5,6\}
$$
因此有$p(A \cup B)=\frac{6}{6}=1$

如果用加法公式进行计算，则有
$$
p(A \cup B)=p(A)+p(B)-p(A \cap B)=\frac{5}{6}+\frac{4}{6}-\frac{3}{6}=1
$$
如果两个事件$A$和$B$是互不相容的，则加法公式变为
$$
p(A \cup B)=p(A)+p(B)
$$
这一结论可以推广到多个随机事件的情况

> 完备事件组

`完备事件组`是对样本空间的一个划分，显然，对于完备事件组，有
$$
p\left(A_{i}, A_{j}\right)=0, i \neq j \qquad \sum_{i=1}^{n} p\left(A_{i}\right)=1
$$
考虑集合的补运算，对应于对立事件，事件$A$的补集称为它的对立事件，记为$\bar{A}$，即$A$不发生，显然有
$$
p(A)+p(\bar{A})=1
$$
对于掷羖子问题，如果记$A$为出现的点数为偶数，则其对立事件为出现的点数为奇数，因为点数不是偶数就是奇数

考虑无限可数的样本空间: 做一个试验，每次成功的概率为$p$，假设各次试验之间无关，事件$A_{n}$定义为试验$n$次才取得第一次成功，即前面$n-1$次都失败，第$n$次成功，显然，整个样本空间为
$$
A_{1}, A_{2}, \cdots, A_{n}, \cdots
$$
可以得到概率值
$$
p\left(A_{n}\right)=(1-p)^{n-1} p
$$
其中$(1-p)^{n-1}$是前面$n-1$次都失败的概率，$p$是第$n$次时成功的概率，显然有
$$
\sum_{n=1}^{+\infty} p\left(A_{n}\right)=\sum_{n=1}^{+\infty}(1-p)^{n-1} p=p \frac{1}{1-(1-p)}=1
$$

满足所有基本事件的概率之和为1的要求，这里利用了下面的幂级数求和结果
$$
\sum_{n=0}^{+\infty} p^{n}=\frac{1}{1-p}, 0<p<1
$$

> 几何型概率

前面介绍的概率均针对有限的或无限可数的样本空间，下面介绍无限不可数样本空间概率的计算，称为`几何型概率`

几何型概率定义在无限不可数集上，根据积分值(也称为测度值，如长度、面积、体积)定义

事件$A$发生的概率为区域$A$的测度值与$\Omega$测度值的比值，即
$$
p(A)=\frac{s(A)}{s(\Omega)}
$$
其中$s(A)$为集合$A$的测度

这里同样假设落在区域内任意点处的可能性相等，同时保证整个样本空间的概率为1

> 一维几何

在$[0,1]$区间内随机扔一个点，计算该点落在$[0,0.7]$内的概率

假设点的坐标为$x$，落在区间$[0,0.7]$内，即$0 \leqslant x \leqslant 0.7$，由于落在区间中任意点处的可能性相等，因此概率值为
$$
\frac{\text { 区间 }[0,0.7] \text { 的长度 }}{\text { 区间 }[0,1] \text { 的长度 }}=\frac{0.7}{1}=0.7
$$
是短线段与长线段的长度之比

> 二维几何

推广到二维的情况，可用面积计算概率

在单位正方形$0 \leqslant x, y \leqslant 1$内部随机地扔一个点，计算该点落在区域$x \leqslant 0.2, y \leqslant 0.3$内的概率

由于落在任意点处的可能性相等，因此是两个矩形区域的面积之比
$$
p(x \leqslant 0.2, y \leqslant 0.3)=\frac{0.2 \times 0.3}{1 \times 1}=0.06
$$
考虑一个更复杂的例子，在圆周上随机选择两个点，计算这两个点与圆心的连线之间沿着逆时针方向的夹角是锐角的概率

假设点落在圆周上任意位置处的可能性相等

![圆周上两点与圆心的连线之间的夹角](https://pic.hycbook.com/i//hexo/bk_resources/math/概率论/圆周上两点与圆心的连线之间的夹角.webp)

如图所示，假设圆周上的两个点 $A 、 B$ 与圆心的连线和$x$轴正半轴的夹角(按照逆时针方向计算)分别为$\theta_{1}$与$\theta_{2}$

显然有$0 \leqslant \theta_{1}, \theta_{2} \leqslant 2 \pi$，这里采用弧度作为计量单位

两个点与圆心的连线之间的夹角为$\theta=\left|\theta_{1}-\theta_{2}\right|$，夹角为锐角，即$\left|\theta_{1}-\theta_{2}\right| \leqslant \frac{\pi}{2}$，这等价于
$$
-\frac{\pi}{2} \leqslant \theta_{1}-\theta_{2} \leqslant \frac{\pi}{2}
$$
夹角为锐角的区域为直线$\theta_{1}-\theta_{2}=-\frac{\pi}{2}$之下、直线$\theta_{1}-\theta_{2}=\frac{\pi}{2}$之上的区域，因此是夹在这两条直线之间的区域，两点之间逆时针方向夹角为锐角的概率为
$$
\frac{\text { 带状区域的面积 }}{[0,2 \pi] \text { 正方形的面积 }}=\frac{[0,2 \pi] \text { 正方形的面积 }-\left[\frac{\pi}{2}, 2 \pi\right] \text { 正方形的面积 }}{[0,2 \pi] \text { 正方形的面积 }} = \frac{2 \pi \times 2 \pi-\frac{3}{2} \pi \times \frac{3}{2} \pi}{2 \pi \times 2 \pi}=\frac{7}{16}
$$

> 三维几何

对于三维的情况，可用体积值来计算概率值，对于更高维的情况，则借助多重积分的值进行计算

### 条件概率

条件概率主要描述的是多个随机件的概率关系

> 条件概率定义

对于随机事件$A$和$B$，在$A$发生的条件下$B$发生的概率称为(`条件概率`)，记为$p(B \mid A)$

如果事件$A$的概率大于0，则条件概率可按下式计算
$$
p(B \mid A)=\frac{p(A, B)}{p(A)}
$$
根据定义，条件概率是$A$和$B$同时发生的概率与$A$发生的概率的比值

> 条件概率计算的例子

下面用一个例子说明条件概率的计算

对于掷骰子问题，假设事件$A$为点数是奇数，事件$B$为点数小于或等于3，则二者的条件概率为
$$
p(A \mid B)=\frac{p(A, B)}{p(B)}=\frac{p(\{1,3,5\} \cap\{1,2,3\})}{p(\{1,2,3\})}=\frac{2 / 6}{3 / 6}=\frac{2}{3}
$$
类似地，有
$$
p(B \mid A)=\frac{p(A, B)}{p(A)}=\frac{p(\{1,3,5\} \cap\{1,2,3\})}{p(\{1,3,5\})}=\frac{2 / 6}{3 / 6}=\frac{2}{3}
$$
对条件概率公式进行变形，可以得到`乘法公式`
$$
p(A,B)=p(A)p(B|A)=p(B)p(A|B)
$$

> 两个以上的随机事件下的条件概率

将条件概率推广到两个以上的随机事件，对于两组随机事件$A_{1}, \cdots, A_{m}$与$B_{1}, \cdots, B_{n}$, 它们的条件概率定义为
$$
p\left(A_{1}, \cdots, A_{m} \mid B_{1}, \cdots, B_{n}\right)=\frac{p\left(A_{1}, \cdots, A_{m}, B_{1}, \cdots, B_{n}\right)}{p\left(B_{1}, \cdots, B_{n}\right)}
$$
将乘法公式推广到 3 个随机事件，可以得到
$$
p(A, B, C)=p(A, B) p(C \mid A, B)=p(A)(B \mid A) p(C \mid A, B)
$$
需要注意的是，这种分解的顺序不是唯一的，推广到$n$个随机事件，有
$$
p\left(A_{1}, \cdots, A_{n}\right)=p\left(A_{1}\right) p\left(A_{2} \mid A_{1}\right) p\left(A_{3} \mid A_{1}, A_{2}\right) \cdots p\left(A_{n} \mid A_{1}, \cdots, A_{n-1}\right)
$$

> 随机事件的独立性

如果$p(B \mid A)=p(B)$，或$p(A \mid B)=p(A)$，则称随机事件$A$和$B$独立

随机事件独立意味着一个事件是否发生并不影响另外一个事件

如果随机事件$A$和$B$独立，根据式 (5.4), 有
$$
p(A,B) = p(A) p(B)
$$
将上面的定义进行推广，如果$n$个随机事件$A_{i}, i=1, \cdots, n$ 相互独立，则对所有可能的组合$1 \leqslant i<j<k<\cdots \leqslant n$，都有
$$
\begin{aligned}
p\left(A_{i}, A_{j}\right) &=p\left(A_{i}\right) p\left(A_{j}\right) \\
p\left(A_{i}, A_{j}, A_{k}\right) &=p\left(A_{i}\right) p\left(A_{j}\right) p\left(A_{k}\right) \\
& \vdots \\
p\left(A_{1}, \cdots, A_{n}\right) &=\prod_{i=1}^{n} p\left(A_{i}\right)
\end{aligned}
$$

### 全概率公式

> 定义

如果随机事件$A_{1}, \cdots, A_{n}$是一个完备事件组，且$p\left(A_{i}\right)>0, i=1, \cdots, n$，$B$是任意随机事件，则有
$$
p(B)=\sum_{i=1}^{n} p\left(A_{i}\right) p\left(B \mid A_{i}\right)
$$
称为全概率公式，借助于条件概率，全概率公式将对复杂事件的概率计算问题转化为在不同情况下发生的简单事件的概率的求和问题

> 例子

| 箱子  | 红球 | 白球 |
| ----- | ---- | ---- |
| 箱子1 | 6    | 4    |
| 箱子2 | 5    | 5    |
| 箱子3 | 2    | 8    |

先随机抽取一个箱子，然后从中随机抽取一个球，计算抽中红球的概率

令$A_{i}$为抽中第$i$个箱子，$B$为抽中红球

根据全概率公式，有
$$
p(B)=p\left(A_{1}\right) p\left(B \mid A_{1}\right)+p\left(A_{2}\right) p\left(B \mid A_{2}\right)+p\left(A_{3}\right) p\left(B \mid A_{3}\right)=\frac{1}{3} \times \frac{6}{10}+\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{2}{10}=\frac{13}{30}
$$

### 贝叶斯公式

贝叶斯公式由数学家贝叶斯(Bayes)提出，它阐明了随机事件之间的因果概率关系，根据条件概率的定义，有
$$
p(A,B)=p(A)p(B|A)=p(B)p(A|B)
$$
变形可得`贝叶斯公式`
$$
p(A, B)=p(A) p(B \mid A)=p(B) p(A \mid B)
$$

> 先后验和似然函数

它描述了先验概率和后验概率之间的关系，如果事件$A$是因，事件件$B$是果

* **先验概率**: 称$p(A)$为`先验概率`(Prior Probability)，意为事先已经知道其值
* **后验概率**: $p(A \mid B)$ 称为`后验概率`(Posterior Probability)，意为事后才知道其值
* **似然函数**: 条件概率$p(B \mid A)$则称为`似然函数`

先验概率是根据以往经验和分析得到的概率，在随机事件发生之前已经知道，是**原因**发生的概率

后验概率是根据**结果**信息所计算出的导致该结果的原因所出现的概率

后验概率用于在事情已经发生的条件下，分析使得这件事情发生的原因概率

根据贝叶斯公式可以实现这种因果推理，这在机器学习中是常用的

> 全概率公式与贝叶斯公式

如果事件$A_{1}, \cdots, A_{n}$构成一个完备事件组，且$p\left(A_{i}\right)>0, p(B)>0$，根据全概率公式与贝叶斯公式，可以得到
$$
p\left(A_{m} \mid B\right)=\frac{p\left(A_{m}\right) p\left(B \mid A_{m}\right)}{p(B)}=\frac{p\left(A_{m}\right) p\left(B \mid A_{m}\right)}{\sum_{i=1}^{n} p\left(A_{i}\right) p\left(B \mid A_{i}\right)}
$$

> 例子

| 箱子  | 红球 | 黑球 |
| ----- | ---- | ---- |
| 箱子1 | 5    | 5    |
| 箱子2 | 7    | 3    |
| 箱子3 | 9    | 1    |

首先随机地抽取一个箱子，然后从中随机抽取一个球，如果抽中的是红球，计算这个球来自每个箱子的概率

令$A_{i}, i=1,2,3$表示抽中第$i$个箱子，$B$表示抽中红球

则这个红球来自第1个箱子的概率为
$$
p\left(A_{1} \mid B\right)=\frac{\frac{1}{3} \times \frac{5}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{5}{21}
$$
来自第2个箱子的概率为
$$
p\left(A_{2} \mid B\right)=\frac{\frac{1}{3} \times \frac{7}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{7}{21}
$$
来自第3个箱子的概率为
$$
p\left(A_{3} \mid B\right)=\frac{\frac{1}{3} \times \frac{9}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{9}{21}
$$

### 条件独立

> 定义

将随机事件的独立性与条件概率相结合，可以得到条件独立的概念

如果随机事件$A, B, C$满足$p(A \mid B, C)=p(A \mid C)$，则称$A$和$B$关于事件$C$条件独立

直观含义是在$C$发生的情况下，$B$是否发生并不影响$A$，它们之间相互独立，这意味着事件$C$的发生使得$A$和$B$相互独立
$$
p(A, B \mid C)=p(A \mid B, C) p(B \mid C)=p(A \mid C) p(B \mid C)
$$
$A$和$B$关于$C$条件独立可以记为$A \perp B \mid C$，条件独立的概念在概率图模型中被广泛使用

## 随机变是

普通的变量只允许取值可变, 随机变量 (Random Variable ) 是取值可变并且取每个值都有一 个概率的变量。从另外一个角度来看, 随机变量是用于表示随机试验结果的变量D随机变量通常 用大写斜体字母表示, 如 $X^{2}$ 。) 随机变量的取值一般用小写斜体字母表示, 如 $x_{i}$ 。
随机变量可分为离散型和连续型两种。前者的取值集合为有限集或者无限可数集，对应 5.1.1 节介绍的离散型随机事件; 后者的取值集合为无限不可数集, 对应 $5.1 .1$ 节介绍的几何型随机 事件。

### 离散型随机变量

离散型随机变量的取值集合是离散集合, 为有限集或无限可数集, 可以将所有取值列举出 来。例如，郑股子出现的点数即为离散型随机变量，取值集合为 1 和 6 之间的整数。
描述离散型随机变量取值概率的是概率质量函数 (Probability Mass Function, PMF )。概率质 量函数由随机变量取每个值的概率
$$
p\left(X=x_{i}\right)=p\left(x_{i}\right)
$$
排列组成。后面会将 $p\left(X=x_{i}\right)$ 简记为 $p\left(x_{i}\right)$ 。这里的 “质量” 与物理学中的质量相对应, 可看作 是一些有质量的质点，概率质量函数值对应这些点的质量。
