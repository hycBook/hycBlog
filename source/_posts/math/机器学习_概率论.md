---
title: 机器学习_概率论
date: '2022/11/27 18:03:19'
top_img: 'https://pic.hycbook.com/i/hexo/post_imgs/蕾姆4.webp'
cover: 'https://pic.hycbook.com/i/hexo/post_cover/蕾姆4.webp'
categories:
  - math
tags:
  - python
  - 机器学习数学
  - 概率论
mathjax: true
description: 机器学习的数学基础入门知识
swiper_index: 8
---


---

> 写在前面，本系列主要是对下面这本书做的学习笔记

![](https://pic1.zhimg.com/80/v2-1a36e4e5fb49fe46e99ea3dfddaa9e54_720w.webp)


> [常用数学符号的 LaTeX 表示方法](http://www.mohu.org/info/symbols/symbols.htm)
>
> [Markdown 常用数学符号和公式](https://blog.csdn.net/qq_38253837/article/details/109923758)



# 随机事件与概率

概率论同样在机器学习和深度学习中有至关重要的作用。如果将机器学习算法的输入数据和输出数据看作随机变量，则可用概率论的方法对数据进行计算，以此对不确定性进行建模

使用概率模型，可以输出概率值而非确定性的值，这对某些应用是至关重要的

对于某些应用问题，需要对变量之间的概率依赖关系进行建模，也需要概率论的技术，`概率图`模型是典型代表

随机数生成算法，即采样算法，需要以概率论作为理论指导

某些随机算法，如蒙特卡洛算法、遗传算法，同样需要以概率论作为理论或实现依据。

![概率论的知识体系](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_概率论/概率论的知识体系.webp)

随机事件和概率是概率论中基本的概念，也是理解随机变量的基础

## 随机事件概率

随机事件是可能发生也可能不发生的事件，这种事件每次出现的结果具有不确定性

例如，天气可能是晴天、雨天、阴天；考试分数可能为0与100之间的整数；掷骰子，1到6这几种点数都可能出现

> 以集合论作为工具，给出随机事件的定义

对于一个随机试验，其所有可能结果组成的集合称为`样本空间`记为$\Omega$

随机试验可能的结果称为`样本点`，记为$\omega$，它是样本空间$\Omega$中的元素

* 对于天气，样本空间为$$\Omega=\{\text { 晴天, 阴天, 雨天 }\}$$，每种天气均为一个样本点
* 对于考试成绩，样本空间为$$\Omega=\{0,1, \cdots, 100\}$$，每个分数均为一个样本点
* 对于掷骰子，样本空间为$$\Omega=\{1,2,3,4,5,6\}$$

> 离散事件和连续事件

样本空间可以是有限集，也可以是无限集

对于无限的样本空间，可以是可数集(离散的)，也可以是不可数集(连续的)

`有限样本空间`与`无限可数样本空间`中定义的随机事件称为`离散型`

* **无限可数样本空间**: 抛一枚硬币，如果令$n$为第一次出现正面时所试验的次数，则其取值为$[1,+\infty)$内的整数

  这种情况的样本空间是无限可数集，如果记事件$A_{n}$为直到扔到第$n$次才第一次出现正面朝上，则这样的事件有无穷多个

* **无限不可数样本空间**: 在区间$[0,1]$内随机扔一个点，这个点的取值为此区间内所有实数，是无限不可数集

  此时, 我们无法将样本空间中所有的样本点列出

样本空间$\Omega$ 元素构成的集合称为随机事件，通常用大写斜体字母表示，如记为$A$

显然$\Omega$也是随机本件，它一定会发生，称为必然事件；空集$\varnothing$则不可能发生，称为不可能事件

> 衡量随机事件的可能性

随机事件发生的可能性用概率进行度量，随机事件$A$发生的概率记为$p(A)$，表示此事件发生的可能性，其值满足
$$
0 \leqslant p(A) \leqslant 1
$$
概率值越大则事件越可能发生。一般情况下，假设样本空间中每个样本点发生的概率是相等的(称为`等概率假设`)

因此事件$A$发生的概率是该集合的基数与整个样本空间基数的比值:
$$
p(A)=\frac{|A|}{|\Omega|}
$$
根据定义，所有单个样本点构成的随机事件的概率之和为$$\sum_{i=1}^{n} p\left(A_{i}\right)=1$$

其中$$A_{1}, \cdots, A_{n}$$为样本空间中所有单个样本点构成的随机事件

对于有限样本空间中的随机事件，可直接根据集合的基数计算的概率值

* **抛硬币问题**: 记正面朝上为事件$A$，反面朝上为事件$B$，则有$p(A)=p(B)=\frac{1}{2}$

  表示正面朝上和反面朝上的概率是相等的

* **掷骰子问题**: 记事件$A$为出现的点数为 1 , 则有$p(A)=\frac{1}{6}$
  1至6点出现的概率相等，均为$\frac{1}{6}$ 

显然，不可能事件发生的概率为0；必然事件发生的概率为1

> 两个随机事件

对应集合的交运算与并运算，可以定义两个随机事件`同时发生`的概率，以及两个随机事件`至少有一个`发生的概率

🍁两个随机事件$A$和$B$`同时发生`即为它们的交集，记为$A \cap B$，其概率为
$$
p(A \cap B)=\frac{|A \cap B|}{|\Omega|}
$$
以掷骰子为例，记$A$为出现的点数为奇数，$B$为出现的点数不超过3，则有

$$
A \cap B=\{1,3\} \Rightarrow p(A \cap B)=\frac{2}{6}
$$
两个事件同时发生的概率也可以简记为$p(A, B)$ 
$$
|A \cap B| \leqslant|A| 和 |A \cap B| \leqslant|B| \Rightarrow p(A, B) \leqslant \min (p(A), p(B))
$$
可以将两个事件同时发生的概率推广到多个事件
$$
p\left(A_{1}, \cdots, A_{n}\right)=\frac{\left|A_{1} \cap \cdots \cap A_{n}\right|}{|\Omega|}
$$
如果两个随机事件满足$A \cap B=\varnothing$

则称为`互不相容事件`，即两个事件不可能同时发生，因此互不相容事件同时发生的概率为0

🍒两个随机事件$A$和$B$`至少有一个发生`即为它们的并集，记为$A \cup B$
$$
|A \cup B|=|A|+|B|-|A \cap B| \Rightarrow p(A \cup B)=p(A)+p(B)-p(A \cap B)
$$
称为加法公式，两个集合的并集元素数等于它们元素数之和减掉它们重复的部分

因为重复的部分被算了两次，所以有
$$
p(A \cap B) \geqslant 0 \Rightarrow  p(A \cup B) \leqslant p(A)+p(B)
$$
考虑拼骰子问题，定义事件$A$为点数大于或等于2，定义事件$B$为点数小于或等于4
$$
A=\{2,3,4,5,6\} 和 B=\{1,2,3,4\} \Rightarrow A \cup B=\{1,2,3,4,5,6\}
$$
因此有$p(A \cup B)=\frac{6}{6}=1$

如果用加法公式进行计算，则有
$$
p(A \cup B)=p(A)+p(B)-p(A \cap B)=\frac{5}{6}+\frac{4}{6}-\frac{3}{6}=1
$$
如果两个事件$A$和$B$是互不相容的，则加法公式变为
$$
p(A \cup B)=p(A)+p(B)
$$
这一结论可以推广到多个随机事件的情况

> 完备事件组

`完备事件组`是对样本空间的一个划分，显然，对于完备事件组，有
$$
p\left(A_{i}, A_{j}\right)=0, i \neq j \qquad \sum_{i=1}^{n} p\left(A_{i}\right)=1
$$
考虑集合的补运算，对应于对立事件，事件$A$的补集称为它的对立事件，记为$\bar{A}$，即$A$不发生，显然有
$$
p(A)+p(\bar{A})=1
$$
对于掷羖子问题，如果记$A$为出现的点数为偶数，则其对立事件为出现的点数为奇数，因为点数不是偶数就是奇数

考虑无限可数的样本空间: 做一个试验，每次成功的概率为$p$，假设各次试验之间无关，事件$A_{n}$定义为试验$n$次才取得第一次成功，即前面$n-1$次都失败，第$n$次成功，显然，整个样本空间为
$$
A_{1}, A_{2}, \cdots, A_{n}, \cdots
$$
可以得到概率值
$$
p\left(A_{n}\right)=(1-p)^{n-1} p
$$
其中$(1-p)^{n-1}$是前面$n-1$次都失败的概率，$p$是第$n$次时成功的概率，显然有
$$
\sum_{n=1}^{+\infty} p\left(A_{n}\right)=\sum_{n=1}^{+\infty}(1-p)^{n-1} p=p \frac{1}{1-(1-p)}=1
$$

满足所有基本事件的概率之和为1的要求，这里利用了下面的幂级数求和结果
$$
\sum_{n=0}^{+\infty} p^{n}=\frac{1}{1-p}, 0<p<1
$$

> 几何型概率

前面介绍的概率均针对有限的或无限可数的样本空间，下面介绍无限不可数样本空间概率的计算，称为`几何型概率`

几何型概率定义在无限不可数集上，根据积分值(也称为测度值，如长度、面积、体积)定义

事件$A$发生的概率为区域$A$的测度值与$\Omega$测度值的比值，即
$$
p(A)=\frac{s(A)}{s(\Omega)}
$$
其中$s(A)$为集合$A$的测度

这里同样假设落在区域内任意点处的可能性相等，同时保证整个样本空间的概率为1

> 一维几何

在$[0,1]$区间内随机扔一个点，计算该点落在$[0,0.7]$内的概率

假设点的坐标为$x$，落在区间$[0,0.7]$内，即$0 \leqslant x \leqslant 0.7$，由于落在区间中任意点处的可能性相等，因此概率值为
$$
\frac{\text { 区间 }[0,0.7] \text { 的长度 }}{\text { 区间 }[0,1] \text { 的长度 }}=\frac{0.7}{1}=0.7
$$
是短线段与长线段的长度之比

> 二维几何

推广到二维的情况，可用面积计算概率

在单位正方形$0 \leqslant x, y \leqslant 1$内部随机地扔一个点，计算该点落在区域$x \leqslant 0.2, y \leqslant 0.3$内的概率

由于落在任意点处的可能性相等，因此是两个矩形区域的面积之比
$$
p(x \leqslant 0.2, y \leqslant 0.3)=\frac{0.2 \times 0.3}{1 \times 1}=0.06
$$
考虑一个更复杂的例子，在圆周上随机选择两个点，计算这两个点与圆心的连线之间沿着逆时针方向的夹角是锐角的概率

假设点落在圆周上任意位置处的可能性相等

![圆周上两点与圆心的连线之间的夹角](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_概率论/圆周上两点与圆心的连线之间的夹角.webp)

如图所示，假设圆周上的两个点 $A 、 B$ 与圆心的连线和$x$轴正半轴的夹角(按照逆时针方向计算)分别为$$\theta_{1}$$与$$\theta_{2}$$

显然有$$0 \leqslant \theta_{1}, \theta_{2} \leqslant 2 \pi$$，这里采用弧度作为计量单位

两个点与圆心的连线之间的夹角为$$\theta=\left|\theta_{1}-\theta_{2}\right|$$，夹角为锐角，即$$\left|\theta_{1}-\theta_{2}\right| \leqslant \frac{\pi}{2}$$，这等价于
$$
-\frac{\pi}{2} \leqslant \theta_{1}-\theta_{2} \leqslant \frac{\pi}{2}
$$
夹角为锐角的区域为直线$$\theta_{1}-\theta_{2}=-\frac{\pi}{2}$$之下、直线$$\theta_{1}-\theta_{2}=\frac{\pi}{2}$$之上的区域，因此是夹在这两条直线之间的区域，两点之间逆时针方向夹角为锐角的概率为
$$
\frac{\text { 带状区域的面积 }}{[0,2 \pi] \text { 正方形的面积 }}=\frac{[0,2 \pi] \text { 正方形的面积 }-\left[\frac{\pi}{2}, 2 \pi\right] \text { 正方形的面积 }}{[0,2 \pi] \text { 正方形的面积 }} = \frac{2 \pi \times 2 \pi-\frac{3}{2} \pi \times \frac{3}{2} \pi}{2 \pi \times 2 \pi}=\frac{7}{16}
$$

> 三维几何

对于三维的情况，可用体积值来计算概率值，对于更高维的情况，则借助多重积分的值进行计算

## 条件概率

条件概率主要描述的是多个随机件的概率关系

> 条件概率定义

对于随机事件$A$和$B$，在$A$发生的条件下$B$发生的概率称为(`条件概率`)，记为$p(B \mid A)$

如果事件$A$的概率大于0，则条件概率可按下式计算
$$
p(B \mid A)=\frac{p(A, B)}{p(A)}
$$
根据定义，条件概率是$A$和$B$同时发生的概率与$A$发生的概率的比值

> 条件概率计算的例子

下面用一个例子说明条件概率的计算

对于掷骰子问题，假设事件$A$为点数是奇数，事件$B$为点数小于或等于3，则二者的条件概率为
$$
p(A \mid B)=\frac{p(A, B)}{p(B)}=\frac{p(\{1,3,5\} \cap\{1,2,3\})}{p(\{1,2,3\})}=\frac{2 / 6}{3 / 6}=\frac{2}{3}
$$
类似地，有
$$
p(B \mid A)=\frac{p(A, B)}{p(A)}=\frac{p(\{1,3,5\} \cap\{1,2,3\})}{p(\{1,3,5\})}=\frac{2 / 6}{3 / 6}=\frac{2}{3}
$$
对条件概率公式进行变形，可以得到`乘法公式`
$$
p(A,B)=p(A)p(B|A)=p(B)p(A|B)
$$

> 两个以上的随机事件下的条件概率

将条件概率推广到两个以上的随机事件，对于两组随机事件$$A_{1}, \cdots, A_{m}$$与$$B_{1}, \cdots, B_{n}$$, 它们的条件概率定义为
$$
p\left(A_{1}, \cdots, A_{m} \mid B_{1}, \cdots, B_{n}\right)=\frac{p\left(A_{1}, \cdots, A_{m}, B_{1}, \cdots, B_{n}\right)}{p\left(B_{1}, \cdots, B_{n}\right)}
$$
将乘法公式推广到 3 个随机事件，可以得到
$$
p(A, B, C)=p(A, B) p(C \mid A, B)=p(A)(B \mid A) p(C \mid A, B)
$$
需要注意的是，这种分解的顺序不是唯一的，推广到$n$个随机事件，有
$$
p\left(A_{1}, \cdots, A_{n}\right)=p\left(A_{1}\right) p\left(A_{2} \mid A_{1}\right) p\left(A_{3} \mid A_{1}, A_{2}\right) \cdots p\left(A_{n} \mid A_{1}, \cdots, A_{n-1}\right)
$$

> 随机事件的独立性

如果$p(B \mid A)=p(B)$，或$p(A \mid B)=p(A)$，则称随机事件$A$和$B$独立

随机事件独立意味着一个事件是否发生并不影响另外一个事件

如果随机事件$A$和$B$独立，根据式 (5.4), 有
$$
p(A,B) = p(A) p(B)
$$
将上面的定义进行推广，如果$n$个随机事件$A_{i}, i=1, \cdots, n$ 相互独立，则对所有可能的组合$1 \leqslant i<j<k<\cdots \leqslant n$，都有
$$
\begin{aligned}
p\left(A_{i}, A_{j}\right) &=p\left(A_{i}\right) p\left(A_{j}\right) \\
p\left(A_{i}, A_{j}, A_{k}\right) &=p\left(A_{i}\right) p\left(A_{j}\right) p\left(A_{k}\right) \\
& \vdots \\
p\left(A_{1}, \cdots, A_{n}\right) &=\prod_{i=1}^{n} p\left(A_{i}\right)
\end{aligned}
$$

## 全概率公式

> 定义

如果随机事件$$A_{1}, \cdots, A_{n}$$是一个完备事件组，且$$p\left(A_{i}\right)>0, i=1, \cdots, n$$，$$B$$是任意随机事件，则有
$$
p(B)=\sum_{i=1}^{n} p\left(A_{i}\right) p\left(B \mid A_{i}\right)
$$
称为全概率公式，借助于条件概率，全概率公式将对复杂事件的概率计算问题转化为在不同情况下发生的简单事件的概率的求和问题

> 例子

| 箱子  | 红球 | 白球 |
| ----- | ---- | ---- |
| 箱子1 | 6    | 4    |
| 箱子2 | 5    | 5    |
| 箱子3 | 2    | 8    |

先随机抽取一个箱子，然后从中随机抽取一个球，计算抽中红球的概率

令$A_{i}$为抽中第$i$个箱子，$B$为抽中红球

根据全概率公式，有
$$
p(B)=p\left(A_{1}\right) p\left(B \mid A_{1}\right)+p\left(A_{2}\right) p\left(B \mid A_{2}\right)+p\left(A_{3}\right) p\left(B \mid A_{3}\right)=\frac{1}{3} \times \frac{6}{10}+\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{2}{10}=\frac{13}{30}
$$

## 贝叶斯公式

贝叶斯公式由数学家贝叶斯(Bayes)提出，它阐明了随机事件之间的因果概率关系，根据条件概率的定义，有
$$
p(A,B)=p(A)p(B|A)=p(B)p(A|B)
$$
变形可得`贝叶斯公式`
$$
p(A, B)=p(A) p(B \mid A)=p(B) p(A \mid B)
$$

> 先后验和似然函数

它描述了先验概率和后验概率之间的关系，如果事件$A$是因，事件件$B$是果

* **先验概率**: 称$p(A)$为`先验概率`(Prior Probability)，意为事先已经知道其值
* **后验概率**: $p(A \mid B)$ 称为`后验概率`(Posterior Probability)，意为事后才知道其值
* **似然函数**: 条件概率$p(B \mid A)$则称为`似然函数`

先验概率是根据以往经验和分析得到的概率，在随机事件发生之前已经知道，是**原因**发生的概率

后验概率是根据**结果**信息所计算出的导致该结果的原因所出现的概率

后验概率用于在事情已经发生的条件下，分析使得这件事情发生的原因概率

根据贝叶斯公式可以实现这种因果推理，这在机器学习中是常用的

> 全概率公式与贝叶斯公式

如果事件$$A_{1}, \cdots, A_{n}$$构成一个完备事件组，且$$p\left(A_{i}\right)>0, p(B)>0$$，根据全概率公式与贝叶斯公式，可以得到
$$
p\left(A_{m} \mid B\right)=\frac{p\left(A_{m}\right) p\left(B \mid A_{m}\right)}{p(B)}=\frac{p\left(A_{m}\right) p\left(B \mid A_{m}\right)}{\sum_{i=1}^{n} p\left(A_{i}\right) p\left(B \mid A_{i}\right)}
$$

> 例子

| 箱子  | 红球 | 黑球 |
| ----- | ---- | ---- |
| 箱子1 | 5    | 5    |
| 箱子2 | 7    | 3    |
| 箱子3 | 9    | 1    |

首先随机地抽取一个箱子，然后从中随机抽取一个球，如果抽中的是红球，计算这个球来自每个箱子的概率

令$A_{i}, i=1,2,3$表示抽中第$i$个箱子，$B$表示抽中红球

则这个红球来自第1个箱子的概率为
$$
p\left(A_{1} \mid B\right)=\frac{\frac{1}{3} \times \frac{5}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{5}{21}
$$
来自第2个箱子的概率为
$$
p\left(A_{2} \mid B\right)=\frac{\frac{1}{3} \times \frac{7}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{7}{21}
$$
来自第3个箱子的概率为
$$
p\left(A_{3} \mid B\right)=\frac{\frac{1}{3} \times \frac{9}{10}}{\frac{1}{3} \times \frac{5}{10}+\frac{1}{3} \times \frac{7}{10}+\frac{1}{3} \times \frac{9}{10}}=\frac{9}{21}
$$

## 条件独立

> 定义

将随机事件的独立性与条件概率相结合，可以得到条件独立的概念

如果随机事件$A, B, C$满足$p(A \mid B, C)=p(A \mid C)$，则称$A$和$B$关于事件$C$条件独立

直观含义是在$C$发生的情况下，$B$是否发生并不影响$A$，它们之间相互独立，这意味着事件$C$的发生使得$A$和$B$相互独立
$$
p(A, B \mid C)=p(A \mid B, C) p(B \mid C)=p(A \mid C) p(B \mid C)
$$
$A$和$B$关于$C$条件独立可以记为$A \perp B \mid C$，条件独立的概念在概率图模型中被广泛使用

# 随机变量

普通的变量只允许取值可变，随机变量(Random Variable)是取值可变并且取每个值都有一 个概率的变量

从另外一个角度来看，随机变量是用于表示随机试验结果的变量

随机变量通常用大写斜体字母表示，如$X$， 随机变量的取值一般用小写斜体字母表示，如$x_{i}$，随机变量可分为`离散型`和`连续型`两种

* **离散型**: 取值集合为有限集或者无限可数集，对应离散型随机事件
* **连续型**: 取值集合为无限不可数集, 对应几何型随机事件

## 离散型随机变量

离散型随机变量的取值集合是离散集合，为有限集或无限可数集，可以将所有取值列举出来

例如，掷骰子出现的点数即为离散型随机变量，取值集合为1和6之间的整数

> 概率质量函数(Probability Mass Function, PMF)

描述离散型随机变量取值概率的是`概率质量函数`，函数由随机变量取每个值的概率
$$
p\left(X=x_{i}\right)=p\left(x_{i}\right)
$$
排列组成，可以将$$p\left(X=x_{i}\right)$$简记为 $p\left(x_{i}\right)$ 

这里的**质量**与物理学中的质量相对应，可看作是一些有质量的质点，概率质量函数值对应这些点的质量

概率质量函数必须满足以下约束条件
$$
p\left(x_{i}\right) \geqslant 0 \quad \sum_{i} p\left(x_{i}\right)=1
$$
下表是一个离散型随机变量的概率质量函数，其取值集合为$\{1,2,3,4\}$

| 随机变量取值 | 概率质量函数值 |
| ------------ | -------------- |
| 1            | 0.1            |
| 2            | 0.5            |
| 3            | 0.2            |
| 4            | 0.2            |

离散型随机变量的取值可能为无限可数集，此时要保证下面的级数收敛，并且其值为1
$$
\sum_{i=1}^{+\infty} p\left(x_{i}\right)=1
$$

> 累积分布函数(Cumulative Distribution Function, CDF)

`累积分布函数`也称为分布函数，是概率质量函数的累加，定义为
$$
p\left(X \leqslant x_{j}\right)=\sum_{i=1}^{j} p\left(x_{i}\right)
$$
上表所示的随机变量，其累积分布函数如表所示

| 随机变量取值 | 累积分布函数值 |
| ------------ | -------------- |
| 1            | 0.1            |
| 2            | 0.6            |
| 3            | 0.8            |
| 4            | 1.0            |

## 连续型随机变量

几何型随机事件对应的是连续型随机变量，连续型随机变量的取值集合为无限不可数集

一般为实数轴上的一个或多个区间，或者是整个实数集$\mathbb{R}$

例如，我们要观测每个时间点的温度，是一个连续值，为连续型随机变量

考虑计算一维几何型随机事件概率的例子，随机点落在$[0, x]$区间内的概率就是$x$，这是$X \leqslant x$这一随机事件的概率
$$
p(X \leqslant x)=x
$$
其中$X$是一个连续型随机变量，是随机点的一维坐标，其允许的取值范围为$[0,1]$

> 累积分布函数

对上面的函数进行扩充，使得$X$的取值范围为整个实数集$\mathbb{R}$，可以得到如下的函数
$$
p(X \leqslant x)=\left\{\begin{array}{ll}
0, & x<0 \\
x, & 0 \leqslant x \leqslant 1 \\
1, & x>1
\end{array} \right.
$$
该函数称为累积分布函数

> 概率密度函数

对累积分布函数进行求导，即可得到概率密度函数， 表示连续型随机变量在每一个取值点处的**概率密度值**

除去0和1这两点，上面的累积分布函数是可导的，其导数为
$$
p^{\prime}(x)=\left\{\begin{array}{ll}
0, & x<0 \\
1, & 0 \leqslant x \leqslant 1 \\
0, & x>1
\end{array}\right.
$$
此函数在区间$[0,1]$内所有点处的取值相等，这意味着点$x$落在$[0,1]$内所有点处的可能性相等

> 概率密度函数与累积分布函数的定义

`概率密度函数`(Probability Density Function, PDF)定义了连续型随机变量的概率分布

其函数值表示随机变量取该值的可能性(注意，不是概率)

概率密度函数必须满足如下约束条件
$$
f(x) \geqslant 0 \qquad \int_{-\infty}^{+\infty} f(x) \mathrm{d} x=1
$$
这可以看作是离散型随机变量的推广，积分值为1对应取各个值的概率之和为1

连续型随机变量落在某一点处的概率值为0

落在某一区间内的概率值为概率密度函数在该区间内的定积分
$$
p\left(x_{1} \leqslant X \leqslant x_{2}\right)=\int_{x_{1}}^{x_{2}} f(x) \mathrm{d} x=F\left(x_{2}\right)-F\left(x_{1}\right)
$$
其中$F(x)$是$f(x)$的一个原函数，也称为`分布函数`，近似地有
$$
p(x \leqslant X \leqslant x+\Delta x) \approx f(\xi) \Delta x
$$
其中$\xi$是$[x, x+\Delta x]$内的一个点

概率密度函数中的**密度**可类比物理学中的密度，概率质量函数在每一点处的值为随机变量取该值的概率

而概率密度函数在每一点处的值并不是概率值，只有区间上的积分值才是随机变量落入此区间的概率

随机变量$X$服从概率分布$f(x)$，一般可以简记为
$$
X \sim f(x)
$$
对于连续型随机变量，分布函数是概率密度函数的变上限积分，定义为
$$
F(y)=p(X \leqslant y)=\int_{-\infty}^{y} f(x) \mathrm{d} x
$$
显然这是增函数，分布函数的意义是随机变量$X \leqslant y$的概率

根据分布函数的定义有
$$
\lim \limits_{x \rightarrow-\infty} F(x)=0 \qquad \lim \limits_{x \rightarrow+\infty} F(x)=1
$$
根据定义，分布函数单调递增

考虑指数分布，其概率密度函数为
$$
f(x)=\left\{\begin{array}{ll}
\lambda \mathrm{e}^{-\lambda x}, & x \geqslant 0 \\
0, & \text { 其他 }
\end{array}\right.
$$
其中$\lambda>0$ ，下面计算它的分布函数，如果$x<0$，则有
$$
F(x)=\int_{-\infty}^{x} 0 \mathrm{~d} u=0
$$
如果$x \geqslant 0$，则有
$$
F(x)=\int_{-\infty}^{x} f(u) \mathrm{d} u=\int_{0}^{x} \lambda \mathrm{e}^{-\lambda u} \mathrm{~d} u=\int_{0}^{x} \mathrm{e}^{-\lambda u} \mathrm{~d} \lambda u=-\left.\mathrm{e}^{-\lambda u}\right|_{0} ^{x}=1-\mathrm{e}^{-\lambda x}
$$
因此其分布函数为
$$
F(x)=\left\{\begin{array}{ll}
1-\mathrm{e}^{-\lambda x}, & x \geqslant 0 \\
0, & \text { 其他 }
\end{array}\right.
$$
下面以logistic回归为例说明概率密度函数与分布函数在机器学习中的应用，logistic回归的分布函数为logistic函数，定义为
$$
F(x)=\frac{1}{1+\mathrm{e}^{-x}}
$$
其形状如图所示，该函数单调递增，且有
$$
\lim \limits_{x \rightarrow-\infty} F(x)=0 \qquad \lim \limits_{x \rightarrow+\infty} F(x)=1
$$
满足分布函数的定义要求，其概率密度函数为$F(x)(1-F(x))$，概率密度函数的图像如图所示

![logistic函数的概率密度函数](https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_概率论/logistic函数的概率密度函数.svg)

## 数学期望

> 定义

`数学期望`(Mathematical Expectation)是平均值的推广，是加权平均值的抽象，对于随机变量，是其在概率意义下的均值

普通的均值没有考虑权重或概率，对于$n$个变量$x_{1}, \cdots, x_{n}$，它们的算木平均值为
$$
\frac{1}{n} \sum_{i=1}^{n} x_{i}
$$
这可看作变量取每个值的可能性相等，或者每个取值的权重相等

但对于很多应用，变量取每个值有不同的概率，因此这种简单的均值无法刻画出变量的性质

表为买彩票时各种奖的中多金额以及对应的概率值，中奖金额可看作离散型随机变量



如果要计算买一张彩票的平均中奖金额，直接用各种奖的中奖金额计算平均值显然是不合理的

正确的做法是考虑中各种奖的概率，以其作为权重来计算均值
$$
0 \times 0.9+10 \times 0.09+1000 \times 0.009+10000 \times 0.00099+1000000 \times 0.00001=29.8
$$
这种计算方式就是求数学期望

> 离散型随机变量的数学期望

对于离散型随机变量数学期望定义为
$$
E[X]=\sum_{i} x_{i} p(x_i)
$$
数学期望也可以写成$E_{X \sim p(x)}[X]$或$E_{p(x)}[X]$，表示用概率分布$p(x)$对随机变量$X$计算数学期望

如果式$E[X]$的级数收敛，则称数学期望存在

> 连续型随机变量的数学期望

对于连续型随机变量，数学期望通过定积分定义

假设连续型随机变量$X$的概率密度函数是$f(x)$，它的数学期望为
$$
E[X]=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x
$$
根据定积分的定义，连续型是离散型数学期望的极限情况

对于连续型随机变量，其数学期望是一个泛函

根据定义，常数的数学期望为其自身，即$E[c]=c$

根据数学期望的定义, 下面的公式成立
$$
E[k X]=k E[X]
$$
其中$k$为常数

如果$g(X)$是随机变量$X$的函数，则由它定义的随机变量的数学期望为
$$
E[g(X)]=\sum_{i} g\left(x_{i}\right) p\left(x_{i}\right)
$$
一般简记为$E_{X \sim p(x)}[g(X)]$

对于连续型椭机变量$X$，其函数$g(X)$的数学期望为
$$
E[g(X)]=\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x
$$
根据这种定义, 下面的公式成立
$$
E[g(X)+h(X)]=E[g(X)]+E[h(X)]
$$
以下表中的随机变量为例，$X^{2}$的数学期望为

| 随机变量取值 | 概率质量函数值 |
| ------------ | -------------- |
| 1            | 0.1            |
| 2            | 0.5            |
| 3            | 0.2            |
| 4            | 0.2            |

$$
E\left[X^{2}\right]=1^{2} \times 0.1+2^{2} \times 0.5+3^{2} \times 0.2+4^{2} \times 0.2=7.1
$$

下面以指数分布为例计算连续型概率分布的数学期望，如果$X$服从参数为$\lambda$的指数分布，则其数学期望为
$$
E[X]=\int_{0}^{+\infty} x \lambda \mathrm{e}^{-\lambda x} \mathrm{~d} x=-\int_{0}^{+\infty} x \mathrm{de}^{-\lambda x}=-\left.x \mathrm{e}^{-\lambda x}\right|_{0} ^{+\infty}+\int_{0}^{+\infty} \mathrm{e}^{-\lambda x} \mathrm{~d} x=-\left.\frac{1}{\lambda} \mathrm{e}^{-\lambda x}\right|_{0} ^{+\infty}=\frac{1}{\lambda}
$$

> 物理意义

如果将随机变量看作物体各点在空间中的坐标，概率密度函数是其在空间各点处的密度，则数学期望的物理意义是物体的质心

## 方差与标准差

> 定义

`方差`(Variance, var)反映随机变量取值的波动程度，是随机变量与其数学期望差值平差的数学期望
$$
var[X]=E[(X-E[X])^2]
$$
方差也可记为$D[X]$，如果不使用平方，则随机变量所有值与其数学期望的差值之和为0

> 离散型随机变量的方差

对于离散随机变量，方差定义为
$$
\operatorname{var}[X]=\sum_{i}\left(x_{i}-E[X]\right)^{2} p\left(x_{i}\right)
$$
对于下表中的随机变量，它的方差为

| 随机变量取值 | 概率质量函数值 |
| ------------ | -------------- |
| 1            | 0.1            |
| 2            | 0.5            |
| 3            | 0.2            |
| 4            | 0.2            |

$$
\operatorname{var}[X]=(1-2.5)^{2} \times 0.1+(2-2.5)^{2} \times 0.5+(3-2.5)^{2} \times 0.2+(4-2.5)^{2} \times 0.2=0.85
$$

> 连续型随机变量的方差

对于连续型随机变量，方差同样通过积分定义
$$
\operatorname{var}[X]=\int_{-\infty}^{+\infty}(x-E[X])^{2} f(x) \mathrm{d} x
$$
其中，$f(x)$为概率密度函数，根据定义，方差是非负的

计算指数分布的方差，其数学期望为$1 / \lambda$，其方差为
$$
\begin{aligned}
\operatorname{var}[X] &=\int_{0}^{+\infty}\left(x-\frac{1}{\lambda}\right)^{2} \lambda \mathrm{e}^{-\lambda x} \mathrm{~d} x=-\int_{0}^{+\infty}\left(x-\frac{1}{\lambda}\right)^{2} \mathrm{de}^{-\lambda x} \\
&=-\left.\left(x-\frac{1}{\lambda}\right)^{2} \mathrm{e}^{-\lambda x}\right|_{0} ^{+\infty}+\int_{0}^{+\infty} 2\left(x-\frac{1}{\lambda}\right) \mathrm{e}^{-\lambda x} \mathrm{~d} x=\frac{1}{\lambda^{2}}-\int_{0}^{+\infty} \frac{2}{\lambda}\left(x-\frac{1}{\lambda}\right) \mathrm{de}^{-\lambda x} \\
&=\frac{1}{\lambda^{2}}-\left.\frac{2}{\lambda}\left(x-\frac{1}{\lambda}\right) \mathrm{e}^{-\lambda x}\right|_{0} ^{+\infty}+\int_{0}^{+\infty} \frac{2}{\lambda} \mathrm{e}^{-\lambda x} \mathrm{~d} x=-\frac{1}{\lambda^{2}}-\left.\frac{2}{\lambda^{2}} \mathrm{e}^{-\lambda x}\right|_{0} ^{+\infty}=\frac{1}{\lambda^{2}}
\end{aligned}
$$
方差反映了随机变量偏离均值的程度，方差越小，随机变量的变化幅度越小，反之则越大

> 标准差(Standard Deviation)

标准差定义为方差的平方根
$$
\sigma=\sqrt{\operatorname{var}[X]}
$$
根据方差的定义，下面公式成立
$$
\begin{aligned}
\operatorname{var}[X] &=E\left[(X-E[X])^{2}\right]=E\left[X^{2}-2 X E[X]+E^{2}[X]\right]=E\left[X^{2}\right]-E[2 X E[X]]+E\left[E^{2}[X]\right] \\
&=E\left[X^{2}\right]-2 E[X] E[X]+E^{2}[X]=E\left[X^{2}\right]-E^{2}[X]
\end{aligned}
$$
实际计算方差时经常采用此式，在机器学习中被广泛使用

根据方差的定义，有$\operatorname{var}[k X]=k^{2} \operatorname{var}[X]$，这是因为
$$
\operatorname{var}[k X]=E\left[(k X-E[k X])^{2}\right]=E\left[(k X-k E[X])^{2}\right]=k^{2} E\left[(X-E[X])^{2}\right]=k^{2} \operatorname{var}[X]
$$
这意味着将随机变量的取值扩大$k$倍，其方差扩大$k^{2}$倍

> 物理意义

如果将随机变量看作物体各点在空间中的坐标，概率密度函数是其在空间各点处的密度，则方差的物理意义是物体的转动惯量

## Jensen不等式

介绍数学期望的一个重要不等式，Jensen不等式(Jensen's Inequality)，它在机器学习某些算法的推导中起着至关重要的作用

回顾凸函数的定义，如果$f(x)$是一个凸函数，$0 \leqslant \theta \leqslant 1$，则有
$$
f\left(\theta x_{1}+(1-\theta) x_{2}\right) \leqslant \theta f\left(x_{1}\right)+(1-\theta) f\left(x_{2}\right)
$$
将上式从两个点推广到$m$个点，如果
$$
a_{i} \geqslant 0, i=1,2, \cdots, m \qquad a_{1}+\cdots+a_{m}=1
$$
可以得到，对于$\forall x_{1}, \cdots, x_{m}$有
$$
f\left(a_{1} x_{1}+\cdots+a_{m} x_{m}\right) \leqslant a_{1} f\left(x_{1}\right)+\cdots+a_{m} f\left(x_{m}\right)
$$
如果将$x$看作是一个随机变量，$p\left(x=x_{i}\right)=a_{i}$是其概率分布，则有
$$
E[x]=a_{1} x_{1}+\cdots+a_{m} x_{m} \quad E[f(x)]=a_{1} f\left(x_{1}\right)+\cdots+a_{m} f\left(x_{m}\right)
$$
从而得到Jensen不等式
$$
E[f(x)] \geqslant f(E[x])
$$
对于凹函数，上面的不等式反号

> 可以根据定义式用归纳法证明式多点情况下的公式成立

首先考虑$m=2$的情况，$a_{1} \geqslant 0, a_{2} \geqslant 0$且$a_{1}+a_{2}=1$，即$a_{2}=1-a_{1}$，根据凸函数的定义，对于$\forall x_{1}, x_{2}$有
$$
f\left(a_{1} x_{1}+a_{2} x_{2}\right)=f\left(a_{1} x_{1}+\left(1-a_{1}\right) x_{2}\right) \leqslant a_{1} f\left(x_{1}\right)+\left(1-a_{1}\right) f\left(x_{2}\right)=a_{1} f\left(x_{1}\right)+a_{2} f\left(x_{2}\right)
$$
假设$m=n$时不等式成立，则当$m=n+1$时有
$$
\begin{aligned}
f\left(\sum_{i=1}^{n+1} a_{i} x_{i}\right) &=f\left(a_{1} x_{1}+\left(1-a_{1}\right) \sum_{i=2}^{n+1} \frac{a_{i}}{1-a_{1}} x_{i}\right) \leqslant a_{1} f\left(x_{1}\right)+\left(1-a_{1}\right) f\left(\sum_{i=2}^{n+1} \frac{a_{i}}{1-a_{1}} x_{i}\right) \\
& \leqslant a_{1} f\left(x_{1}\right)+\left(1-a_{1}\right) \sum_{i=2}^{n+1} \frac{a_{i}}{1-a_{1}} f\left(x_{i}\right)=a_{1} f\left(x_{1}\right)+\sum_{i=2}^{n+1} a_{i} f\left(x_{i}\right)=\sum_{i=1}^{n+1} a_{i} f\left(x_{i}\right)
\end{aligned}
$$


上面第2步利用了凸函数的定义，第3步成立是因为
$$
\sum_{i=2}^{n+1} \frac{a_{i}}{1-a_{1}}=\frac{\sum_{i=2}^{n+1} a_{i}}{1-a_{1}}=\frac{1-a_{1}}{1-a_{1}}=1
$$
根据归纳法的假设，$m=n$时不等式成立

如果$f(x)$是严格凸函数且$x$不是常数，则有
$$
E[f(x)]>f(E[x])
$$
这同样可以用归纳法证明，与前面的证明过程类似

如果$f(x)$是严格凸函数，当且仅当随机变量$x$是常数时，不等式取等号
$$
E[f(x)]=f(E[x])
$$
下面给出证明，如果随机变量$x$是常数，则有
$$
x_{1}=x_{2}=\cdots=x_{m}=c
$$
因此
$$
f\left(a_{1} x_{1}+\cdots+a_{m} x_{m}\right)=f\left(a_{1} c+\cdots+a_{m} c\right)=f\left(\left(a_{1}+\cdots+a_{m}\right) c\right)=f(c)
$$
以及
$$
[a_{1} f\left(x_{1}\right)+\cdots+a_{m} f\left(x_{m}\right)=a_{1} f(c)+\cdots+a_{m} f(c)=\left(a_{1}+\cdots+a_{m}\right) f(c)=f(c)
$$
因此有
$$
f\left(a_{1} x_{1}+\cdots+a_{m} x_{m}\right)=a_{1} f\left(x_{1}\right)+\cdots+a_{m} f\left(x_{m}\right)
$$
接下来证明如果不等式取等号，则有$x_{1}=x_{2}=\cdots=x_{m}$

可用反证法证明，如果$x_{i} \neq x_{j}, i \neq j$，由于$f(x)$是严格凸函数，根据前面的结论有
$$
f\left(a_{1} x_{1}+\cdots+a_{m} x_{m}\right)<a_{1} f\left(x_{1}\right)+\cdots+a_{m} f\left(x_{m}\right)
$$
Jensen不等式可以推广到随机向量的情况，在后面将利用此不等式推导出求解含有隐变量的最大似然估计问题的EM算法


# 常用概率分布

离散型概率分布包括均匀分布、伯努利分布、 二项分布、多项分布、几何分布

连续型概率分布包括均匀分布、正态分布, 以及$t$分布

## 均匀分布


对于离散型随机变量$X$，如果服从均匀分布(Uniform Distribution)，则其取每个值的概率相等，即
$$
p\left(X=x_{i}\right)=\frac{1}{n}, i=1, \cdots, n
$$
对于连续型随机变量$X$，如果服从区间$[a, b]$上的均匀分布，则其概率密度函数为分段常数函数，定义为
$$
f(x)=\left\{\begin{array}{ll}
\frac{1}{b-a}, & a \leqslant x \leqslant b \\
0, & x<a, x>b
\end{array}\right.
$$
